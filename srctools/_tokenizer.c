/* Generated by Cython 0.29.21 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "depends": [],
        "name": "srctools._tokenizer",
        "sources": [
            "srctools/_tokenizer.pyx"
        ]
    },
    "module_name": "srctools._tokenizer"
}
END: Cython Metadata */

#define PY_SSIZE_T_CLEAN
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.6+ or Python 3.3+.
#else
#define CYTHON_ABI "0_29_21"
#define CYTHON_HEX_VERSION 0x001D15F0
#define CYTHON_FUTURE_DIVISION 1
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x02070000
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 0
  #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT (PY_VERSION_HEX >= 0x03050000)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
  #endif
  #ifndef CYTHON_USE_DICT_VERSIONS
    #define CYTHON_USE_DICT_VERSIONS (PY_VERSION_HEX >= 0x030600B1)
  #endif
  #ifndef CYTHON_USE_EXC_INFO_STACK
    #define CYTHON_USE_EXC_INFO_STACK (PY_VERSION_HEX >= 0x030700A3)
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
  #ifdef SIZEOF_VOID_P
    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };
  #endif
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus) && __cplusplus >= 201103L
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #elif __has_cpp_attribute(gnu::fallthrough)
      #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__ ) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #elif defined(__GNUC__)
    #define CYTHON_INLINE __inline__
  #elif defined(_MSC_VER)
    #define CYTHON_INLINE __inline
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_INLINE inline
  #else
    #define CYTHON_INLINE
  #endif
#endif

#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
#if PY_VERSION_HEX >= 0x030800A4 && PY_VERSION_HEX < 0x030800B2
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, 0, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#else
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#endif
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#ifndef METH_STACKLESS
  #define METH_STACKLESS 0
#endif
#if PY_VERSION_HEX <= 0x030700A3 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject *const *args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject *const *args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
  #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
  #define PyMem_RawRealloc(p, n)       PyMem_Realloc(p, n)
  #define PyMem_RawFree(p)             PyMem_Free(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#if !CYTHON_FAST_THREAD_STATE || PY_VERSION_HEX < 0x02070000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
#include "pythread.h"
#define Py_tss_NEEDS_INIT 0
typedef int Py_tss_t;
static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
  *key = PyThread_create_key();
  return 0;
}
static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
  Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
  *key = Py_tss_NEEDS_INIT;
  return key;
}
static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
  PyObject_Free(key);
}
static CYTHON_INLINE int PyThread_tss_is_created(Py_tss_t *key) {
  return *key != Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE void PyThread_tss_delete(Py_tss_t *key) {
  PyThread_delete_key(*key);
  *key = Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
  return PyThread_set_key_value(*key, value);
}
static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
  return PyThread_get_key_value(*key);
}
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1 && CYTHON_USE_UNICODE_INTERNALS
#define __Pyx_PyDict_GetItemStr(dict, name)  _PyDict_GetItem_KnownHash(dict, name, ((PyASCIIObject *) name)->hash)
#else
#define __Pyx_PyDict_GetItemStr(dict, name)  PyDict_GetItem(dict, name)
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #if defined(PyUnicode_IS_READY) && defined(PyUnicode_GET_SIZE)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
  #else
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_LENGTH(u))
  #endif
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None || (PyString_Check(b) && !PyString_CheckExact(b)))) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None || (PyUnicode_Check(b) && !PyUnicode_CheckExact(b)))) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#ifndef PyObject_Unicode
  #define PyObject_Unicode             PyObject_Str
#endif
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#if PY_VERSION_HEX >= 0x030900A4
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_SET_REFCNT(obj, refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SET_SIZE(obj, size)
#else
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_REFCNT(obj) = (refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SIZE(obj) = (size)
#endif
#if CYTHON_ASSUME_SAFE_MACROS
  #define __Pyx_PySequence_SIZE(seq)  Py_SIZE(seq)
#else
  #define __Pyx_PySequence_SIZE(seq)  PySequence_Size(seq)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? ((void)(klass), PyMethod_New(func, self)) : __Pyx_NewRef(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif

#define __PYX_MARK_ERR_POS(f_index, lineno) \
    { __pyx_filename = __pyx_f[f_index]; (void)__pyx_filename; __pyx_lineno = lineno; (void)__pyx_lineno; __pyx_clineno = __LINE__; (void)__pyx_clineno; }
#define __PYX_ERR(f_index, lineno, Ln_error) \
    { __PYX_MARK_ERR_POS(f_index, lineno) goto Ln_error; }

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__srctools___tokenizer
#define __PYX_HAVE_API__srctools___tokenizer
/* Early includes */
#include <string.h>
#include <stdio.h>
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
static CYTHON_INLINE int __Pyx_is_valid_index(Py_ssize_t i, Py_ssize_t limit) {
    return (size_t) i < (size_t) limit;
}
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b);
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c) + 1);
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m = NULL;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime = NULL;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;


static const char *__pyx_f[] = {
  "srctools\\_tokenizer.pyx",
  "type.pxd",
};

/*--- Type declarations ---*/
struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer;
struct __pyx_obj_8srctools_10_tokenizer_Tokenizer;
struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer;
struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter;

/* "srctools/_tokenizer.pyx":61
 * 
 * # noinspection PyMissingTypeHints
 * cdef class BaseTokenizer:             # <<<<<<<<<<<<<<
 *     """Provides an interface for processing text into tokens.
 * 
 */
struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer {
  PyObject_HEAD
  struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *__pyx_vtab;
  PyObject *error_type;
  PyObject *filename;
  PyObject *pushback_tok;
  PyObject *pushback_val;
  int line_num;
};


/* "srctools/_tokenizer.pyx":219
 * 
 * 
 * cdef class Tokenizer(BaseTokenizer):             # <<<<<<<<<<<<<<
 *     """Processes text data into groups of tokens.
 * 
 */
struct __pyx_obj_8srctools_10_tokenizer_Tokenizer {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer __pyx_base;
  PyObject *cur_chunk;
  PyObject *chunk_iter;
  int char_index;
  int string_bracket;
  int allow_escapes;
  int allow_star_comments;
  int mark_bare_strings;
  Py_ssize_t buf_size;
  Py_ssize_t buf_pos;
  Py_UCS4 *val_buffer;
};


/* "srctools/_tokenizer.pyx":609
 * 
 * 
 * cdef class IterTokenizer(BaseTokenizer):             # <<<<<<<<<<<<<<
 *     """Wraps a token iterator to provide the tokenizer interface.
 * 
 */
struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer __pyx_base;
  PyObject *source;
};


/* "srctools/_tokenizer.pyx":637
 * @cython.embedsignature(False)
 * @cython.internal
 * cdef class _NewlinesIter:             # <<<<<<<<<<<<<<
 *     """Iterate over the tokens, skipping newlines."""
 *     cdef Tokenizer tok
 */
struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter {
  PyObject_HEAD
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *tok;
};



/* "srctools/_tokenizer.pyx":61
 * 
 * # noinspection PyMissingTypeHints
 * cdef class BaseTokenizer:             # <<<<<<<<<<<<<<
 *     """Provides an interface for processing text into tokens.
 * 
 */

struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer {
  PyObject *(*_error)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *, PyObject *);
  PyObject *(*next_token)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *);
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *__pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer;
static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *, PyObject *);


/* "srctools/_tokenizer.pyx":219
 * 
 * 
 * cdef class Tokenizer(BaseTokenizer):             # <<<<<<<<<<<<<<
 *     """Processes text data into groups of tokens.
 * 
 */

struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer {
  struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer __pyx_base;
  void (*buf_reset)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
  void (*buf_add_char)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, Py_UCS4);
  PyObject *(*buf_get_text)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
  Py_UCS4 (*_next_char)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *__pyx_vtabptr_8srctools_10_tokenizer_Tokenizer;
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, Py_UCS4);


/* "srctools/_tokenizer.pyx":609
 * 
 * 
 * cdef class IterTokenizer(BaseTokenizer):             # <<<<<<<<<<<<<<
 *     """Wraps a token iterator to provide the tokenizer interface.
 * 
 */

struct __pyx_vtabstruct_8srctools_10_tokenizer_IterTokenizer {
  struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer __pyx_base;
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_IterTokenizer *__pyx_vtabptr_8srctools_10_tokenizer_IterTokenizer;

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#define __Pyx_BUILD_ASSERT_EXPR(cond)\
    (sizeof(char [1 - 2*!(cond)]) - 1)
#ifndef Py_MEMBER_SIZE
#define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
#endif
  static size_t __pyx_pyframe_localsplus_offset = 0;
  #include "frameobject.h"
  #define __Pxy_PyFrame_Initialize_Offsets()\
    ((void)__Pyx_BUILD_ASSERT_EXPR(sizeof(PyFrameObject) == offsetof(PyFrameObject, f_localsplus) + Py_MEMBER_SIZE(PyFrameObject, f_localsplus)),\
     (void)(__pyx_pyframe_localsplus_offset = ((size_t)PyFrame_Type.tp_basicsize) - Py_MEMBER_SIZE(PyFrameObject, f_localsplus)))
  #define __Pyx_PyFrame_GetLocalsplus(frame)\
    (assert(__pyx_pyframe_localsplus_offset), (PyObject **)(((char *)(frame)) + __pyx_pyframe_localsplus_offset))
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* PyObjectFormatSimple.proto */
#if CYTHON_COMPILING_IN_PYPY
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        PyObject_Format(s, f))
#elif PY_MAJOR_VERSION < 3
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        likely(PyString_CheckExact(s)) ? PyUnicode_FromEncodedObject(s, NULL, "strict") :\
        PyObject_Format(s, f))
#elif CYTHON_USE_TYPE_SLOTS
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        likely(PyLong_CheckExact(s)) ? PyLong_Type.tp_str(s) :\
        likely(PyFloat_CheckExact(s)) ? PyFloat_Type.tp_str(s) :\
        PyObject_Format(s, f))
#else
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        PyObject_Format(s, f))
#endif

/* IncludeStringH.proto */
#include <string.h>

/* JoinPyUnicode.proto */
static PyObject* __Pyx_PyUnicode_Join(PyObject* value_tuple, Py_ssize_t value_count, Py_ssize_t result_ulength,
                                      Py_UCS4 max_char);

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* KeywordStringCheck.proto */
static int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed);

/* ArgTypeTest.proto */
#define __Pyx_ArgTypeTest(obj, type, none_allowed, name, exact)\
    ((likely((Py_TYPE(obj) == type) | (none_allowed && (obj == Py_None)))) ? 1 :\
        __Pyx__ArgTypeTest(obj, type, name, exact))
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact);

/* PyObjectFormatAndDecref.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatSimpleAndDecref(PyObject* s, PyObject* f);
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatAndDecref(PyObject* s, PyObject* f);

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* RaiseNoneIterError.proto */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void);

/* GetTopmostException.proto */
#if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem * __Pyx_PyErr_GetTopmostException(PyThreadState *tstate);
#endif

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* GetItemIntUnicode.proto */
#define __Pyx_GetItemInt_Unicode(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Unicode_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "string index out of range"), (Py_UCS4)-1))
static CYTHON_INLINE Py_UCS4 __Pyx_GetItemInt_Unicode_Fast(PyObject* ustring, Py_ssize_t i,
                                                           int wraparound, int boundscheck);

/* IterNext.proto */
#define __Pyx_PyIter_Next(obj) __Pyx_PyIter_Next2(obj, NULL)
static CYTHON_INLINE PyObject *__Pyx_PyIter_Next2(PyObject *, PyObject *);

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* BuildPyUnicode.proto */
static PyObject* __Pyx_PyUnicode_BuildFromAscii(Py_ssize_t ulength, char* chars, int clength,
                                                int prepend_sign, char padding_char);

/* CIntToPyUnicode.proto */
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_From_int(int value, Py_ssize_t width, char padding_char, char format_char);

/* PyObjectCallNoArg.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

/* unicode_iter.proto */
static CYTHON_INLINE int __Pyx_init_unicode_iteration(
    PyObject* ustring, Py_ssize_t *length, void** data, int *kind);

/* PyObjectFormat.proto */
#if CYTHON_USE_UNICODE_WRITER
static PyObject* __Pyx_PyObject_Format(PyObject* s, PyObject* f);
#else
#define __Pyx_PyObject_Format(s, f) PyObject_Format(s, f)
#endif

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* PyObject_GenericGetAttrNoDict.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttrNoDict PyObject_GenericGetAttr
#endif

/* PyObject_GenericGetAttr.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject* __Pyx_PyObject_GenericGetAttr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttr PyObject_GenericGetAttr
#endif

/* SetVTable.proto */
static int __Pyx_SetVtable(PyObject *dict, void *vtable);

/* TypeImport.proto */
#ifndef __PYX_HAVE_RT_ImportType_proto
#define __PYX_HAVE_RT_ImportType_proto
enum __Pyx_ImportType_CheckSize {
   __Pyx_ImportType_CheckSize_Error = 0,
   __Pyx_ImportType_CheckSize_Warn = 1,
   __Pyx_ImportType_CheckSize_Ignore = 2
};
static PyTypeObject *__Pyx_ImportType(PyObject* module, const char *module_name, const char *class_name, size_t size, enum __Pyx_ImportType_CheckSize check_size);
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* ImportFrom.proto */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);

/* FetchCommonType.proto */
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type);

/* CythonFunctionShared.proto */
#define __Pyx_CyFunction_USED 1
#define __Pyx_CYFUNCTION_STATICMETHOD  0x01
#define __Pyx_CYFUNCTION_CLASSMETHOD   0x02
#define __Pyx_CYFUNCTION_CCLASS        0x04
#define __Pyx_CyFunction_GetClosure(f)\
    (((__pyx_CyFunctionObject *) (f))->func_closure)
#define __Pyx_CyFunction_GetClassObj(f)\
    (((__pyx_CyFunctionObject *) (f))->func_classobj)
#define __Pyx_CyFunction_Defaults(type, f)\
    ((type *)(((__pyx_CyFunctionObject *) (f))->defaults))
#define __Pyx_CyFunction_SetDefaultsGetter(f, g)\
    ((__pyx_CyFunctionObject *) (f))->defaults_getter = (g)
typedef struct {
    PyCFunctionObject func;
#if PY_VERSION_HEX < 0x030500A0
    PyObject *func_weakreflist;
#endif
    PyObject *func_dict;
    PyObject *func_name;
    PyObject *func_qualname;
    PyObject *func_doc;
    PyObject *func_globals;
    PyObject *func_code;
    PyObject *func_closure;
    PyObject *func_classobj;
    void *defaults;
    int defaults_pyobjects;
    size_t defaults_size;  // used by FusedFunction for copying defaults
    int flags;
    PyObject *defaults_tuple;
    PyObject *defaults_kwdict;
    PyObject *(*defaults_getter)(PyObject *);
    PyObject *func_annotations;
} __pyx_CyFunctionObject;
static PyTypeObject *__pyx_CyFunctionType = 0;
#define __Pyx_CyFunction_Check(obj)  (__Pyx_TypeCheck(obj, __pyx_CyFunctionType))
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject* op, PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *self,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *m,
                                                         size_t size,
                                                         int pyobjects);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *m,
                                                            PyObject *tuple);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *m,
                                                             PyObject *dict);
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *m,
                                                              PyObject *dict);
static int __pyx_CyFunction_init(void);

/* CythonFunction.proto */
static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *closure,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);

/* PyDictVersioning.proto */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
    (version_var) = __PYX_GET_DICT_VERSION(dict);\
    (cache_var) = (value);
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
        (VAR) = __pyx_dict_cached_value;\
    } else {\
        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
    }\
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
#else
#define __PYX_GET_DICT_VERSION(dict)  (0)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
#endif

/* GetModuleGlobalName.proto */
#if CYTHON_USE_DICT_VERSIONS
#define __Pyx_GetModuleGlobalName(var, name)  {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
        (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
        __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
}
#define __Pyx_GetModuleGlobalNameUncached(var, name)  {\
    PY_UINT64_T __pyx_dict_version;\
    PyObject *__pyx_dict_cached_value;\
    (var) = __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
}
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value);
#else
#define __Pyx_GetModuleGlobalName(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name);
#endif

/* PyObjectSetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
#define __Pyx_PyObject_DelAttrStr(o,n) __Pyx_PyObject_SetAttrStr(o, n, NULL)
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value);
#else
#define __Pyx_PyObject_DelAttrStr(o,n)   PyObject_DelAttr(o,n)
#define __Pyx_PyObject_SetAttrStr(o,n,v) PyObject_SetAttr(o,n,v)
#endif

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* PyUCS4InUnicode.proto */
static CYTHON_INLINE int __Pyx_UnicodeContainsUCS4(PyObject* unicode, Py_UCS4 character);

/* UnicodeAsUCS4.proto */
static CYTHON_INLINE Py_UCS4 __Pyx_PyUnicode_AsPy_UCS4(PyObject*);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE char __Pyx_PyInt_As_char(PyObject *);

/* ObjectAsUCS4.proto */
#define __Pyx_PyObject_AsPy_UCS4(x)\
    (likely(PyUnicode_Check(x)) ? __Pyx_PyUnicode_AsPy_UCS4(x) : __Pyx__PyObject_AsPy_UCS4(x))
static Py_UCS4 __Pyx__PyObject_AsPy_UCS4(PyObject*);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_message); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer_next_token(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto*/
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, Py_UCS4 __pyx_v_uchar); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static Py_UCS4 __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_13IterTokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self); /* proto*/

/* Module declarations from 'cython' */

/* Module declarations from 'cpython.mem' */

/* Module declarations from 'libc.string' */

/* Module declarations from 'libc.stdio' */

/* Module declarations from '__builtin__' */

/* Module declarations from 'cpython.type' */
static PyTypeObject *__pyx_ptype_7cpython_4type_type = 0;

/* Module declarations from 'cpython' */

/* Module declarations from 'cpython.object' */

/* Module declarations from 'srctools._tokenizer' */
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_Tokenizer = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_IterTokenizer = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer__NewlinesIter = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_os_fspath = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_Token = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_TokenSyntaxError = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_STRING = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PAREN_ARGS = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PROP_FLAG = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_DIRECTIVE = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BARE_STRING = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EOF = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_NEWLINE = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EMPTY_ITER = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EOF_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_COLON_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EQUALS_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PLUS_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP = 0;
#define __Pyx_MODULE_NAME "srctools._tokenizer"
extern int __pyx_module_is_main_srctools___tokenizer;
int __pyx_module_is_main_srctools___tokenizer = 0;

/* Implementation of 'srctools._tokenizer' */
static PyObject *__pyx_builtin_TypeError;
static PyObject *__pyx_builtin_NotImplementedError;
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_AttributeError;
static PyObject *__pyx_builtin_UnicodeDecodeError;
static PyObject *__pyx_builtin_StopIteration;
static PyObject *__pyx_builtin_id;
static const char __pyx_k_[] = "\"!";
static const char __pyx_k_X[] = "X";
static const char __pyx_k_i[] = "i";
static const char __pyx_k__3[] = "!";
static const char __pyx_k__6[] = "";
static const char __pyx_k__7[] = "\n";
static const char __pyx_k__8[] = "{";
static const char __pyx_k__9[] = "}";
static const char __pyx_k_id[] = "id";
static const char __pyx_k_os[] = "os";
static const char __pyx_k_EOF[] = "EOF";
static const char __pyx_k__10[] = "[";
static const char __pyx_k__11[] = "]";
static const char __pyx_k__12[] = ":";
static const char __pyx_k__13[] = "=";
static const char __pyx_k__14[] = "+";
static const char __pyx_k__18[] = ")!";
static const char __pyx_k__19[] = ", ";
static const char __pyx_k__20[] = ")";
static const char __pyx_k__21[] = ">";
static const char __pyx_k_all[] = "__all__";
static const char __pyx_k_tok[] = "tok";
static const char __pyx_k_PLUS[] = "PLUS";
static const char __pyx_k_args[] = "args";
static const char __pyx_k_data[] = "data";
static const char __pyx_k_init[] = "__init__";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_name[] = "__name__";
static const char __pyx_k_peek[] = "peek";
static const char __pyx_k_self[] = "self";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_text[] = "text";
static const char __pyx_k_COLON[] = "COLON";
static const char __pyx_k_Token[] = "Token";
static const char __pyx_k_error[] = "error";
static const char __pyx_k_token[] = "token";
static const char __pyx_k_value[] = "value";
static const char __pyx_k_EQUALS[] = "EQUALS";
static const char __pyx_k_STRING[] = "STRING";
static const char __pyx_k_expect[] = "expect";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_fspath[] = "fspath";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_letter[] = "letter";
static const char __pyx_k_module[] = "__module__";
static const char __pyx_k_name_2[] = "name";
static const char __pyx_k_reduce[] = "__reduce__";
static const char __pyx_k_return[] = "return";
static const char __pyx_k_source[] = "source";
static const char __pyx_k_NEWLINE[] = "NEWLINE";
static const char __pyx_k_but_got[] = ", but got ";
static const char __pyx_k_message[] = "message";
static const char __pyx_k_tok_val[] = "tok_val";
static const char __pyx_k_unicode[] = "unicode";
static const char __pyx_k_value_2[] = "_value_";
static const char __pyx_k_Expected[] = "Expected ";
static const char __pyx_k_casefold[] = "casefold";
static const char __pyx_k_enc_text[] = "enc_text";
static const char __pyx_k_filename[] = "filename";
static const char __pyx_k_out_buff[] = "out_buff";
static const char __pyx_k_DIRECTIVE[] = "DIRECTIVE";
static const char __pyx_k_PROP_FLAG[] = "PROP_FLAG";
static const char __pyx_k_Tokenizer[] = "Tokenizer";
static const char __pyx_k_TypeError[] = "TypeError";
static const char __pyx_k_final_len[] = "final_len";
static const char __pyx_k_push_back[] = "push_back";
static const char __pyx_k_BRACE_OPEN[] = "BRACE_OPEN";
static const char __pyx_k_BRACK_OPEN[] = "BRACK_OPEN";
static const char __pyx_k_PAREN_ARGS[] = "PAREN_ARGS";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_next_token[] = "next_token";
static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static const char __pyx_k_real_value[] = "real_value";
static const char __pyx_k_BARE_STRING[] = "BARE_STRING";
static const char __pyx_k_BRACE_CLOSE[] = "BRACE_CLOSE";
static const char __pyx_k_BRACK_CLOSE[] = "BRACK_CLOSE";
static const char __pyx_k_escape_text[] = "escape_text";
static const char __pyx_k_tok_and_val[] = "tok_and_val";
static const char __pyx_k_skip_newline[] = "skip_newline";
static const char __pyx_k_BaseTokenizer[] = "BaseTokenizer";
static const char __pyx_k_IterTokenizer[] = "IterTokenizer(";
static const char __pyx_k_StopIteration[] = "StopIteration";
static const char __pyx_k_Unknown_token[] = "Unknown token ";
static const char __pyx_k_allow_escapes[] = "allow_escapes";
static const char __pyx_k_AttributeError[] = "AttributeError";
static const char __pyx_k_is_not_a_Token[] = " is not a Token!";
static const char __pyx_k_string_bracket[] = "string_bracket";
static const char __pyx_k_Abstract_method[] = "Abstract method!";
static const char __pyx_k_IterTokenizer_2[] = "IterTokenizer";
static const char __pyx_k_TokenSyntaxError[] = "TokenSyntaxError";
static const char __pyx_k_Unexpected_token[] = "Unexpected token ";
static const char __pyx_k_mark_bare_strings[] = "mark_bare_strings";
static const char __pyx_k_skipping_newlines[] = "skipping_newlines";
static const char __pyx_k_BaseTokenizer_peek[] = "BaseTokenizer.peek";
static const char __pyx_k_UnicodeDecodeError[] = "UnicodeDecodeError";
static const char __pyx_k_Value_required_for[] = "Value required for ";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_srctools_tokenizer[] = "srctools.tokenizer";
static const char __pyx_k_BaseTokenizer_error[] = "BaseTokenizer.error";
static const char __pyx_k_NotImplementedError[] = "NotImplementedError";
static const char __pyx_k_Unterminated_string[] = "Unterminated string!";
static const char __pyx_k_allow_star_comments[] = "allow_star_comments";
static const char __pyx_k_srctools__tokenizer[] = "srctools._tokenizer";
static const char __pyx_k_BaseTokenizer_expect[] = "BaseTokenizer.expect";
static const char __pyx_k_Cannot_nest_brackets[] = "Cannot nest [] brackets!";
static const char __pyx_k_Unexpected_character[] = "Unexpected character \"";
static const char __pyx_k_Could_not_decode_file[] = "Could not decode file!";
static const char __pyx_k_Data_was_not_a_string[] = "Data was not a string!";
static const char __pyx_k_NewlinesIter___reduce[] = "_NewlinesIter.__reduce__";
static const char __pyx_k_No_open_to_close_with[] = "No open [] to close with \"]\"!";
static const char __pyx_k_BaseTokenizer___reduce[] = "BaseTokenizer.__reduce__";
static const char __pyx_k_Cannot_nest_brackets_2[] = "Cannot nest () brackets!";
static const char __pyx_k_Invalid_error_instance[] = "Invalid error instance \"";
static const char __pyx_k_BaseTokenizer_push_back[] = "BaseTokenizer.push_back";
static const char __pyx_k_No_open_to_close_with_2[] = "No open () to close with \")\"!";
static const char __pyx_k_srctools__tokenizer_pyx[] = "srctools\\_tokenizer.pyx";
static const char __pyx_k_Cannot_parse_binary_data[] = "Cannot parse binary data!";
static const char __pyx_k_Cannot_pickle_Tokenizers[] = "Cannot pickle Tokenizers!";
static const char __pyx_k_Unterminated_parentheses[] = "Unterminated parentheses!";
static const char __pyx_k_Token_already_pushed_back[] = "Token already pushed back!";
static const char __pyx_k_Cannot_pickle__NewlinesIter[] = "Cannot pickle _NewlinesIter!";
static const char __pyx_k_style_comments_are_not_allowed[] = "/**/-style comments are not allowed!";
static const char __pyx_k_BaseTokenizer_skipping_newlines[] = "BaseTokenizer.skipping_newlines";
static const char __pyx_k_Cannot_parse_binary_data_Decode[] = "Cannot parse binary data! Decode to the desired encoding, or wrap in io.TextIOWrapper() to decode gradually.";
static const char __pyx_k_Cython_version_of_the_Tokenizer[] = "Cython version of the Tokenizer class.";
static const char __pyx_k_srctools_tokenizer_BaseTokenize[] = "<srctools.tokenizer.BaseTokenizer.skipping_newlines() at ";
static const char __pyx_k_Cannot_create__NewlinesIter_inst[] = "Cannot create '_NewlinesIter' instances";
static const char __pyx_k_Reached_end_of_line_without_clos[] = "Reached end of line without closing \"]\"!";
static const char __pyx_k_Single_slash_found_instead_of_tw[] = "Single slash found, instead of two for a comment (// or /* */)!";
static const char __pyx_k_Unclosed_comment_starting_on_lin[] = "Unclosed /* comment (starting on line ";
static const char __pyx_k_Single_slash_found_instead_of_tw_2[] = "Single slash found, instead of two for a comment (//)!";
static PyObject *__pyx_kp_u_;
static PyObject *__pyx_kp_u_Abstract_method;
static PyObject *__pyx_n_s_AttributeError;
static PyObject *__pyx_n_s_BARE_STRING;
static PyObject *__pyx_n_s_BRACE_CLOSE;
static PyObject *__pyx_n_s_BRACE_OPEN;
static PyObject *__pyx_n_s_BRACK_CLOSE;
static PyObject *__pyx_n_s_BRACK_OPEN;
static PyObject *__pyx_n_s_BaseTokenizer;
static PyObject *__pyx_n_u_BaseTokenizer;
static PyObject *__pyx_n_s_BaseTokenizer___reduce;
static PyObject *__pyx_n_s_BaseTokenizer_error;
static PyObject *__pyx_n_s_BaseTokenizer_expect;
static PyObject *__pyx_n_s_BaseTokenizer_peek;
static PyObject *__pyx_n_s_BaseTokenizer_push_back;
static PyObject *__pyx_n_s_BaseTokenizer_skipping_newlines;
static PyObject *__pyx_n_s_COLON;
static PyObject *__pyx_kp_u_Cannot_create__NewlinesIter_inst;
static PyObject *__pyx_kp_u_Cannot_nest_brackets;
static PyObject *__pyx_kp_u_Cannot_nest_brackets_2;
static PyObject *__pyx_kp_u_Cannot_parse_binary_data;
static PyObject *__pyx_kp_u_Cannot_parse_binary_data_Decode;
static PyObject *__pyx_kp_u_Cannot_pickle_Tokenizers;
static PyObject *__pyx_kp_u_Cannot_pickle__NewlinesIter;
static PyObject *__pyx_kp_u_Could_not_decode_file;
static PyObject *__pyx_n_s_DIRECTIVE;
static PyObject *__pyx_kp_u_Data_was_not_a_string;
static PyObject *__pyx_n_s_EOF;
static PyObject *__pyx_n_s_EQUALS;
static PyObject *__pyx_kp_u_Expected;
static PyObject *__pyx_kp_u_Invalid_error_instance;
static PyObject *__pyx_kp_u_IterTokenizer;
static PyObject *__pyx_n_s_IterTokenizer_2;
static PyObject *__pyx_n_u_IterTokenizer_2;
static PyObject *__pyx_n_s_NEWLINE;
static PyObject *__pyx_n_s_NewlinesIter___reduce;
static PyObject *__pyx_kp_u_No_open_to_close_with;
static PyObject *__pyx_kp_u_No_open_to_close_with_2;
static PyObject *__pyx_n_s_NotImplementedError;
static PyObject *__pyx_n_s_PAREN_ARGS;
static PyObject *__pyx_n_s_PLUS;
static PyObject *__pyx_n_s_PROP_FLAG;
static PyObject *__pyx_kp_u_Reached_end_of_line_without_clos;
static PyObject *__pyx_n_s_STRING;
static PyObject *__pyx_kp_u_Single_slash_found_instead_of_tw;
static PyObject *__pyx_kp_u_Single_slash_found_instead_of_tw_2;
static PyObject *__pyx_n_s_StopIteration;
static PyObject *__pyx_n_s_Token;
static PyObject *__pyx_n_s_TokenSyntaxError;
static PyObject *__pyx_kp_u_Token_already_pushed_back;
static PyObject *__pyx_n_s_Tokenizer;
static PyObject *__pyx_n_u_Tokenizer;
static PyObject *__pyx_n_s_TypeError;
static PyObject *__pyx_kp_u_Unclosed_comment_starting_on_lin;
static PyObject *__pyx_kp_u_Unexpected_character;
static PyObject *__pyx_kp_u_Unexpected_token;
static PyObject *__pyx_n_s_UnicodeDecodeError;
static PyObject *__pyx_kp_u_Unknown_token;
static PyObject *__pyx_kp_u_Unterminated_parentheses;
static PyObject *__pyx_kp_u_Unterminated_string;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_kp_u_Value_required_for;
static PyObject *__pyx_n_u_X;
static PyObject *__pyx_kp_u__10;
static PyObject *__pyx_kp_u__11;
static PyObject *__pyx_kp_u__12;
static PyObject *__pyx_kp_u__13;
static PyObject *__pyx_kp_u__14;
static PyObject *__pyx_kp_u__18;
static PyObject *__pyx_kp_u__19;
static PyObject *__pyx_kp_u__20;
static PyObject *__pyx_kp_u__21;
static PyObject *__pyx_kp_u__3;
static PyObject *__pyx_kp_u__6;
static PyObject *__pyx_kp_u__7;
static PyObject *__pyx_kp_u__8;
static PyObject *__pyx_kp_u__9;
static PyObject *__pyx_n_s_all;
static PyObject *__pyx_n_s_allow_escapes;
static PyObject *__pyx_n_s_allow_star_comments;
static PyObject *__pyx_n_s_args;
static PyObject *__pyx_kp_u_but_got;
static PyObject *__pyx_n_s_casefold;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_data;
static PyObject *__pyx_n_s_enc_text;
static PyObject *__pyx_n_s_error;
static PyObject *__pyx_n_s_escape_text;
static PyObject *__pyx_n_u_escape_text;
static PyObject *__pyx_n_s_expect;
static PyObject *__pyx_n_s_filename;
static PyObject *__pyx_n_s_final_len;
static PyObject *__pyx_n_s_format;
static PyObject *__pyx_n_s_fspath;
static PyObject *__pyx_n_s_i;
static PyObject *__pyx_n_s_id;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_init;
static PyObject *__pyx_kp_u_is_not_a_Token;
static PyObject *__pyx_n_s_letter;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_mark_bare_strings;
static PyObject *__pyx_n_s_message;
static PyObject *__pyx_n_s_module;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_name_2;
static PyObject *__pyx_n_s_next_token;
static PyObject *__pyx_n_s_os;
static PyObject *__pyx_n_s_out_buff;
static PyObject *__pyx_n_s_peek;
static PyObject *__pyx_n_s_push_back;
static PyObject *__pyx_n_s_pyx_vtable;
static PyObject *__pyx_n_s_real_value;
static PyObject *__pyx_n_s_reduce;
static PyObject *__pyx_n_s_return;
static PyObject *__pyx_n_s_self;
static PyObject *__pyx_n_s_skip_newline;
static PyObject *__pyx_n_s_skipping_newlines;
static PyObject *__pyx_n_s_source;
static PyObject *__pyx_n_s_srctools__tokenizer;
static PyObject *__pyx_kp_s_srctools__tokenizer_pyx;
static PyObject *__pyx_n_s_srctools_tokenizer;
static PyObject *__pyx_kp_u_srctools_tokenizer;
static PyObject *__pyx_kp_u_srctools_tokenizer_BaseTokenize;
static PyObject *__pyx_n_s_string_bracket;
static PyObject *__pyx_kp_u_style_comments_are_not_allowed;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_n_s_text;
static PyObject *__pyx_n_s_tok;
static PyObject *__pyx_n_s_tok_and_val;
static PyObject *__pyx_n_s_tok_val;
static PyObject *__pyx_n_s_token;
static PyObject *__pyx_n_u_unicode;
static PyObject *__pyx_n_s_value;
static PyObject *__pyx_n_s_value_2;
static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer___init__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_filename, PyObject *__pyx_v_error); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_4error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_message, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_6__call__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8__iter__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10push_back(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_tok, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_12peek(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_14skipping_newlines(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_16expect(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_token, int __pyx_v_skip_newline); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_4__del__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static void __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_data, PyObject *__pyx_v_filename, PyObject *__pyx_v_error, int __pyx_v_string_bracket, int __pyx_v_allow_escapes, int __pyx_v_allow_star_comments, int __pyx_v_mark_bare_strings); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer___init__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self, PyObject *__pyx_v_source, PyObject *__pyx_v_filename, PyObject *__pyx_v_error); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13IterTokenizer_2__repr__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source___get__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_2__set__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_4__del__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter___cinit__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self, struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_tok); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_2__repr__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_4__init__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_tok); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_6__iter__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_8__next__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_escape_text(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_text); /* proto */
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_Tokenizer(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_IterTokenizer(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer__NewlinesIter(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tuple__2;
static PyObject *__pyx_tuple__4;
static PyObject *__pyx_tuple__5;
static PyObject *__pyx_tuple__15;
static PyObject *__pyx_tuple__16;
static PyObject *__pyx_tuple__17;
static PyObject *__pyx_tuple__22;
static PyObject *__pyx_tuple__23;
static PyObject *__pyx_tuple__24;
static PyObject *__pyx_tuple__26;
static PyObject *__pyx_tuple__28;
static PyObject *__pyx_tuple__30;
static PyObject *__pyx_tuple__32;
static PyObject *__pyx_tuple__34;
static PyObject *__pyx_tuple__36;
static PyObject *__pyx_tuple__38;
static PyObject *__pyx_codeobj__25;
static PyObject *__pyx_codeobj__27;
static PyObject *__pyx_codeobj__29;
static PyObject *__pyx_codeobj__31;
static PyObject *__pyx_codeobj__33;
static PyObject *__pyx_codeobj__35;
static PyObject *__pyx_codeobj__37;
static PyObject *__pyx_codeobj__39;
/* Late includes */

/* "srctools/_tokenizer.pyx":78
 *     cdef public int line_num
 * 
 *     def __init__(self, filename, error):             # <<<<<<<<<<<<<<
 *         # Use os method to convert to string.
 *         # We know this isn't a method, so skip Cython's optimisation.
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_filename = 0;
  PyObject *__pyx_v_error = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_filename,&__pyx_n_s_error,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_filename)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_error)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__init__", 1, 2, 2, 1); __PYX_ERR(0, 78, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 78, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_filename = values[0];
    __pyx_v_error = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 78, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer___init__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_filename, __pyx_v_error);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer___init__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_filename, PyObject *__pyx_v_error) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  Py_UCS4 __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":82
 *         # We know this isn't a method, so skip Cython's optimisation.
 *         with cython.optimize.unpack_method_calls(False):
 *             self.filename = os_fspath(filename)             # <<<<<<<<<<<<<<
 * 
 *         if error is None:
 */
  __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_v_8srctools_10_tokenizer_os_fspath, __pyx_v_filename); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 82, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyUnicode_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_1)->tp_name), 0))) __PYX_ERR(0, 82, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->filename);
  __Pyx_DECREF(__pyx_v_self->filename);
  __pyx_v_self->filename = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":84
 *             self.filename = os_fspath(filename)
 * 
 *         if error is None:             # <<<<<<<<<<<<<<
 *             self.error_type = TokenSyntaxError
 *         else:
 */
  __pyx_t_2 = (__pyx_v_error == Py_None);
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "srctools/_tokenizer.pyx":85
 * 
 *         if error is None:
 *             self.error_type = TokenSyntaxError             # <<<<<<<<<<<<<<
 *         else:
 *             if not issubclass(error, TokenSyntaxError):
 */
    __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
    __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
    __Pyx_GOTREF(__pyx_v_self->error_type);
    __Pyx_DECREF(__pyx_v_self->error_type);
    __pyx_v_self->error_type = __pyx_v_8srctools_10_tokenizer_TokenSyntaxError;

    /* "srctools/_tokenizer.pyx":84
 *             self.filename = os_fspath(filename)
 * 
 *         if error is None:             # <<<<<<<<<<<<<<
 *             self.error_type = TokenSyntaxError
 *         else:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":87
 *             self.error_type = TokenSyntaxError
 *         else:
 *             if not issubclass(error, TokenSyntaxError):             # <<<<<<<<<<<<<<
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"' '!')
 *             self.error_type = error
 */
  /*else*/ {
    __pyx_t_1 = __pyx_v_8srctools_10_tokenizer_TokenSyntaxError;
    __Pyx_INCREF(__pyx_t_1);
    __pyx_t_3 = PyObject_IsSubclass(__pyx_v_error, __pyx_t_1); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(0, 87, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_2 = ((!(__pyx_t_3 != 0)) != 0);
    if (unlikely(__pyx_t_2)) {

      /* "srctools/_tokenizer.pyx":88
 *         else:
 *             if not issubclass(error, TokenSyntaxError):
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"' '!')             # <<<<<<<<<<<<<<
 *             self.error_type = error
 * 
 */
      __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 88, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_4 = 0;
      __pyx_t_5 = 127;
      __Pyx_INCREF(__pyx_kp_u_Invalid_error_instance);
      __pyx_t_4 += 24;
      __Pyx_GIVEREF(__pyx_kp_u_Invalid_error_instance);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_kp_u_Invalid_error_instance);
      __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)Py_TYPE(__pyx_v_error)), __pyx_n_s_name); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 88, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = __Pyx_PyObject_FormatSimple(__pyx_t_6, __pyx_empty_unicode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 88, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_5;
      __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_7);
      __pyx_t_7 = 0;
      __Pyx_INCREF(__pyx_kp_u_);
      __pyx_t_4 += 2;
      __Pyx_GIVEREF(__pyx_kp_u_);
      PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_kp_u_);
      __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_1, 3, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 88, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_builtin_TypeError, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 88, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 88, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":87
 *             self.error_type = TokenSyntaxError
 *         else:
 *             if not issubclass(error, TokenSyntaxError):             # <<<<<<<<<<<<<<
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"' '!')
 *             self.error_type = error
 */
    }

    /* "srctools/_tokenizer.pyx":89
 *             if not issubclass(error, TokenSyntaxError):
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"' '!')
 *             self.error_type = error             # <<<<<<<<<<<<<<
 * 
 *         self.pushback_tok = self.pushback_val = None
 */
    __Pyx_INCREF(__pyx_v_error);
    __Pyx_GIVEREF(__pyx_v_error);
    __Pyx_GOTREF(__pyx_v_self->error_type);
    __Pyx_DECREF(__pyx_v_self->error_type);
    __pyx_v_self->error_type = __pyx_v_error;
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":91
 *             self.error_type = error
 * 
 *         self.pushback_tok = self.pushback_val = None             # <<<<<<<<<<<<<<
 *         self.line_num = 1
 * 
 */
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = Py_None;
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = Py_None;

  /* "srctools/_tokenizer.pyx":92
 * 
 *         self.pushback_tok = self.pushback_val = None
 *         self.line_num = 1             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
  __pyx_v_self->line_num = 1;

  /* "srctools/_tokenizer.pyx":78
 *     cdef public int line_num
 * 
 *     def __init__(self, filename, error):             # <<<<<<<<<<<<<<
 *         # Use os method to convert to string.
 *         # We know this isn't a method, so skip Cython's optimisation.
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":94
 *         self.line_num = 1
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__[] = "BaseTokenizer.__reduce__(self)\nDisallow pickling Tokenizers.\n\n        The files themselves usually are not pickleable, or are very\n        large strings.\n        There is also the issue with recreating the C/Python versions.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__ = {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "srctools/_tokenizer.pyx":101
 *         There is also the issue with recreating the C/Python versions.
 *         """
 *         raise TypeError('Cannot pickle Tokenizers!')             # <<<<<<<<<<<<<<
 * 
 *     def error(self, message, *args):
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 101, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":94
 *         self.line_num = 1
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":103
 *         raise TypeError('Cannot pickle Tokenizers!')
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_5error(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_4error[] = "BaseTokenizer.error(self, message, *args)\nRaise a syntax error exception.\n\n        This returns the TokenSyntaxError instance, with\n        line number and filename attributes filled in.\n        The message can be a Token to indicate a wrong token,\n        or a string which will be {}-formatted with the positional args\n        if they are present.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_5error = {"error", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_5error, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_4error};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_5error(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_message = 0;
  PyObject *__pyx_v_args = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("error (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 1) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 1, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return NULL;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_message,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_message)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t used_pos_args = (pos_args < 1) ? pos_args : 1;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, used_pos_args, "error") < 0)) __PYX_ERR(0, 103, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_message = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("error", 0, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 103, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_4error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_message, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_4error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_message, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  Py_UCS4 __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("error", 0);
  __Pyx_INCREF(__pyx_v_message);

  /* "srctools/_tokenizer.pyx":112
 *         if they are present.
 *         """
 *         if isinstance(message, Token):             # <<<<<<<<<<<<<<
 *             message = f'Unexpected token {message.name}' '!'
 *         elif args:
 */
  __pyx_t_1 = __pyx_v_8srctools_10_tokenizer_Token;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = PyObject_IsInstance(__pyx_v_message, __pyx_t_1); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 112, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "srctools/_tokenizer.pyx":113
 *         """
 *         if isinstance(message, Token):
 *             message = f'Unexpected token {message.name}' '!'             # <<<<<<<<<<<<<<
 *         elif args:
 *             message = message.format(*args)
 */
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = 0;
    __pyx_t_5 = 127;
    __Pyx_INCREF(__pyx_kp_u_Unexpected_token);
    __pyx_t_4 += 17;
    __Pyx_GIVEREF(__pyx_kp_u_Unexpected_token);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_kp_u_Unexpected_token);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_message, __pyx_n_s_name_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_FormatSimple(__pyx_t_6, __pyx_empty_unicode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_7);
    __pyx_t_7 = 0;
    __Pyx_INCREF(__pyx_kp_u__3);
    __pyx_t_4 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__3);
    PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_kp_u__3);
    __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_1, 3, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_message, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "srctools/_tokenizer.pyx":112
 *         if they are present.
 *         """
 *         if isinstance(message, Token):             # <<<<<<<<<<<<<<
 *             message = f'Unexpected token {message.name}' '!'
 *         elif args:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":114
 *         if isinstance(message, Token):
 *             message = f'Unexpected token {message.name}' '!'
 *         elif args:             # <<<<<<<<<<<<<<
 *             message = message.format(*args)
 *         return self._error(message)
 */
  __pyx_t_3 = (PyTuple_GET_SIZE(__pyx_v_args) != 0);
  if (__pyx_t_3) {

    /* "srctools/_tokenizer.pyx":115
 *             message = f'Unexpected token {message.name}' '!'
 *         elif args:
 *             message = message.format(*args)             # <<<<<<<<<<<<<<
 *         return self._error(message)
 * 
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_message, __pyx_n_s_format); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 115, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_v_args, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 115, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF_SET(__pyx_v_message, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":114
 *         if isinstance(message, Token):
 *             message = f'Unexpected token {message.name}' '!'
 *         elif args:             # <<<<<<<<<<<<<<
 *             message = message.format(*args)
 *         return self._error(message)
 */
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":116
 *         elif args:
 *             message = message.format(*args)
 *         return self._error(message)             # <<<<<<<<<<<<<<
 * 
 *     # Don't unpack, error_type should be a class.
 */
  __Pyx_XDECREF(__pyx_r);
  if (!(likely(PyUnicode_CheckExact(__pyx_v_message))||((__pyx_v_message) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_message)->tp_name), 0))) __PYX_ERR(0, 116, __pyx_L1_error)
  __pyx_t_1 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(__pyx_v_self, ((PyObject*)__pyx_v_message)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":103
 *         raise TypeError('Cannot pickle Tokenizers!')
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_message);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":120
 *     # Don't unpack, error_type should be a class.
 *     @cython.optimize.unpack_method_calls(False)
 *     cdef inline _error(self, str message):             # <<<<<<<<<<<<<<
 *         """C-private self.error()."""
 *         return self.error_type(
 */

static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_message) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_error", 0);

  /* "srctools/_tokenizer.pyx":122
 *     cdef inline _error(self, str message):
 *         """C-private self.error()."""
 *         return self.error_type(             # <<<<<<<<<<<<<<
 *             message,
 *             self.filename,
 */
  __Pyx_XDECREF(__pyx_r);

  /* "srctools/_tokenizer.pyx":125
 *             message,
 *             self.filename,
 *             self.line_num,             # <<<<<<<<<<<<<<
 *         )
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->line_num); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "srctools/_tokenizer.pyx":122
 *     cdef inline _error(self, str message):
 *         """C-private self.error()."""
 *         return self.error_type(             # <<<<<<<<<<<<<<
 *             message,
 *             self.filename,
 */
  __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 122, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_message);
  __Pyx_GIVEREF(__pyx_v_message);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_message);
  __Pyx_INCREF(__pyx_v_self->filename);
  __Pyx_GIVEREF(__pyx_v_self->filename);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_v_self->filename);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_v_self->error_type, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 122, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":120
 *     # Don't unpack, error_type should be a class.
 *     @cython.optimize.unpack_method_calls(False)
 *     cdef inline _error(self, str message):             # <<<<<<<<<<<<<<
 *         """C-private self.error()."""
 *         return self.error_type(
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer._error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":128
 *         )
 * 
 *     def __call__(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair."""
 *         return self.next_token()
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_6__call__[] = "Return the next token, value pair.";
#if CYTHON_COMPILING_IN_CPYTHON
struct wrapperbase __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_6__call__;
#endif
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__call__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__call__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return NULL;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__call__", 0))) return NULL;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_6__call__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_6__call__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__call__", 0);

  /* "srctools/_tokenizer.pyx":130
 *     def __call__(self):
 *         """Return the next token, value pair."""
 *         return self.next_token()             # <<<<<<<<<<<<<<
 * 
 *     cdef next_token(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":128
 *         )
 * 
 *     def __call__(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair."""
 *         return self.next_token()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__call__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":132
 *         return self.next_token()
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         raise NotImplementedError("Abstract method!")
 * 
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer_next_token(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("next_token", 0);

  /* "srctools/_tokenizer.pyx":133
 * 
 *     cdef next_token(self):
 *         raise NotImplementedError("Abstract method!")             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_NotImplementedError, __pyx_tuple__4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 133, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 133, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":132
 *         return self.next_token()
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         raise NotImplementedError("Abstract method!")
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":135
 *         raise NotImplementedError("Abstract method!")
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         # Call ourselves until EOF is returned
 *         return iter(self, EOF_TUP)
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9__iter__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9__iter__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8__iter__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8__iter__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__iter__", 0);

  /* "srctools/_tokenizer.pyx":137
 *     def __iter__(self):
 *         # Call ourselves until EOF is returned
 *         return iter(self, EOF_TUP)             # <<<<<<<<<<<<<<
 * 
 *     def push_back(self, object tok not None, str value=None):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_v_8srctools_10_tokenizer_EOF_TUP;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = PyCallIter_New(((PyObject *)__pyx_v_self), __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 137, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":135
 *         raise NotImplementedError("Abstract method!")
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         # Call ourselves until EOF is returned
 *         return iter(self, EOF_TUP)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__iter__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":139
 *         return iter(self, EOF_TUP)
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11push_back(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_10push_back[] = "BaseTokenizer.push_back(self, tok, unicode value=None)\nReturn a token, so it will be reproduced when called again.\n\n        Only one token can be pushed back at once.\n        The value is required for STRING, PAREN_ARGS and PROP_FLAGS, but ignored\n        for other token types.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_11push_back = {"push_back", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11push_back, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_10push_back};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11push_back(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_tok = 0;
  PyObject *__pyx_v_value = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("push_back (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,&__pyx_n_s_value,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject*)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_value);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "push_back") < 0)) __PYX_ERR(0, 139, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_tok = values[0];
    __pyx_v_value = ((PyObject*)values[1]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("push_back", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 139, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.push_back", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(((PyObject *)__pyx_v_tok) == Py_None)) {
    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "tok"); __PYX_ERR(0, 139, __pyx_L1_error)
  }
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_value), (&PyUnicode_Type), 1, "value", 1))) __PYX_ERR(0, 139, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10push_back(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_tok, __pyx_v_value);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10push_back(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_tok, PyObject *__pyx_v_value) {
  int __pyx_v_tok_val;
  CYTHON_UNUSED PyObject *__pyx_v_real_value = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  Py_UCS4 __pyx_t_7;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("push_back", 0);

  /* "srctools/_tokenizer.pyx":146
 *         for other token types.
 *         """
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 */
  __pyx_t_1 = (__pyx_v_self->pushback_tok != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (unlikely(__pyx_t_2)) {

    /* "srctools/_tokenizer.pyx":147
 *         """
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')             # <<<<<<<<<<<<<<
 *         if not isinstance(tok, Token):
 *             raise ValueError(repr(tok) + ' is not a Token!')
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 147, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 147, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":146
 *         for other token types.
 *         """
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 */
  }

  /* "srctools/_tokenizer.pyx":148
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):             # <<<<<<<<<<<<<<
 *             raise ValueError(repr(tok) + ' is not a Token!')
 * 
 */
  __pyx_t_3 = __pyx_v_8srctools_10_tokenizer_Token;
  __Pyx_INCREF(__pyx_t_3);
  __pyx_t_2 = PyObject_IsInstance(__pyx_v_tok, __pyx_t_3); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 148, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
  if (unlikely(__pyx_t_1)) {

    /* "srctools/_tokenizer.pyx":149
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 *             raise ValueError(repr(tok) + ' is not a Token!')             # <<<<<<<<<<<<<<
 * 
 *         # Read this directly to skip the 'value' descriptor.
 */
    __pyx_t_3 = PyObject_Repr(__pyx_v_tok); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 149, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyUnicode_ConcatSafe(__pyx_t_3, __pyx_kp_u_is_not_a_Token); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 149, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 149, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 149, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":148
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):             # <<<<<<<<<<<<<<
 *             raise ValueError(repr(tok) + ' is not a Token!')
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":152
 * 
 *         # Read this directly to skip the 'value' descriptor.
 *         cdef int tok_val = tok._value_             # <<<<<<<<<<<<<<
 *         cdef str real_value
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_tok, __pyx_n_s_value_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 152, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 152, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_tok_val = __pyx_t_5;

  /* "srctools/_tokenizer.pyx":155
 *         cdef str real_value
 * 
 *         if tok_val == 0: # EOF             # <<<<<<<<<<<<<<
 *             real_value = ''
 *         elif tok_val in (1, 3, 4, 5, 10):  # STRING, PAREN_ARGS, DIRECTIVE, BARE_STRING, PROP_FLAG
 */
  switch (__pyx_v_tok_val) {
    case 0:

    /* "srctools/_tokenizer.pyx":156
 * 
 *         if tok_val == 0: # EOF
 *             real_value = ''             # <<<<<<<<<<<<<<
 *         elif tok_val in (1, 3, 4, 5, 10):  # STRING, PAREN_ARGS, DIRECTIVE, BARE_STRING, PROP_FLAG
 *             # The value can be anything, so just accept this.
 */
    __Pyx_INCREF(__pyx_kp_u__6);
    __pyx_v_real_value = __pyx_kp_u__6;

    /* "srctools/_tokenizer.pyx":155
 *         cdef str real_value
 * 
 *         if tok_val == 0: # EOF             # <<<<<<<<<<<<<<
 *             real_value = ''
 *         elif tok_val in (1, 3, 4, 5, 10):  # STRING, PAREN_ARGS, DIRECTIVE, BARE_STRING, PROP_FLAG
 */
    break;
    case 1:

    /* "srctools/_tokenizer.pyx":157
 *         if tok_val == 0: # EOF
 *             real_value = ''
 *         elif tok_val in (1, 3, 4, 5, 10):  # STRING, PAREN_ARGS, DIRECTIVE, BARE_STRING, PROP_FLAG             # <<<<<<<<<<<<<<
 *             # The value can be anything, so just accept this.
 *             self.pushback_tok = tok
 */
    case 3:
    case 4:
    case 5:
    case 10:

    /* "srctools/_tokenizer.pyx":159
 *         elif tok_val in (1, 3, 4, 5, 10):  # STRING, PAREN_ARGS, DIRECTIVE, BARE_STRING, PROP_FLAG
 *             # The value can be anything, so just accept this.
 *             self.pushback_tok = tok             # <<<<<<<<<<<<<<
 *             self.pushback_val = value
 *             return
 */
    __Pyx_INCREF(__pyx_v_tok);
    __Pyx_GIVEREF(__pyx_v_tok);
    __Pyx_GOTREF(__pyx_v_self->pushback_tok);
    __Pyx_DECREF(__pyx_v_self->pushback_tok);
    __pyx_v_self->pushback_tok = __pyx_v_tok;

    /* "srctools/_tokenizer.pyx":160
 *             # The value can be anything, so just accept this.
 *             self.pushback_tok = tok
 *             self.pushback_val = value             # <<<<<<<<<<<<<<
 *             return
 *         elif tok_val == 2:  # NEWLINE
 */
    __Pyx_INCREF(__pyx_v_value);
    __Pyx_GIVEREF(__pyx_v_value);
    __Pyx_GOTREF(__pyx_v_self->pushback_val);
    __Pyx_DECREF(__pyx_v_self->pushback_val);
    __pyx_v_self->pushback_val = __pyx_v_value;

    /* "srctools/_tokenizer.pyx":161
 *             self.pushback_tok = tok
 *             self.pushback_val = value
 *             return             # <<<<<<<<<<<<<<
 *         elif tok_val == 2:  # NEWLINE
 *             real_value = '\n'
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":157
 *         if tok_val == 0: # EOF
 *             real_value = ''
 *         elif tok_val in (1, 3, 4, 5, 10):  # STRING, PAREN_ARGS, DIRECTIVE, BARE_STRING, PROP_FLAG             # <<<<<<<<<<<<<<
 *             # The value can be anything, so just accept this.
 *             self.pushback_tok = tok
 */
    break;
    case 2:

    /* "srctools/_tokenizer.pyx":163
 *             return
 *         elif tok_val == 2:  # NEWLINE
 *             real_value = '\n'             # <<<<<<<<<<<<<<
 *         elif tok_val == 6:  # BRACE_OPEN
 *             real_value = '{'
 */
    __Pyx_INCREF(__pyx_kp_u__7);
    __pyx_v_real_value = __pyx_kp_u__7;

    /* "srctools/_tokenizer.pyx":162
 *             self.pushback_val = value
 *             return
 *         elif tok_val == 2:  # NEWLINE             # <<<<<<<<<<<<<<
 *             real_value = '\n'
 *         elif tok_val == 6:  # BRACE_OPEN
 */
    break;
    case 6:

    /* "srctools/_tokenizer.pyx":165
 *             real_value = '\n'
 *         elif tok_val == 6:  # BRACE_OPEN
 *             real_value = '{'             # <<<<<<<<<<<<<<
 *         elif tok_val == 7:  # BRACE_CLOSE
 *             real_value = '}'
 */
    __Pyx_INCREF(__pyx_kp_u__8);
    __pyx_v_real_value = __pyx_kp_u__8;

    /* "srctools/_tokenizer.pyx":164
 *         elif tok_val == 2:  # NEWLINE
 *             real_value = '\n'
 *         elif tok_val == 6:  # BRACE_OPEN             # <<<<<<<<<<<<<<
 *             real_value = '{'
 *         elif tok_val == 7:  # BRACE_CLOSE
 */
    break;
    case 7:

    /* "srctools/_tokenizer.pyx":167
 *             real_value = '{'
 *         elif tok_val == 7:  # BRACE_CLOSE
 *             real_value = '}'             # <<<<<<<<<<<<<<
 *         elif tok_val == 11:  # BRACK_OPEN
 *             real_value = '['
 */
    __Pyx_INCREF(__pyx_kp_u__9);
    __pyx_v_real_value = __pyx_kp_u__9;

    /* "srctools/_tokenizer.pyx":166
 *         elif tok_val == 6:  # BRACE_OPEN
 *             real_value = '{'
 *         elif tok_val == 7:  # BRACE_CLOSE             # <<<<<<<<<<<<<<
 *             real_value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN
 */
    break;
    case 11:

    /* "srctools/_tokenizer.pyx":169
 *             real_value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN
 *             real_value = '['             # <<<<<<<<<<<<<<
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             real_value = ']'
 */
    __Pyx_INCREF(__pyx_kp_u__10);
    __pyx_v_real_value = __pyx_kp_u__10;

    /* "srctools/_tokenizer.pyx":168
 *         elif tok_val == 7:  # BRACE_CLOSE
 *             real_value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN             # <<<<<<<<<<<<<<
 *             real_value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE
 */
    break;
    case 12:

    /* "srctools/_tokenizer.pyx":171
 *             real_value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             real_value = ']'             # <<<<<<<<<<<<<<
 *         elif tok_val == 13:  # COLON
 *             real_value = ':'
 */
    __Pyx_INCREF(__pyx_kp_u__11);
    __pyx_v_real_value = __pyx_kp_u__11;

    /* "srctools/_tokenizer.pyx":170
 *         elif tok_val == 11:  # BRACK_OPEN
 *             real_value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE             # <<<<<<<<<<<<<<
 *             real_value = ']'
 *         elif tok_val == 13:  # COLON
 */
    break;
    case 13:

    /* "srctools/_tokenizer.pyx":173
 *             real_value = ']'
 *         elif tok_val == 13:  # COLON
 *             real_value = ':'             # <<<<<<<<<<<<<<
 *         elif tok_val == 14:  # EQUALS
 *             real_value = '='
 */
    __Pyx_INCREF(__pyx_kp_u__12);
    __pyx_v_real_value = __pyx_kp_u__12;

    /* "srctools/_tokenizer.pyx":172
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             real_value = ']'
 *         elif tok_val == 13:  # COLON             # <<<<<<<<<<<<<<
 *             real_value = ':'
 *         elif tok_val == 14:  # EQUALS
 */
    break;
    case 14:

    /* "srctools/_tokenizer.pyx":175
 *             real_value = ':'
 *         elif tok_val == 14:  # EQUALS
 *             real_value = '='             # <<<<<<<<<<<<<<
 *         elif tok_val == 15:  # PLUS
 *             real_value = '+'
 */
    __Pyx_INCREF(__pyx_kp_u__13);
    __pyx_v_real_value = __pyx_kp_u__13;

    /* "srctools/_tokenizer.pyx":174
 *         elif tok_val == 13:  # COLON
 *             real_value = ':'
 *         elif tok_val == 14:  # EQUALS             # <<<<<<<<<<<<<<
 *             real_value = '='
 *         elif tok_val == 15:  # PLUS
 */
    break;
    case 15:

    /* "srctools/_tokenizer.pyx":177
 *             real_value = '='
 *         elif tok_val == 15:  # PLUS
 *             real_value = '+'             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError(f'Unknown token {tok!r}')
 */
    __Pyx_INCREF(__pyx_kp_u__14);
    __pyx_v_real_value = __pyx_kp_u__14;

    /* "srctools/_tokenizer.pyx":176
 *         elif tok_val == 14:  # EQUALS
 *             real_value = '='
 *         elif tok_val == 15:  # PLUS             # <<<<<<<<<<<<<<
 *             real_value = '+'
 *         else:
 */
    break;
    default:

    /* "srctools/_tokenizer.pyx":179
 *             real_value = '+'
 *         else:
 *             raise ValueError(f'Unknown token {tok!r}')             # <<<<<<<<<<<<<<
 * 
 *         if value is None:
 */
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_tok), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 179, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyUnicode_Concat(__pyx_kp_u_Unknown_token, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 179, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 179, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 179, __pyx_L1_error)
    break;
  }

  /* "srctools/_tokenizer.pyx":181
 *             raise ValueError(f'Unknown token {tok!r}')
 * 
 *         if value is None:             # <<<<<<<<<<<<<<
 *             raise ValueError(f'Value required for {tok!r}' '!') from None
 * 
 */
  __pyx_t_1 = (__pyx_v_value == ((PyObject*)Py_None));
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (unlikely(__pyx_t_2)) {

    /* "srctools/_tokenizer.pyx":182
 * 
 *         if value is None:
 *             raise ValueError(f'Value required for {tok!r}' '!') from None             # <<<<<<<<<<<<<<
 * 
 *         self.pushback_tok = tok
 */
    __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 182, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = 0;
    __pyx_t_7 = 127;
    __Pyx_INCREF(__pyx_kp_u_Value_required_for);
    __pyx_t_6 += 19;
    __Pyx_GIVEREF(__pyx_kp_u_Value_required_for);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Value_required_for);
    __pyx_t_4 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_tok), __pyx_empty_unicode); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 182, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_4) > __pyx_t_7) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_4) : __pyx_t_7;
    __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_4);
    __pyx_t_4 = 0;
    __Pyx_INCREF(__pyx_kp_u__3);
    __pyx_t_6 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__3);
    PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__3);
    __pyx_t_4 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 182, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 182, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, Py_None);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 182, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":181
 *             raise ValueError(f'Unknown token {tok!r}')
 * 
 *         if value is None:             # <<<<<<<<<<<<<<
 *             raise ValueError(f'Value required for {tok!r}' '!') from None
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":184
 *             raise ValueError(f'Value required for {tok!r}' '!') from None
 * 
 *         self.pushback_tok = tok             # <<<<<<<<<<<<<<
 *         self.pushback_val = value
 * 
 */
  __Pyx_INCREF(__pyx_v_tok);
  __Pyx_GIVEREF(__pyx_v_tok);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = __pyx_v_tok;

  /* "srctools/_tokenizer.pyx":185
 * 
 *         self.pushback_tok = tok
 *         self.pushback_val = value             # <<<<<<<<<<<<<<
 * 
 *     def peek(self):
 */
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = __pyx_v_value;

  /* "srctools/_tokenizer.pyx":139
 *         return iter(self, EOF_TUP)
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.push_back", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_real_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":187
 *         self.pushback_val = value
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13peek(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_12peek[] = "BaseTokenizer.peek(self)\nPeek at the next token, without removing it from the stream.";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_13peek = {"peek", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13peek, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_12peek};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13peek(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("peek (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_12peek(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_12peek(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_v_tok_and_val = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("peek", 0);

  /* "srctools/_tokenizer.pyx":191
 *         # We know this is a valid pushback value, and any existing value was
 *         # just removed. So unconditionally assign.
 *         self.pushback_tok, self.pushback_val = tok_and_val = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         return tok_and_val
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 191, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_t_1;
  __Pyx_INCREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(__pyx_t_2 != Py_None)) {
    PyObject* sequence = __pyx_t_2;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 191, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
    __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
  } else {
    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 191, __pyx_L1_error)
  }
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = __pyx_t_1;
  __pyx_t_1 = 0;
  __Pyx_GIVEREF(__pyx_t_3);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = __pyx_t_3;
  __pyx_t_3 = 0;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_v_tok_and_val = ((PyObject*)__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":193
 *         self.pushback_tok, self.pushback_val = tok_and_val = <tuple>self.next_token()
 * 
 *         return tok_and_val             # <<<<<<<<<<<<<<
 * 
 *     def skipping_newlines(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_tok_and_val);
  __pyx_r = __pyx_v_tok_and_val;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":187
 *         self.pushback_val = value
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.peek", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tok_and_val);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":195
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_15skipping_newlines(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_14skipping_newlines[] = "BaseTokenizer.skipping_newlines(self)\nIterate over the tokens, skipping newlines.";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_15skipping_newlines = {"skipping_newlines", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_15skipping_newlines, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_14skipping_newlines};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_15skipping_newlines(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("skipping_newlines (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_14skipping_newlines(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_14skipping_newlines(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("skipping_newlines", 0);

  /* "srctools/_tokenizer.pyx":197
 *     def skipping_newlines(self):
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)             # <<<<<<<<<<<<<<
 * 
 *     def expect(self, object token, bint skip_newline=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)__pyx_v_self));
  __pyx_t_2 = ((PyObject *)__pyx_tp_new_8srctools_10_tokenizer__NewlinesIter(((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer__NewlinesIter), __pyx_t_1, NULL)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 197, __pyx_L1_error)
  __Pyx_GOTREF(((PyObject *)__pyx_t_2));
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = ((PyObject *)__pyx_t_2);
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":195
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.skipping_newlines", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":199
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_17expect(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_16expect[] = "BaseTokenizer.expect(self, token, bool skip_newline=True)\nConsume the next token, which should be the given type.\n\n        If it is not, this raises an error.\n        If skip_newline is true, newlines will be skipped over. This\n        does not apply if the desired token is newline.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_17expect = {"expect", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_17expect, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_16expect};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_17expect(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_token = 0;
  int __pyx_v_skip_newline;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("expect (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_token,&__pyx_n_s_skip_newline,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_token)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_skip_newline);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "expect") < 0)) __PYX_ERR(0, 199, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_token = values[0];
    if (values[1]) {
      __pyx_v_skip_newline = __Pyx_PyObject_IsTrue(values[1]); if (unlikely((__pyx_v_skip_newline == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 199, __pyx_L3_error)
    } else {
      __pyx_v_skip_newline = ((int)1);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("expect", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 199, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.expect", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_16expect(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_token, __pyx_v_skip_newline);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_16expect(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_token, int __pyx_v_skip_newline) {
  PyObject *__pyx_v_next_token = NULL;
  PyObject *__pyx_v_value = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  Py_ssize_t __pyx_t_7;
  Py_UCS4 __pyx_t_8;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("expect", 0);

  /* "srctools/_tokenizer.pyx":206
 *         does not apply if the desired token is newline.
 *         """
 *         if token is NEWLINE:             # <<<<<<<<<<<<<<
 *             skip_newline = False
 * 
 */
  __pyx_t_1 = (__pyx_v_token == __pyx_v_8srctools_10_tokenizer_NEWLINE);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":207
 *         """
 *         if token is NEWLINE:
 *             skip_newline = False             # <<<<<<<<<<<<<<
 * 
 *         next_token, value = <tuple>self.next_token()
 */
    __pyx_v_skip_newline = 0;

    /* "srctools/_tokenizer.pyx":206
 *         does not apply if the desired token is newline.
 *         """
 *         if token is NEWLINE:             # <<<<<<<<<<<<<<
 *             skip_newline = False
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":209
 *             skip_newline = False
 * 
 *         next_token, value = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         while skip_newline and next_token is NEWLINE:
 */
  __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __pyx_t_3;
  __Pyx_INCREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (likely(__pyx_t_4 != Py_None)) {
    PyObject* sequence = __pyx_t_4;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 209, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
    __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_5);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 209, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 209, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    #endif
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else {
    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 209, __pyx_L1_error)
  }
  __pyx_v_next_token = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_value = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "srctools/_tokenizer.pyx":211
 *         next_token, value = <tuple>self.next_token()
 * 
 *         while skip_newline and next_token is NEWLINE:             # <<<<<<<<<<<<<<
 *             next_token, value = <tuple>self.next_token()
 * 
 */
  while (1) {
    __pyx_t_1 = (__pyx_v_skip_newline != 0);
    if (__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_1 = (__pyx_v_next_token == __pyx_v_8srctools_10_tokenizer_NEWLINE);
    __pyx_t_6 = (__pyx_t_1 != 0);
    __pyx_t_2 = __pyx_t_6;
    __pyx_L6_bool_binop_done:;
    if (!__pyx_t_2) break;

    /* "srctools/_tokenizer.pyx":212
 * 
 *         while skip_newline and next_token is NEWLINE:
 *             next_token, value = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         if next_token is not token:
 */
    __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 212, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __pyx_t_4;
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (likely(__pyx_t_5 != Py_None)) {
      PyObject* sequence = __pyx_t_5;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 212, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_3);
      #else
      __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 212, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 212, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else {
      __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 212, __pyx_L1_error)
    }
    __Pyx_DECREF_SET(__pyx_v_next_token, __pyx_t_4);
    __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_t_3);
    __pyx_t_3 = 0;
  }

  /* "srctools/_tokenizer.pyx":214
 *             next_token, value = <tuple>self.next_token()
 * 
 *         if next_token is not token:             # <<<<<<<<<<<<<<
 *             raise self._error(f'Expected {token}, but got {next_token}' '!')
 *         return value
 */
  __pyx_t_2 = (__pyx_v_next_token != __pyx_v_token);
  __pyx_t_6 = (__pyx_t_2 != 0);
  if (unlikely(__pyx_t_6)) {

    /* "srctools/_tokenizer.pyx":215
 * 
 *         if next_token is not token:
 *             raise self._error(f'Expected {token}, but got {next_token}' '!')             # <<<<<<<<<<<<<<
 *         return value
 * 
 */
    __pyx_t_5 = PyTuple_New(5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 215, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = 0;
    __pyx_t_8 = 127;
    __Pyx_INCREF(__pyx_kp_u_Expected);
    __pyx_t_7 += 9;
    __Pyx_GIVEREF(__pyx_kp_u_Expected);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_kp_u_Expected);
    __pyx_t_3 = __Pyx_PyObject_FormatSimple(__pyx_v_token, __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 215, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_8;
    __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u_but_got);
    __pyx_t_7 += 10;
    __Pyx_GIVEREF(__pyx_kp_u_but_got);
    PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_kp_u_but_got);
    __pyx_t_3 = __Pyx_PyObject_FormatSimple(__pyx_v_next_token, __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 215, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_8;
    __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 3, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__3);
    __pyx_t_7 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__3);
    PyTuple_SET_ITEM(__pyx_t_5, 4, __pyx_kp_u__3);
    __pyx_t_3 = __Pyx_PyUnicode_Join(__pyx_t_5, 5, __pyx_t_7, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 215, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(__pyx_v_self, ((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 215, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(0, 215, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":214
 *             next_token, value = <tuple>self.next_token()
 * 
 *         if next_token is not token:             # <<<<<<<<<<<<<<
 *             raise self._error(f'Expected {token}, but got {next_token}' '!')
 *         return value
 */
  }

  /* "srctools/_tokenizer.pyx":216
 *         if next_token is not token:
 *             raise self._error(f'Expected {token}, but got {next_token}' '!')
 *         return value             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_value);
  __pyx_r = __pyx_v_value;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":199
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.expect", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_next_token);
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":71
 *     cdef object error_type
 * 
 *     cdef public str filename             # <<<<<<<<<<<<<<
 * 
 *     cdef object pushback_tok
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename___get__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->filename);
  __pyx_r = __pyx_v_self->filename;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);
  if (!(likely(PyUnicode_CheckExact(__pyx_v_value))||((__pyx_v_value) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_value)->tp_name), 0))) __PYX_ERR(0, 71, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_value;
  __Pyx_INCREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->filename);
  __Pyx_DECREF(__pyx_v_self->filename);
  __pyx_v_self->filename = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.filename.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_4__del__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_4__del__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->filename);
  __Pyx_DECREF(__pyx_v_self->filename);
  __pyx_v_self->filename = ((PyObject*)Py_None);

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":76
 *     cdef object pushback_val
 * 
 *     cdef public int line_num             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self, filename, error):
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num___get__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->line_num); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 76, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.line_num.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyInt_As_int(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 76, __pyx_L1_error)
  __pyx_v_self->line_num = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.line_num.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":247
 *     cdef Py_UCS4* val_buffer
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))
 *         self.buf_size = 32
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__cinit__", 0))) return -1;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "srctools/_tokenizer.pyx":248
 * 
 *     def __cinit__(self):
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))             # <<<<<<<<<<<<<<
 *         self.buf_size = 32
 *         self.buf_pos = 0
 */
  __pyx_v_self->val_buffer = ((Py_UCS4 *)PyMem_Malloc((32 * (sizeof(Py_UCS4)))));

  /* "srctools/_tokenizer.pyx":249
 *     def __cinit__(self):
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))
 *         self.buf_size = 32             # <<<<<<<<<<<<<<
 *         self.buf_pos = 0
 * 
 */
  __pyx_v_self->buf_size = 32;

  /* "srctools/_tokenizer.pyx":250
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))
 *         self.buf_size = 32
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(self):
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":247
 *     cdef Py_UCS4* val_buffer
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         self.val_buffer = <Py_UCS4 *>PyMem_Malloc(32 * sizeof(Py_UCS4))
 *         self.buf_size = 32
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":252
 *         self.buf_pos = 0
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         PyMem_Free(self.val_buffer)
 * 
 */

/* Python wrapper */
static void __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "srctools/_tokenizer.pyx":253
 * 
 *     def __dealloc__(self):
 *         PyMem_Free(self.val_buffer)             # <<<<<<<<<<<<<<
 * 
 *     def __init__(
 */
  PyMem_Free(__pyx_v_self->val_buffer);

  /* "srctools/_tokenizer.pyx":252
 *         self.buf_pos = 0
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         PyMem_Free(self.val_buffer)
 * 
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":255
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_data = 0;
  PyObject *__pyx_v_filename = 0;
  PyObject *__pyx_v_error = 0;
  int __pyx_v_string_bracket;
  int __pyx_v_allow_escapes;
  int __pyx_v_allow_star_comments;
  int __pyx_v_mark_bare_strings;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_data,&__pyx_n_s_filename,&__pyx_n_s_error,&__pyx_n_s_string_bracket,&__pyx_n_s_allow_escapes,&__pyx_n_s_allow_star_comments,&__pyx_n_s_mark_bare_strings,0};
    PyObject* values[7] = {0,0,0,0,0,0,0};

    /* "srctools/_tokenizer.pyx":258
 *         self,
 *         data not None,
 *         object filename=None,             # <<<<<<<<<<<<<<
 *         error=None,
 *         bint string_bracket=False,
 */
    values[1] = ((PyObject *)Py_None);

    /* "srctools/_tokenizer.pyx":259
 *         data not None,
 *         object filename=None,
 *         error=None,             # <<<<<<<<<<<<<<
 *         bint string_bracket=False,
 *         bint allow_escapes=True,
 */
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_data)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_filename);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_error);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_string_bracket);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_allow_escapes);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_allow_star_comments);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_mark_bare_strings);
          if (value) { values[6] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 255, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_data = values[0];
    __pyx_v_filename = values[1];
    __pyx_v_error = values[2];
    if (values[3]) {
      __pyx_v_string_bracket = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_string_bracket == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 260, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":260
 *         object filename=None,
 *         error=None,
 *         bint string_bracket=False,             # <<<<<<<<<<<<<<
 *         bint allow_escapes=True,
 *         bint allow_star_comments=False,
 */
      __pyx_v_string_bracket = ((int)0);
    }
    if (values[4]) {
      __pyx_v_allow_escapes = __Pyx_PyObject_IsTrue(values[4]); if (unlikely((__pyx_v_allow_escapes == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 261, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":261
 *         error=None,
 *         bint string_bracket=False,
 *         bint allow_escapes=True,             # <<<<<<<<<<<<<<
 *         bint allow_star_comments=False,
 *         bint mark_bare_strings=False,
 */
      __pyx_v_allow_escapes = ((int)1);
    }
    if (values[5]) {
      __pyx_v_allow_star_comments = __Pyx_PyObject_IsTrue(values[5]); if (unlikely((__pyx_v_allow_star_comments == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 262, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":262
 *         bint string_bracket=False,
 *         bint allow_escapes=True,
 *         bint allow_star_comments=False,             # <<<<<<<<<<<<<<
 *         bint mark_bare_strings=False,
 *     ):
 */
      __pyx_v_allow_star_comments = ((int)0);
    }
    if (values[6]) {
      __pyx_v_mark_bare_strings = __Pyx_PyObject_IsTrue(values[6]); if (unlikely((__pyx_v_mark_bare_strings == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 263, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":263
 *         bint allow_escapes=True,
 *         bint allow_star_comments=False,
 *         bint mark_bare_strings=False,             # <<<<<<<<<<<<<<
 *     ):
 *         # Early warning for this particular error.
 */
      __pyx_v_mark_bare_strings = ((int)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 0, 1, 7, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 255, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(((PyObject *)__pyx_v_data) == Py_None)) {
    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "data"); __PYX_ERR(0, 257, __pyx_L1_error)
  }
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_data, __pyx_v_filename, __pyx_v_error, __pyx_v_string_bracket, __pyx_v_allow_escapes, __pyx_v_allow_star_comments, __pyx_v_mark_bare_strings);

  /* "srctools/_tokenizer.pyx":255
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_data, PyObject *__pyx_v_filename, PyObject *__pyx_v_error, int __pyx_v_string_bracket, int __pyx_v_allow_escapes, int __pyx_v_allow_star_comments, int __pyx_v_mark_bare_strings) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);
  __Pyx_INCREF(__pyx_v_filename);

  /* "srctools/_tokenizer.pyx":266
 *     ):
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):             # <<<<<<<<<<<<<<
 *             raise TypeError(
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 */
  __pyx_t_2 = PyBytes_Check(__pyx_v_data); 
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (!__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = PyByteArray_Check(__pyx_v_data); 
  __pyx_t_2 = (__pyx_t_3 != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L4_bool_binop_done:;
  if (unlikely(__pyx_t_1)) {

    /* "srctools/_tokenizer.pyx":267
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):
 *             raise TypeError(             # <<<<<<<<<<<<<<
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 *                 'or wrap in io.TextIOWrapper() to decode gradually.'
 */
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__15, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 267, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 267, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":266
 *     ):
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):             # <<<<<<<<<<<<<<
 *             raise TypeError(
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 */
  }

  /* "srctools/_tokenizer.pyx":274
 *         # For direct strings, we can immediately assign that as our chunk,
 *         # and then set the iterable to an empty iterator.
 *         if isinstance(data, str):             # <<<<<<<<<<<<<<
 *             self.cur_chunk = data
 *             self.chunk_iter = EMPTY_ITER
 */
  __pyx_t_1 = PyUnicode_Check(__pyx_v_data); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":275
 *         # and then set the iterable to an empty iterator.
 *         if isinstance(data, str):
 *             self.cur_chunk = data             # <<<<<<<<<<<<<<
 *             self.chunk_iter = EMPTY_ITER
 *         else:
 */
    if (!(likely(PyUnicode_CheckExact(__pyx_v_data))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_data)->tp_name), 0))) __PYX_ERR(0, 275, __pyx_L1_error)
    __pyx_t_4 = __pyx_v_data;
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __Pyx_GOTREF(__pyx_v_self->cur_chunk);
    __Pyx_DECREF(__pyx_v_self->cur_chunk);
    __pyx_v_self->cur_chunk = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;

    /* "srctools/_tokenizer.pyx":276
 *         if isinstance(data, str):
 *             self.cur_chunk = data
 *             self.chunk_iter = EMPTY_ITER             # <<<<<<<<<<<<<<
 *         else:
 *             # The first next_char() call will pull out a chunk.
 */
    __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EMPTY_ITER);
    __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_EMPTY_ITER);
    __Pyx_GOTREF(__pyx_v_self->chunk_iter);
    __Pyx_DECREF(__pyx_v_self->chunk_iter);
    __pyx_v_self->chunk_iter = __pyx_v_8srctools_10_tokenizer_EMPTY_ITER;

    /* "srctools/_tokenizer.pyx":274
 *         # For direct strings, we can immediately assign that as our chunk,
 *         # and then set the iterable to an empty iterator.
 *         if isinstance(data, str):             # <<<<<<<<<<<<<<
 *             self.cur_chunk = data
 *             self.chunk_iter = EMPTY_ITER
 */
    goto __pyx_L6;
  }

  /* "srctools/_tokenizer.pyx":279
 *         else:
 *             # The first next_char() call will pull out a chunk.
 *             self.cur_chunk = ''             # <<<<<<<<<<<<<<
 *             # This checks that it is indeed iterable.
 *             self.chunk_iter = iter(data)
 */
  /*else*/ {
    __Pyx_INCREF(__pyx_kp_u__6);
    __Pyx_GIVEREF(__pyx_kp_u__6);
    __Pyx_GOTREF(__pyx_v_self->cur_chunk);
    __Pyx_DECREF(__pyx_v_self->cur_chunk);
    __pyx_v_self->cur_chunk = __pyx_kp_u__6;

    /* "srctools/_tokenizer.pyx":281
 *             self.cur_chunk = ''
 *             # This checks that it is indeed iterable.
 *             self.chunk_iter = iter(data)             # <<<<<<<<<<<<<<
 * 
 *         # We initially add one, so it'll be 0 next.
 */
    __pyx_t_4 = PyObject_GetIter(__pyx_v_data); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 281, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __Pyx_GOTREF(__pyx_v_self->chunk_iter);
    __Pyx_DECREF(__pyx_v_self->chunk_iter);
    __pyx_v_self->chunk_iter = __pyx_t_4;
    __pyx_t_4 = 0;
  }
  __pyx_L6:;

  /* "srctools/_tokenizer.pyx":284
 * 
 *         # We initially add one, so it'll be 0 next.
 *         self.char_index = -1             # <<<<<<<<<<<<<<
 * 
 *         self.buf_reset()
 */
  __pyx_v_self->char_index = -1;

  /* "srctools/_tokenizer.pyx":286
 *         self.char_index = -1
 * 
 *         self.buf_reset()             # <<<<<<<<<<<<<<
 * 
 *         if not filename:
 */
  __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

  /* "srctools/_tokenizer.pyx":288
 *         self.buf_reset()
 * 
 *         if not filename:             # <<<<<<<<<<<<<<
 *             # If we're given a file-like object, automatically set the filename.
 *             try:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_filename); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 288, __pyx_L1_error)
  __pyx_t_1 = ((!__pyx_t_2) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":290
 *         if not filename:
 *             # If we're given a file-like object, automatically set the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 filename = data.name
 *             except AttributeError:
 */
    {
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __Pyx_ExceptionSave(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7);
      __Pyx_XGOTREF(__pyx_t_5);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_7);
      /*try:*/ {

        /* "srctools/_tokenizer.pyx":291
 *             # If we're given a file-like object, automatically set the filename.
 *             try:
 *                 filename = data.name             # <<<<<<<<<<<<<<
 *             except AttributeError:
 *                 # If not, a Falsey filename means nothing is added to any
 */
        __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_data, __pyx_n_s_name_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 291, __pyx_L8_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF_SET(__pyx_v_filename, __pyx_t_4);
        __pyx_t_4 = 0;

        /* "srctools/_tokenizer.pyx":290
 *         if not filename:
 *             # If we're given a file-like object, automatically set the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 filename = data.name
 *             except AttributeError:
 */
      }
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      goto __pyx_L13_try_end;
      __pyx_L8_error:;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "srctools/_tokenizer.pyx":292
 *             try:
 *                 filename = data.name
 *             except AttributeError:             # <<<<<<<<<<<<<<
 *                 # If not, a Falsey filename means nothing is added to any
 *                 # KV exception message.
 */
      __pyx_t_8 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_AttributeError);
      if (__pyx_t_8) {
        __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
        if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_9, &__pyx_t_10) < 0) __PYX_ERR(0, 292, __pyx_L10_except_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_GOTREF(__pyx_t_9);
        __Pyx_GOTREF(__pyx_t_10);

        /* "srctools/_tokenizer.pyx":295
 *                 # If not, a Falsey filename means nothing is added to any
 *                 # KV exception message.
 *                 filename = ''             # <<<<<<<<<<<<<<
 * 
 *         BaseTokenizer.__init__(self, filename, error)
 */
        __Pyx_INCREF(__pyx_kp_u__6);
        __Pyx_DECREF_SET(__pyx_v_filename, __pyx_kp_u__6);
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        goto __pyx_L9_exception_handled;
      }
      goto __pyx_L10_except_error;
      __pyx_L10_except_error:;

      /* "srctools/_tokenizer.pyx":290
 *         if not filename:
 *             # If we're given a file-like object, automatically set the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 filename = data.name
 *             except AttributeError:
 */
      __Pyx_XGIVEREF(__pyx_t_5);
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_ExceptionReset(__pyx_t_5, __pyx_t_6, __pyx_t_7);
      goto __pyx_L1_error;
      __pyx_L9_exception_handled:;
      __Pyx_XGIVEREF(__pyx_t_5);
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_ExceptionReset(__pyx_t_5, __pyx_t_6, __pyx_t_7);
      __pyx_L13_try_end:;
    }

    /* "srctools/_tokenizer.pyx":288
 *         self.buf_reset()
 * 
 *         if not filename:             # <<<<<<<<<<<<<<
 *             # If we're given a file-like object, automatically set the filename.
 *             try:
 */
  }

  /* "srctools/_tokenizer.pyx":297
 *                 filename = ''
 * 
 *         BaseTokenizer.__init__(self, filename, error)             # <<<<<<<<<<<<<<
 * 
 *         self.string_bracket = string_bracket
 */
  __pyx_t_9 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer), __pyx_n_s_init); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 297, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __pyx_t_4 = NULL;
  __pyx_t_8 = 0;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_9))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_9);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_9, function);
      __pyx_t_8 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_9)) {
    PyObject *__pyx_temp[4] = {__pyx_t_4, ((PyObject *)__pyx_v_self), __pyx_v_filename, __pyx_v_error};
    __pyx_t_10 = __Pyx_PyFunction_FastCall(__pyx_t_9, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_10);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_9)) {
    PyObject *__pyx_temp[4] = {__pyx_t_4, ((PyObject *)__pyx_v_self), __pyx_v_filename, __pyx_v_error};
    __pyx_t_10 = __Pyx_PyCFunction_FastCall(__pyx_t_9, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_10);
  } else
  #endif
  {
    __pyx_t_11 = PyTuple_New(3+__pyx_t_8); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_11, 0+__pyx_t_8, ((PyObject *)__pyx_v_self));
    __Pyx_INCREF(__pyx_v_filename);
    __Pyx_GIVEREF(__pyx_v_filename);
    PyTuple_SET_ITEM(__pyx_t_11, 1+__pyx_t_8, __pyx_v_filename);
    __Pyx_INCREF(__pyx_v_error);
    __Pyx_GIVEREF(__pyx_v_error);
    PyTuple_SET_ITEM(__pyx_t_11, 2+__pyx_t_8, __pyx_v_error);
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_9, __pyx_t_11, NULL); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  }
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

  /* "srctools/_tokenizer.pyx":299
 *         BaseTokenizer.__init__(self, filename, error)
 * 
 *         self.string_bracket = string_bracket             # <<<<<<<<<<<<<<
 *         self.allow_escapes = allow_escapes
 *         self.allow_star_comments = allow_star_comments
 */
  __pyx_v_self->string_bracket = __pyx_v_string_bracket;

  /* "srctools/_tokenizer.pyx":300
 * 
 *         self.string_bracket = string_bracket
 *         self.allow_escapes = allow_escapes             # <<<<<<<<<<<<<<
 *         self.allow_star_comments = allow_star_comments
 *         self.mark_bare_strings = mark_bare_strings
 */
  __pyx_v_self->allow_escapes = __pyx_v_allow_escapes;

  /* "srctools/_tokenizer.pyx":301
 *         self.string_bracket = string_bracket
 *         self.allow_escapes = allow_escapes
 *         self.allow_star_comments = allow_star_comments             # <<<<<<<<<<<<<<
 *         self.mark_bare_strings = mark_bare_strings
 * 
 */
  __pyx_v_self->allow_star_comments = __pyx_v_allow_star_comments;

  /* "srctools/_tokenizer.pyx":302
 *         self.allow_escapes = allow_escapes
 *         self.allow_star_comments = allow_star_comments
 *         self.mark_bare_strings = mark_bare_strings             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_v_self->mark_bare_strings = __pyx_v_mark_bare_strings;

  /* "srctools/_tokenizer.pyx":255
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_filename);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":305
 * 
 * 
 *     cdef inline void buf_reset(self):             # <<<<<<<<<<<<<<
 *         """Reset the temporary buffer."""
 *         # Don't bother resizing or clearing, the next append will overwrite.
 */

static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("buf_reset", 0);

  /* "srctools/_tokenizer.pyx":308
 *         """Reset the temporary buffer."""
 *         # Don't bother resizing or clearing, the next append will overwrite.
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 * 
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":305
 * 
 * 
 *     cdef inline void buf_reset(self):             # <<<<<<<<<<<<<<
 *         """Reset the temporary buffer."""
 *         # Don't bother resizing or clearing, the next append will overwrite.
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":310
 *         self.buf_pos = 0
 * 
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):             # <<<<<<<<<<<<<<
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:
 */

static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, Py_UCS4 __pyx_v_uchar) {
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("buf_add_char", 0);

  /* "srctools/_tokenizer.pyx":312
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:             # <<<<<<<<<<<<<<
 *             self.buf_size *= 2
 *             self.val_buffer = <Py_UCS4 *>PyMem_Realloc(
 */
  __pyx_t_1 = ((__pyx_v_self->buf_pos >= __pyx_v_self->buf_size) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":313
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:
 *             self.buf_size *= 2             # <<<<<<<<<<<<<<
 *             self.val_buffer = <Py_UCS4 *>PyMem_Realloc(
 *                 self.val_buffer,
 */
    __pyx_v_self->buf_size = (__pyx_v_self->buf_size * 2);

    /* "srctools/_tokenizer.pyx":314
 *         if self.buf_pos >= self.buf_size:
 *             self.buf_size *= 2
 *             self.val_buffer = <Py_UCS4 *>PyMem_Realloc(             # <<<<<<<<<<<<<<
 *                 self.val_buffer,
 *                 self.buf_size * sizeof(Py_UCS4),
 */
    __pyx_v_self->val_buffer = ((Py_UCS4 *)PyMem_Realloc(__pyx_v_self->val_buffer, (__pyx_v_self->buf_size * (sizeof(Py_UCS4)))));

    /* "srctools/_tokenizer.pyx":312
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:             # <<<<<<<<<<<<<<
 *             self.buf_size *= 2
 *             self.val_buffer = <Py_UCS4 *>PyMem_Realloc(
 */
  }

  /* "srctools/_tokenizer.pyx":318
 *                 self.buf_size * sizeof(Py_UCS4),
 *             )
 *         self.val_buffer[self.buf_pos] = uchar             # <<<<<<<<<<<<<<
 *         self.buf_pos += 1
 * 
 */
  (__pyx_v_self->val_buffer[__pyx_v_self->buf_pos]) = __pyx_v_uchar;

  /* "srctools/_tokenizer.pyx":319
 *             )
 *         self.val_buffer[self.buf_pos] = uchar
 *         self.buf_pos += 1             # <<<<<<<<<<<<<<
 * 
 *     cdef object buf_get_text(self):
 */
  __pyx_v_self->buf_pos = (__pyx_v_self->buf_pos + 1);

  /* "srctools/_tokenizer.pyx":310
 *         self.buf_pos = 0
 * 
 *     cdef inline void buf_add_char(self, Py_UCS4 uchar):             # <<<<<<<<<<<<<<
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         if self.buf_pos >= self.buf_size:
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":321
 *         self.buf_pos += 1
 * 
 *     cdef object buf_get_text(self):             # <<<<<<<<<<<<<<
 *         """Decode the buffer, and return the text."""
 *         # Convert the buffer directly to a string. 4 = UCS4 mode.
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_out = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("buf_get_text", 0);

  /* "srctools/_tokenizer.pyx":324
 *         """Decode the buffer, and return the text."""
 *         # Convert the buffer directly to a string. 4 = UCS4 mode.
 *         out = PyUnicode_FromKindAndData(4, self.val_buffer, self.buf_pos)             # <<<<<<<<<<<<<<
 *         # Don't bother resizing or clearing, the next append will overwrite.
 *         self.buf_pos = 0
 */
  __pyx_t_1 = PyUnicode_FromKindAndData(4, __pyx_v_self->val_buffer, __pyx_v_self->buf_pos); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 324, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_out = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":326
 *         out = PyUnicode_FromKindAndData(4, self.val_buffer, self.buf_pos)
 *         # Don't bother resizing or clearing, the next append will overwrite.
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 *         return out
 * 
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":327
 *         # Don't bother resizing or clearing, the next append will overwrite.
 *         self.buf_pos = 0
 *         return out             # <<<<<<<<<<<<<<
 * 
 *     # We check all the getitem[] accesses, so don't have Cython recheck.
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_out);
  __pyx_r = __pyx_v_out;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":321
 *         self.buf_pos += 1
 * 
 *     cdef object buf_get_text(self):             # <<<<<<<<<<<<<<
 *         """Decode the buffer, and return the text."""
 *         # Convert the buffer directly to a string. 4 = UCS4 mode.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.buf_get_text", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_out);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":332
 *     @cython.boundscheck(False)
 *     @cython.wraparound(False)
 *     cdef Py_UCS4 _next_char(self) except -2:             # <<<<<<<<<<<<<<
 *         """Return the next character, or -1 if no more characters are there."""
 *         cdef str chunk
 */

static Py_UCS4 __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_chunk = 0;
  PyObject *__pyx_v_chunk_obj = 0;
  PyObject *__pyx_v_exc = NULL;
  Py_UCS4 __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  Py_UCS4 __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  char const *__pyx_t_13;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  PyObject *__pyx_t_19 = NULL;
  int __pyx_t_20;
  char const *__pyx_t_21;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_next_char", 0);

  /* "srctools/_tokenizer.pyx":337
 *         cdef object chunk_obj
 * 
 *         self.char_index += 1             # <<<<<<<<<<<<<<
 *         if self.char_index < len(self.cur_chunk):
 *             return self.cur_chunk[self.char_index]
 */
  __pyx_v_self->char_index = (__pyx_v_self->char_index + 1);

  /* "srctools/_tokenizer.pyx":338
 * 
 *         self.char_index += 1
 *         if self.char_index < len(self.cur_chunk):             # <<<<<<<<<<<<<<
 *             return self.cur_chunk[self.char_index]
 * 
 */
  __pyx_t_1 = __pyx_v_self->cur_chunk;
  __Pyx_INCREF(__pyx_t_1);
  if (unlikely(__pyx_t_1 == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 338, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyUnicode_GET_LENGTH(__pyx_t_1); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 338, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = ((__pyx_v_self->char_index < __pyx_t_2) != 0);
  if (__pyx_t_3) {

    /* "srctools/_tokenizer.pyx":339
 *         self.char_index += 1
 *         if self.char_index < len(self.cur_chunk):
 *             return self.cur_chunk[self.char_index]             # <<<<<<<<<<<<<<
 * 
 *         # Retrieve a chunk from the iterable.
 */
    __pyx_t_4 = __Pyx_GetItemInt_Unicode(__pyx_v_self->cur_chunk, __pyx_v_self->char_index, int, 1, __Pyx_PyInt_From_int, 0, 0, 0); if (unlikely(__pyx_t_4 == (Py_UCS4)-1)) __PYX_ERR(0, 339, __pyx_L1_error)
    __pyx_r = __pyx_t_4;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":338
 * 
 *         self.char_index += 1
 *         if self.char_index < len(self.cur_chunk):             # <<<<<<<<<<<<<<
 *             return self.cur_chunk[self.char_index]
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":342
 * 
 *         # Retrieve a chunk from the iterable.
 *         try:             # <<<<<<<<<<<<<<
 *             chunk_obj = next(self.chunk_iter, None)
 *         except UnicodeDecodeError as exc:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7);
    __Pyx_XGOTREF(__pyx_t_5);
    __Pyx_XGOTREF(__pyx_t_6);
    __Pyx_XGOTREF(__pyx_t_7);
    /*try:*/ {

      /* "srctools/_tokenizer.pyx":343
 *         # Retrieve a chunk from the iterable.
 *         try:
 *             chunk_obj = next(self.chunk_iter, None)             # <<<<<<<<<<<<<<
 *         except UnicodeDecodeError as exc:
 *             raise self._error("Could not decode file!") from exc
 */
      __pyx_t_1 = __pyx_v_self->chunk_iter;
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_8 = __Pyx_PyIter_Next2(__pyx_t_1, Py_None); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 343, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_chunk_obj = __pyx_t_8;
      __pyx_t_8 = 0;

      /* "srctools/_tokenizer.pyx":342
 * 
 *         # Retrieve a chunk from the iterable.
 *         try:             # <<<<<<<<<<<<<<
 *             chunk_obj = next(self.chunk_iter, None)
 *         except UnicodeDecodeError as exc:
 */
    }
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    goto __pyx_L9_try_end;
    __pyx_L4_error:;
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "srctools/_tokenizer.pyx":344
 *         try:
 *             chunk_obj = next(self.chunk_iter, None)
 *         except UnicodeDecodeError as exc:             # <<<<<<<<<<<<<<
 *             raise self._error("Could not decode file!") from exc
 *         if chunk_obj is None:
 */
    __pyx_t_9 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_UnicodeDecodeError);
    if (__pyx_t_9) {
      __Pyx_AddTraceback("srctools._tokenizer.Tokenizer._next_char", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_8, &__pyx_t_1, &__pyx_t_10) < 0) __PYX_ERR(0, 344, __pyx_L6_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GOTREF(__pyx_t_10);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_v_exc = __pyx_t_1;
      /*try:*/ {

        /* "srctools/_tokenizer.pyx":345
 *             chunk_obj = next(self.chunk_iter, None)
 *         except UnicodeDecodeError as exc:
 *             raise self._error("Could not decode file!") from exc             # <<<<<<<<<<<<<<
 *         if chunk_obj is None:
 *             return -1
 */
        __pyx_t_11 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Could_not_decode_file); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 345, __pyx_L15_error)
        __Pyx_GOTREF(__pyx_t_11);
        __Pyx_Raise(__pyx_t_11, 0, 0, __pyx_v_exc);
        __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        __PYX_ERR(0, 345, __pyx_L15_error)
      }

      /* "srctools/_tokenizer.pyx":344
 *         try:
 *             chunk_obj = next(self.chunk_iter, None)
 *         except UnicodeDecodeError as exc:             # <<<<<<<<<<<<<<
 *             raise self._error("Could not decode file!") from exc
 *         if chunk_obj is None:
 */
      /*finally:*/ {
        __pyx_L15_error:;
        /*exception exit:*/{
          __Pyx_PyThreadState_declare
          __Pyx_PyThreadState_assign
          __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
          __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
          if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_17, &__pyx_t_18, &__pyx_t_19);
          if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16) < 0)) __Pyx_ErrFetch(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
          __Pyx_XGOTREF(__pyx_t_14);
          __Pyx_XGOTREF(__pyx_t_15);
          __Pyx_XGOTREF(__pyx_t_16);
          __Pyx_XGOTREF(__pyx_t_17);
          __Pyx_XGOTREF(__pyx_t_18);
          __Pyx_XGOTREF(__pyx_t_19);
          __pyx_t_9 = __pyx_lineno; __pyx_t_12 = __pyx_clineno; __pyx_t_13 = __pyx_filename;
          {
            __Pyx_DECREF(__pyx_v_exc);
            __pyx_v_exc = NULL;
          }
          if (PY_MAJOR_VERSION >= 3) {
            __Pyx_XGIVEREF(__pyx_t_17);
            __Pyx_XGIVEREF(__pyx_t_18);
            __Pyx_XGIVEREF(__pyx_t_19);
            __Pyx_ExceptionReset(__pyx_t_17, __pyx_t_18, __pyx_t_19);
          }
          __Pyx_XGIVEREF(__pyx_t_14);
          __Pyx_XGIVEREF(__pyx_t_15);
          __Pyx_XGIVEREF(__pyx_t_16);
          __Pyx_ErrRestore(__pyx_t_14, __pyx_t_15, __pyx_t_16);
          __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
          __pyx_lineno = __pyx_t_9; __pyx_clineno = __pyx_t_12; __pyx_filename = __pyx_t_13;
          goto __pyx_L6_except_error;
        }
      }
    }
    goto __pyx_L6_except_error;
    __pyx_L6_except_error:;

    /* "srctools/_tokenizer.pyx":342
 * 
 *         # Retrieve a chunk from the iterable.
 *         try:             # <<<<<<<<<<<<<<
 *             chunk_obj = next(self.chunk_iter, None)
 *         except UnicodeDecodeError as exc:
 */
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_ExceptionReset(__pyx_t_5, __pyx_t_6, __pyx_t_7);
    goto __pyx_L1_error;
    __pyx_L9_try_end:;
  }

  /* "srctools/_tokenizer.pyx":346
 *         except UnicodeDecodeError as exc:
 *             raise self._error("Could not decode file!") from exc
 *         if chunk_obj is None:             # <<<<<<<<<<<<<<
 *             return -1
 * 
 */
  __pyx_t_3 = (__pyx_v_chunk_obj == Py_None);
  __pyx_t_20 = (__pyx_t_3 != 0);
  if (__pyx_t_20) {

    /* "srctools/_tokenizer.pyx":347
 *             raise self._error("Could not decode file!") from exc
 *         if chunk_obj is None:
 *             return -1             # <<<<<<<<<<<<<<
 * 
 *         if isinstance(chunk_obj, bytes):
 */
    __pyx_r = -1;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":346
 *         except UnicodeDecodeError as exc:
 *             raise self._error("Could not decode file!") from exc
 *         if chunk_obj is None:             # <<<<<<<<<<<<<<
 *             return -1
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":349
 *             return -1
 * 
 *         if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):
 */
  __pyx_t_20 = PyBytes_Check(__pyx_v_chunk_obj); 
  __pyx_t_3 = (__pyx_t_20 != 0);
  if (unlikely(__pyx_t_3)) {

    /* "srctools/_tokenizer.pyx":350
 * 
 *         if isinstance(chunk_obj, bytes):
 *             raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *         if not isinstance(chunk_obj, str):
 *             raise ValueError("Data was not a string!")
 */
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__16, NULL); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 350, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_Raise(__pyx_t_10, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __PYX_ERR(0, 350, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":349
 *             return -1
 * 
 *         if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):
 */
  }

  /* "srctools/_tokenizer.pyx":351
 *         if isinstance(chunk_obj, bytes):
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):             # <<<<<<<<<<<<<<
 *             raise ValueError("Data was not a string!")
 * 
 */
  __pyx_t_3 = PyUnicode_Check(__pyx_v_chunk_obj); 
  __pyx_t_20 = ((!(__pyx_t_3 != 0)) != 0);
  if (unlikely(__pyx_t_20)) {

    /* "srctools/_tokenizer.pyx":352
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):
 *             raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *         self.cur_chunk = chunk = <str>chunk_obj
 */
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__17, NULL); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 352, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_Raise(__pyx_t_10, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __PYX_ERR(0, 352, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":351
 *         if isinstance(chunk_obj, bytes):
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):             # <<<<<<<<<<<<<<
 *             raise ValueError("Data was not a string!")
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":354
 *             raise ValueError("Data was not a string!")
 * 
 *         self.cur_chunk = chunk = <str>chunk_obj             # <<<<<<<<<<<<<<
 *         self.char_index = 0
 * 
 */
  __pyx_t_10 = __pyx_v_chunk_obj;
  __Pyx_INCREF(__pyx_t_10);
  __Pyx_INCREF(__pyx_t_10);
  __Pyx_GIVEREF(__pyx_t_10);
  __Pyx_GOTREF(__pyx_v_self->cur_chunk);
  __Pyx_DECREF(__pyx_v_self->cur_chunk);
  __pyx_v_self->cur_chunk = ((PyObject*)__pyx_t_10);
  __Pyx_INCREF(__pyx_t_10);
  __pyx_v_chunk = ((PyObject*)__pyx_t_10);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

  /* "srctools/_tokenizer.pyx":355
 * 
 *         self.cur_chunk = chunk = <str>chunk_obj
 *         self.char_index = 0             # <<<<<<<<<<<<<<
 * 
 *         if len(chunk) > 0:
 */
  __pyx_v_self->char_index = 0;

  /* "srctools/_tokenizer.pyx":357
 *         self.char_index = 0
 * 
 *         if len(chunk) > 0:             # <<<<<<<<<<<<<<
 *             return (<str>chunk)[0]
 * 
 */
  if (unlikely(__pyx_v_chunk == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 357, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyUnicode_GET_LENGTH(__pyx_v_chunk); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 357, __pyx_L1_error)
  __pyx_t_20 = ((__pyx_t_2 > 0) != 0);
  if (__pyx_t_20) {

    /* "srctools/_tokenizer.pyx":358
 * 
 *         if len(chunk) > 0:
 *             return (<str>chunk)[0]             # <<<<<<<<<<<<<<
 * 
 *         # Skip empty chunks (shouldn't be there.)
 */
    __pyx_t_4 = __Pyx_GetItemInt_Unicode(__pyx_v_chunk, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(__pyx_t_4 == (Py_UCS4)-1)) __PYX_ERR(0, 358, __pyx_L1_error)
    __pyx_r = __pyx_t_4;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":357
 *         self.char_index = 0
 * 
 *         if len(chunk) > 0:             # <<<<<<<<<<<<<<
 *             return (<str>chunk)[0]
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":363
 *         # Use manual next to avoid re-calling iter() here,
 *         # or using list/tuple optimisations.
 *         while True:             # <<<<<<<<<<<<<<
 *             try:
 *                 chunk_obj = next(self.chunk_iter, None)
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":364
 *         # or using list/tuple optimisations.
 *         while True:
 *             try:             # <<<<<<<<<<<<<<
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:
 */
    {
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_6, &__pyx_t_5);
      __Pyx_XGOTREF(__pyx_t_7);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_5);
      /*try:*/ {

        /* "srctools/_tokenizer.pyx":365
 *         while True:
 *             try:
 *                 chunk_obj = next(self.chunk_iter, None)             # <<<<<<<<<<<<<<
 *             except UnicodeDecodeError as exc:
 *                 raise self._error("Could not decode file!") from exc
 */
        __pyx_t_10 = __pyx_v_self->chunk_iter;
        __Pyx_INCREF(__pyx_t_10);
        __pyx_t_1 = __Pyx_PyIter_Next2(__pyx_t_10, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 365, __pyx_L27_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_DECREF_SET(__pyx_v_chunk_obj, __pyx_t_1);
        __pyx_t_1 = 0;

        /* "srctools/_tokenizer.pyx":364
 *         # or using list/tuple optimisations.
 *         while True:
 *             try:             # <<<<<<<<<<<<<<
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:
 */
      }
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      goto __pyx_L34_try_end;
      __pyx_L27_error:;
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;

      /* "srctools/_tokenizer.pyx":366
 *             try:
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:             # <<<<<<<<<<<<<<
 *                 raise self._error("Could not decode file!") from exc
 *             if chunk_obj is None:
 */
      __pyx_t_12 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_UnicodeDecodeError);
      if (__pyx_t_12) {
        __Pyx_AddTraceback("srctools._tokenizer.Tokenizer._next_char", __pyx_clineno, __pyx_lineno, __pyx_filename);
        if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_10, &__pyx_t_8) < 0) __PYX_ERR(0, 366, __pyx_L29_except_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_GOTREF(__pyx_t_10);
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_10);
        __pyx_v_exc = __pyx_t_10;
        /*try:*/ {

          /* "srctools/_tokenizer.pyx":367
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:
 *                 raise self._error("Could not decode file!") from exc             # <<<<<<<<<<<<<<
 *             if chunk_obj is None:
 *                 # Out of characters after empty chunks
 */
          __pyx_t_11 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Could_not_decode_file); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 367, __pyx_L40_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_Raise(__pyx_t_11, 0, 0, __pyx_v_exc);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          __PYX_ERR(0, 367, __pyx_L40_error)
        }

        /* "srctools/_tokenizer.pyx":366
 *             try:
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:             # <<<<<<<<<<<<<<
 *                 raise self._error("Could not decode file!") from exc
 *             if chunk_obj is None:
 */
        /*finally:*/ {
          __pyx_L40_error:;
          /*exception exit:*/{
            __Pyx_PyThreadState_declare
            __Pyx_PyThreadState_assign
            __pyx_t_19 = 0; __pyx_t_18 = 0; __pyx_t_17 = 0; __pyx_t_16 = 0; __pyx_t_15 = 0; __pyx_t_14 = 0;
            __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
            if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_16, &__pyx_t_15, &__pyx_t_14);
            if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_19, &__pyx_t_18, &__pyx_t_17) < 0)) __Pyx_ErrFetch(&__pyx_t_19, &__pyx_t_18, &__pyx_t_17);
            __Pyx_XGOTREF(__pyx_t_19);
            __Pyx_XGOTREF(__pyx_t_18);
            __Pyx_XGOTREF(__pyx_t_17);
            __Pyx_XGOTREF(__pyx_t_16);
            __Pyx_XGOTREF(__pyx_t_15);
            __Pyx_XGOTREF(__pyx_t_14);
            __pyx_t_12 = __pyx_lineno; __pyx_t_9 = __pyx_clineno; __pyx_t_21 = __pyx_filename;
            {
              __Pyx_DECREF(__pyx_v_exc);
              __pyx_v_exc = NULL;
            }
            if (PY_MAJOR_VERSION >= 3) {
              __Pyx_XGIVEREF(__pyx_t_16);
              __Pyx_XGIVEREF(__pyx_t_15);
              __Pyx_XGIVEREF(__pyx_t_14);
              __Pyx_ExceptionReset(__pyx_t_16, __pyx_t_15, __pyx_t_14);
            }
            __Pyx_XGIVEREF(__pyx_t_19);
            __Pyx_XGIVEREF(__pyx_t_18);
            __Pyx_XGIVEREF(__pyx_t_17);
            __Pyx_ErrRestore(__pyx_t_19, __pyx_t_18, __pyx_t_17);
            __pyx_t_19 = 0; __pyx_t_18 = 0; __pyx_t_17 = 0; __pyx_t_16 = 0; __pyx_t_15 = 0; __pyx_t_14 = 0;
            __pyx_lineno = __pyx_t_12; __pyx_clineno = __pyx_t_9; __pyx_filename = __pyx_t_21;
            goto __pyx_L29_except_error;
          }
        }
      }
      goto __pyx_L29_except_error;
      __pyx_L29_except_error:;

      /* "srctools/_tokenizer.pyx":364
 *         # or using list/tuple optimisations.
 *         while True:
 *             try:             # <<<<<<<<<<<<<<
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:
 */
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_XGIVEREF(__pyx_t_5);
      __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_6, __pyx_t_5);
      goto __pyx_L1_error;
      __pyx_L34_try_end:;
    }

    /* "srctools/_tokenizer.pyx":368
 *             except UnicodeDecodeError as exc:
 *                 raise self._error("Could not decode file!") from exc
 *             if chunk_obj is None:             # <<<<<<<<<<<<<<
 *                 # Out of characters after empty chunks
 *                 return -1
 */
    __pyx_t_20 = (__pyx_v_chunk_obj == Py_None);
    __pyx_t_3 = (__pyx_t_20 != 0);
    if (__pyx_t_3) {

      /* "srctools/_tokenizer.pyx":370
 *             if chunk_obj is None:
 *                 # Out of characters after empty chunks
 *                 return -1             # <<<<<<<<<<<<<<
 * 
 *             if isinstance(chunk_obj, bytes):
 */
      __pyx_r = -1;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":368
 *             except UnicodeDecodeError as exc:
 *                 raise self._error("Could not decode file!") from exc
 *             if chunk_obj is None:             # <<<<<<<<<<<<<<
 *                 # Out of characters after empty chunks
 *                 return -1
 */
    }

    /* "srctools/_tokenizer.pyx":372
 *                 return -1
 * 
 *             if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):
 */
    __pyx_t_3 = PyBytes_Check(__pyx_v_chunk_obj); 
    __pyx_t_20 = (__pyx_t_3 != 0);
    if (unlikely(__pyx_t_20)) {

      /* "srctools/_tokenizer.pyx":373
 * 
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *             if not isinstance(chunk_obj, str):
 *                 raise ValueError("Data was not a string!")
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__16, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 373, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(0, 373, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":372
 *                 return -1
 * 
 *             if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):
 */
    }

    /* "srctools/_tokenizer.pyx":374
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):             # <<<<<<<<<<<<<<
 *                 raise ValueError("Data was not a string!")
 * 
 */
    __pyx_t_20 = PyUnicode_Check(__pyx_v_chunk_obj); 
    __pyx_t_3 = ((!(__pyx_t_20 != 0)) != 0);
    if (unlikely(__pyx_t_3)) {

      /* "srctools/_tokenizer.pyx":375
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):
 *                 raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *             if len(<str ?>chunk_obj) > 0:
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__17, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 375, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(0, 375, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":374
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')
 *             if not isinstance(chunk_obj, str):             # <<<<<<<<<<<<<<
 *                 raise ValueError("Data was not a string!")
 * 
 */
    }

    /* "srctools/_tokenizer.pyx":377
 *                 raise ValueError("Data was not a string!")
 * 
 *             if len(<str ?>chunk_obj) > 0:             # <<<<<<<<<<<<<<
 *                 self.cur_chunk = <str>chunk_obj
 *                 return (<str>chunk_obj)[0]
 */
    if (!(likely(PyUnicode_CheckExact(__pyx_v_chunk_obj))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_chunk_obj)->tp_name), 0))) __PYX_ERR(0, 377, __pyx_L1_error)
    if (unlikely(__pyx_v_chunk_obj == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
      __PYX_ERR(0, 377, __pyx_L1_error)
    }
    __pyx_t_2 = __Pyx_PyUnicode_GET_LENGTH(((PyObject*)__pyx_v_chunk_obj)); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 377, __pyx_L1_error)
    __pyx_t_3 = ((__pyx_t_2 > 0) != 0);
    if (__pyx_t_3) {

      /* "srctools/_tokenizer.pyx":378
 * 
 *             if len(<str ?>chunk_obj) > 0:
 *                 self.cur_chunk = <str>chunk_obj             # <<<<<<<<<<<<<<
 *                 return (<str>chunk_obj)[0]
 * 
 */
      __pyx_t_8 = __pyx_v_chunk_obj;
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_8);
      __Pyx_GOTREF(__pyx_v_self->cur_chunk);
      __Pyx_DECREF(__pyx_v_self->cur_chunk);
      __pyx_v_self->cur_chunk = ((PyObject*)__pyx_t_8);
      __pyx_t_8 = 0;

      /* "srctools/_tokenizer.pyx":379
 *             if len(<str ?>chunk_obj) > 0:
 *                 self.cur_chunk = <str>chunk_obj
 *                 return (<str>chunk_obj)[0]             # <<<<<<<<<<<<<<
 * 
 *     cdef next_token(self):
 */
      __pyx_t_4 = __Pyx_GetItemInt_Unicode(__pyx_v_chunk_obj, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(__pyx_t_4 == (Py_UCS4)-1)) __PYX_ERR(0, 379, __pyx_L1_error)
      __pyx_r = __pyx_t_4;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":377
 *                 raise ValueError("Data was not a string!")
 * 
 *             if len(<str ?>chunk_obj) > 0:             # <<<<<<<<<<<<<<
 *                 self.cur_chunk = <str>chunk_obj
 *                 return (<str>chunk_obj)[0]
 */
    }
  }

  /* "srctools/_tokenizer.pyx":332
 *     @cython.boundscheck(False)
 *     @cython.wraparound(False)
 *     cdef Py_UCS4 _next_char(self) except -2:             # <<<<<<<<<<<<<<
 *         """Return the next character, or -1 if no more characters are there."""
 *         cdef str chunk
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer._next_char", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -2;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_chunk);
  __Pyx_XDECREF(__pyx_v_chunk_obj);
  __Pyx_XDECREF(__pyx_v_exc);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":381
 *                 return (<str>chunk_obj)[0]
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair - this is the C version."""
 *         cdef:
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  Py_UCS4 __pyx_v_next_char;
  Py_UCS4 __pyx_v_escape_char;
  Py_UCS4 __pyx_v_peek_char;
  int __pyx_v_start_line;
  PyObject *__pyx_v_output = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  Py_UCS4 __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  Py_ssize_t __pyx_t_10;
  void *__pyx_t_11;
  int __pyx_t_12;
  Py_ssize_t __pyx_t_13;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("next_token", 0);

  /* "srctools/_tokenizer.pyx":389
 *             int start_line
 * 
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  __pyx_t_1 = (__pyx_v_self->__pyx_base.pushback_tok != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":390
 * 
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val             # <<<<<<<<<<<<<<
 *             self.pushback_tok = self.pushback_val = None
 *             return output
 */
    __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 390, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_GIVEREF(__pyx_v_self->__pyx_base.pushback_tok);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_INCREF(__pyx_v_self->__pyx_base.pushback_val);
    __Pyx_GIVEREF(__pyx_v_self->__pyx_base.pushback_val);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_v_self->__pyx_base.pushback_val);
    __pyx_v_output = ((PyObject*)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":391
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None             # <<<<<<<<<<<<<<
 *             return output
 * 
 */
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_DECREF(__pyx_v_self->__pyx_base.pushback_tok);
    __pyx_v_self->__pyx_base.pushback_tok = Py_None;
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->__pyx_base.pushback_val);
    __Pyx_DECREF(__pyx_v_self->__pyx_base.pushback_val);
    __pyx_v_self->__pyx_base.pushback_val = Py_None;

    /* "srctools/_tokenizer.pyx":392
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 *             return output             # <<<<<<<<<<<<<<
 * 
 *         while True:
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_output);
    __pyx_r = __pyx_v_output;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":389
 *             int start_line
 * 
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  }

  /* "srctools/_tokenizer.pyx":394
 *             return output
 * 
 *         while True:             # <<<<<<<<<<<<<<
 *             next_char = self._next_char()
 *             if next_char == -1:
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":395
 * 
 *         while True:
 *             next_char = self._next_char()             # <<<<<<<<<<<<<<
 *             if next_char == -1:
 *                 return EOF_TUP
 */
    __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 395, __pyx_L1_error)
    __pyx_v_next_char = __pyx_t_4;

    /* "srctools/_tokenizer.pyx":396
 *         while True:
 *             next_char = self._next_char()
 *             if next_char == -1:             # <<<<<<<<<<<<<<
 *                 return EOF_TUP
 * 
 */
    switch (__pyx_v_next_char) {
      case -1L:

      /* "srctools/_tokenizer.pyx":397
 *             next_char = self._next_char()
 *             if next_char == -1:
 *                 return EOF_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == '{':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EOF_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_EOF_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":396
 *         while True:
 *             next_char = self._next_char()
 *             if next_char == -1:             # <<<<<<<<<<<<<<
 *                 return EOF_TUP
 * 
 */
      break;
      case 0x7B:

      /* "srctools/_tokenizer.pyx":400
 * 
 *             elif next_char == '{':
 *                 return BRACE_OPEN_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == '}':
 *                 return BRACE_CLOSE_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":399
 *                 return EOF_TUP
 * 
 *             elif next_char == '{':             # <<<<<<<<<<<<<<
 *                 return BRACE_OPEN_TUP
 *             elif next_char == '}':
 */
      break;
      case 0x7D:

      /* "srctools/_tokenizer.pyx":402
 *                 return BRACE_OPEN_TUP
 *             elif next_char == '}':
 *                 return BRACE_CLOSE_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == ':':
 *                 return COLON_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":401
 *             elif next_char == '{':
 *                 return BRACE_OPEN_TUP
 *             elif next_char == '}':             # <<<<<<<<<<<<<<
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == ':':
 */
      break;
      case 58:

      /* "srctools/_tokenizer.pyx":404
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == ':':
 *                 return COLON_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == '+':
 *                 return PLUS_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_COLON_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_COLON_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":403
 *             elif next_char == '}':
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == ':':             # <<<<<<<<<<<<<<
 *                 return COLON_TUP
 *             elif next_char == '+':
 */
      break;
      case 43:

      /* "srctools/_tokenizer.pyx":406
 *                 return COLON_TUP
 *             elif next_char == '+':
 *                 return PLUS_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == '=':
 *                 return EQUALS_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PLUS_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_PLUS_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":405
 *             elif next_char == ':':
 *                 return COLON_TUP
 *             elif next_char == '+':             # <<<<<<<<<<<<<<
 *                 return PLUS_TUP
 *             elif next_char == '=':
 */
      break;
      case 61:

      /* "srctools/_tokenizer.pyx":408
 *                 return PLUS_TUP
 *             elif next_char == '=':
 *                 return EQUALS_TUP             # <<<<<<<<<<<<<<
 *             # First try simple operators & EOF.
 * 
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_EQUALS_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":407
 *             elif next_char == '+':
 *                 return PLUS_TUP
 *             elif next_char == '=':             # <<<<<<<<<<<<<<
 *                 return EQUALS_TUP
 *             # First try simple operators & EOF.
 */
      break;
      case 10:

      /* "srctools/_tokenizer.pyx":412
 * 
 *             elif next_char == '\n':
 *                 self.line_num += 1             # <<<<<<<<<<<<<<
 *                 return NEWLINE_TUP
 * 
 */
      __pyx_v_self->__pyx_base.line_num = (__pyx_v_self->__pyx_base.line_num + 1);

      /* "srctools/_tokenizer.pyx":413
 *             elif next_char == '\n':
 *                 self.line_num += 1
 *                 return NEWLINE_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char in ' \t':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_NEWLINE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":411
 *             # First try simple operators & EOF.
 * 
 *             elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                 self.line_num += 1
 *                 return NEWLINE_TUP
 */
      break;
      case 9:

      /* "srctools/_tokenizer.pyx":415
 *                 return NEWLINE_TUP
 * 
 *             elif next_char in ' \t':             # <<<<<<<<<<<<<<
 *                 # Ignore whitespace..
 *                 continue
 */
      case 32:

      /* "srctools/_tokenizer.pyx":417
 *             elif next_char in ' \t':
 *                 # Ignore whitespace..
 *                 continue             # <<<<<<<<<<<<<<
 * 
 *             # Comments
 */
      goto __pyx_L4_continue;

      /* "srctools/_tokenizer.pyx":415
 *                 return NEWLINE_TUP
 * 
 *             elif next_char in ' \t':             # <<<<<<<<<<<<<<
 *                 # Ignore whitespace..
 *                 continue
 */
      break;
      case 47:

      /* "srctools/_tokenizer.pyx":422
 *             elif next_char == '/':
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.allow_star_comments:
 */
      __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 422, __pyx_L1_error)
      __pyx_v_next_char = __pyx_t_4;

      /* "srctools/_tokenizer.pyx":423
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.             # <<<<<<<<<<<<<<
 *                     if self.allow_star_comments:
 *                         start_line = self.line_num
 */
      switch (__pyx_v_next_char) {
        case 42:

        /* "srctools/_tokenizer.pyx":424
 *                 next_char = self._next_char()
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.allow_star_comments:             # <<<<<<<<<<<<<<
 *                         start_line = self.line_num
 *                         while True:
 */
        __pyx_t_2 = (__pyx_v_self->allow_star_comments != 0);
        if (likely(__pyx_t_2)) {

          /* "srctools/_tokenizer.pyx":425
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.allow_star_comments:
 *                         start_line = self.line_num             # <<<<<<<<<<<<<<
 *                         while True:
 *                             next_char = self._next_char()
 */
          __pyx_t_5 = __pyx_v_self->__pyx_base.line_num;
          __pyx_v_start_line = __pyx_t_5;

          /* "srctools/_tokenizer.pyx":426
 *                     if self.allow_star_comments:
 *                         start_line = self.line_num
 *                         while True:             # <<<<<<<<<<<<<<
 *                             next_char = self._next_char()
 *                             if next_char == -1:
 */
          while (1) {

            /* "srctools/_tokenizer.pyx":427
 *                         start_line = self.line_num
 *                         while True:
 *                             next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                             if next_char == -1:
 *                                 raise self._error(
 */
            __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 427, __pyx_L1_error)
            __pyx_v_next_char = __pyx_t_4;

            /* "srctools/_tokenizer.pyx":428
 *                         while True:
 *                             next_char = self._next_char()
 *                             if next_char == -1:             # <<<<<<<<<<<<<<
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
            switch (__pyx_v_next_char) {
              case -1L:

              /* "srctools/_tokenizer.pyx":430
 *                             if next_char == -1:
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                     f'(starting on line {start_line})!',
 *                                 )
 */
              __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 430, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_3);
              __pyx_t_6 = 0;
              __pyx_t_4 = 127;
              __Pyx_INCREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
              __pyx_t_6 += 38;
              __Pyx_GIVEREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
              PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unclosed_comment_starting_on_lin);

              /* "srctools/_tokenizer.pyx":431
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                     f'(starting on line {start_line})!',             # <<<<<<<<<<<<<<
 *                                 )
 *                             elif next_char == '\n':
 */
              __pyx_t_7 = __Pyx_PyUnicode_From_int(__pyx_v_start_line, 0, ' ', 'd'); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 431, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_7);
              __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
              __Pyx_GIVEREF(__pyx_t_7);
              PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
              __pyx_t_7 = 0;
              __Pyx_INCREF(__pyx_kp_u__18);
              __pyx_t_6 += 2;
              __Pyx_GIVEREF(__pyx_kp_u__18);
              PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__18);

              /* "srctools/_tokenizer.pyx":430
 *                             if next_char == -1:
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                     f'(starting on line {start_line})!',
 *                                 )
 */
              __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 430, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_7);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

              /* "srctools/_tokenizer.pyx":429
 *                             next_char = self._next_char()
 *                             if next_char == -1:
 *                                 raise self._error(             # <<<<<<<<<<<<<<
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                     f'(starting on line {start_line})!',
 */
              __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject*)__pyx_t_7)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 429, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
              __Pyx_Raise(__pyx_t_3, 0, 0, 0);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
              __PYX_ERR(0, 429, __pyx_L1_error)

              /* "srctools/_tokenizer.pyx":428
 *                         while True:
 *                             next_char = self._next_char()
 *                             if next_char == -1:             # <<<<<<<<<<<<<<
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
              break;
              case 10:

              /* "srctools/_tokenizer.pyx":434
 *                                 )
 *                             elif next_char == '\n':
 *                                 self.line_num += 1             # <<<<<<<<<<<<<<
 *                             elif next_char == '*':
 *                                 # Check next next character!
 */
              __pyx_v_self->__pyx_base.line_num = (__pyx_v_self->__pyx_base.line_num + 1);

              /* "srctools/_tokenizer.pyx":433
 *                                     f'(starting on line {start_line})!',
 *                                 )
 *                             elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                                 self.line_num += 1
 *                             elif next_char == '*':
 */
              break;
              case 42:

              /* "srctools/_tokenizer.pyx":437
 *                             elif next_char == '*':
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()             # <<<<<<<<<<<<<<
 *                                 if peek_char == -1:
 *                                     raise self._error(
 */
              __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 437, __pyx_L1_error)
              __pyx_v_peek_char = __pyx_t_4;

              /* "srctools/_tokenizer.pyx":438
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 *                                 if peek_char == -1:             # <<<<<<<<<<<<<<
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
              switch (__pyx_v_peek_char) {
                case -1L:

                /* "srctools/_tokenizer.pyx":440
 *                                 if peek_char == -1:
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                         f'(starting on line {start_line})!',
 *                                     )
 */
                __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 440, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_3);
                __pyx_t_6 = 0;
                __pyx_t_4 = 127;
                __Pyx_INCREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
                __pyx_t_6 += 38;
                __Pyx_GIVEREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
                PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unclosed_comment_starting_on_lin);

                /* "srctools/_tokenizer.pyx":441
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                         f'(starting on line {start_line})!',             # <<<<<<<<<<<<<<
 *                                     )
 *                                 elif peek_char == '/':
 */
                __pyx_t_7 = __Pyx_PyUnicode_From_int(__pyx_v_start_line, 0, ' ', 'd'); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 441, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_7);
                __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
                __Pyx_GIVEREF(__pyx_t_7);
                PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
                __pyx_t_7 = 0;
                __Pyx_INCREF(__pyx_kp_u__18);
                __pyx_t_6 += 2;
                __Pyx_GIVEREF(__pyx_kp_u__18);
                PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__18);

                /* "srctools/_tokenizer.pyx":440
 *                                 if peek_char == -1:
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                         f'(starting on line {start_line})!',
 *                                     )
 */
                __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 440, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_7);
                __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

                /* "srctools/_tokenizer.pyx":439
 *                                 peek_char = self._next_char()
 *                                 if peek_char == -1:
 *                                     raise self._error(             # <<<<<<<<<<<<<<
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                         f'(starting on line {start_line})!',
 */
                __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject*)__pyx_t_7)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 439, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_3);
                __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
                __Pyx_Raise(__pyx_t_3, 0, 0, 0);
                __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
                __PYX_ERR(0, 439, __pyx_L1_error)

                /* "srctools/_tokenizer.pyx":438
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 *                                 if peek_char == -1:             # <<<<<<<<<<<<<<
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
                break;
                case 47:

                /* "srctools/_tokenizer.pyx":444
 *                                     )
 *                                 elif peek_char == '/':
 *                                     break             # <<<<<<<<<<<<<<
 *                                 else:
 *                                     # We need to reparse this, to ensure
 */
                goto __pyx_L8_break;

                /* "srctools/_tokenizer.pyx":443
 *                                         f'(starting on line {start_line})!',
 *                                     )
 *                                 elif peek_char == '/':             # <<<<<<<<<<<<<<
 *                                     break
 *                                 else:
 */
                break;
                default:

                /* "srctools/_tokenizer.pyx":448
 *                                     # We need to reparse this, to ensure
 *                                     # "**[inserted by cython to avoid comment closer]/" parses correctly!
 *                                     self.char_index -= 1             # <<<<<<<<<<<<<<
 *                     else:
 *                         raise self._error(
 */
                __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);
                break;
              }

              /* "srctools/_tokenizer.pyx":435
 *                             elif next_char == '\n':
 *                                 self.line_num += 1
 *                             elif next_char == '*':             # <<<<<<<<<<<<<<
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 */
              break;
              default: break;
            }
          }
          __pyx_L8_break:;

          /* "srctools/_tokenizer.pyx":424
 *                 next_char = self._next_char()
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.allow_star_comments:             # <<<<<<<<<<<<<<
 *                         start_line = self.line_num
 *                         while True:
 */
          goto __pyx_L6;
        }

        /* "srctools/_tokenizer.pyx":450
 *                                     self.char_index -= 1
 *                     else:
 *                         raise self._error(             # <<<<<<<<<<<<<<
 *                             '/[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/-style comments are not allowed!'
 *                         )
 */
        /*else*/ {
          __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_style_comments_are_not_allowed); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 450, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_Raise(__pyx_t_3, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __PYX_ERR(0, 450, __pyx_L1_error)
        }
        __pyx_L6:;

        /* "srctools/_tokenizer.pyx":423
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 *                 if next_char == '*': # /[inserted by cython to avoid comment start]* comment.             # <<<<<<<<<<<<<<
 *                     if self.allow_star_comments:
 *                         start_line = self.line_num
 */
        break;
        case 47:

        /* "srctools/_tokenizer.pyx":455
 *                 elif next_char == '/':
 *                     # Skip to end of line
 *                     while True:             # <<<<<<<<<<<<<<
 *                         next_char = self._next_char()
 *                         if next_char == -1 or next_char == '\n':
 */
        while (1) {

          /* "srctools/_tokenizer.pyx":456
 *                     # Skip to end of line
 *                     while True:
 *                         next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if next_char == -1 or next_char == '\n':
 *                             break
 */
          __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 456, __pyx_L1_error)
          __pyx_v_next_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":457
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == -1 or next_char == '\n':             # <<<<<<<<<<<<<<
 *                             break
 * 
 */
          switch (__pyx_v_next_char) {
            case -1L:
            case 10:

            /* "srctools/_tokenizer.pyx":458
 *                         next_char = self._next_char()
 *                         if next_char == -1 or next_char == '\n':
 *                             break             # <<<<<<<<<<<<<<
 * 
 *                     # We want to produce the token for the end character -
 */
            goto __pyx_L10_break;

            /* "srctools/_tokenizer.pyx":457
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == -1 or next_char == '\n':             # <<<<<<<<<<<<<<
 *                             break
 * 
 */
            break;
            default: break;
          }
        }
        __pyx_L10_break:;

        /* "srctools/_tokenizer.pyx":462
 *                     # We want to produce the token for the end character -
 *                     # EOF or NEWLINE.
 *                     self.char_index -= 1             # <<<<<<<<<<<<<<
 *                 else:
 *                     raise self._error(
 */
        __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

        /* "srctools/_tokenizer.pyx":453
 *                             '/[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/-style comments are not allowed!'
 *                         )
 *                 elif next_char == '/':             # <<<<<<<<<<<<<<
 *                     # Skip to end of line
 *                     while True:
 */
        break;
        default:

        /* "srctools/_tokenizer.pyx":467
 *                         'Single slash found, '
 *                         'instead of two for a comment (// or /[inserted by cython to avoid comment start]* *[inserted by cython to avoid comment closer]/)!'
 *                         if self.allow_star_comments else             # <<<<<<<<<<<<<<
 *                         'Single slash found, '
 *                         'instead of two for a comment (//)!'
 */
        if ((__pyx_v_self->allow_star_comments != 0)) {
          __Pyx_INCREF(__pyx_kp_u_Single_slash_found_instead_of_tw);
          __pyx_t_3 = __pyx_kp_u_Single_slash_found_instead_of_tw;
        } else {
          __Pyx_INCREF(__pyx_kp_u_Single_slash_found_instead_of_tw_2);
          __pyx_t_3 = __pyx_kp_u_Single_slash_found_instead_of_tw_2;
        }

        /* "srctools/_tokenizer.pyx":464
 *                     self.char_index -= 1
 *                 else:
 *                     raise self._error(             # <<<<<<<<<<<<<<
 *                         'Single slash found, '
 *                         'instead of two for a comment (// or /[inserted by cython to avoid comment start]* *[inserted by cython to avoid comment closer]/)!'
 */
        __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 464, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_Raise(__pyx_t_7, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __PYX_ERR(0, 464, __pyx_L1_error)
        break;
      }

      /* "srctools/_tokenizer.pyx":420
 * 
 *             # Comments
 *             elif next_char == '/':             # <<<<<<<<<<<<<<
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 */
      break;
      case 34:

      /* "srctools/_tokenizer.pyx":474
 *             # Strings
 *             elif next_char == '"':
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":475
 *             elif next_char == '"':
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":476
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == -1:
 *                         raise self._error('Unterminated string!')
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 476, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":477
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':
 */
        __pyx_t_2 = ((__pyx_v_next_char == -1L) != 0);
        if (unlikely(__pyx_t_2)) {

          /* "srctools/_tokenizer.pyx":478
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 *                         raise self._error('Unterminated string!')             # <<<<<<<<<<<<<<
 *                     elif next_char == '"':
 *                         return STRING, self.buf_get_text()
 */
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Unterminated_string); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 478, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_Raise(__pyx_t_7, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __PYX_ERR(0, 478, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":477
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':
 */
        }

        /* "srctools/_tokenizer.pyx":479
 *                     if next_char == -1:
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':             # <<<<<<<<<<<<<<
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':
 */
        __pyx_t_2 = ((__pyx_v_next_char == 34) != 0);
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":480
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':
 *                         return STRING, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_7 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 480, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 480, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_STRING);
          PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_STRING);
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_r = __pyx_t_3;
          __pyx_t_3 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":479
 *                     if next_char == -1:
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == '"':             # <<<<<<<<<<<<<<
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':
 */
        }

        /* "srctools/_tokenizer.pyx":481
 *                     elif next_char == '"':
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     elif next_char == '\\' and self.allow_escapes:
 */
        __pyx_t_2 = ((__pyx_v_next_char == 10) != 0);
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":482
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':
 *                         self.line_num += 1             # <<<<<<<<<<<<<<
 *                     elif next_char == '\\' and self.allow_escapes:
 *                         # Escape text
 */
          __pyx_v_self->__pyx_base.line_num = (__pyx_v_self->__pyx_base.line_num + 1);

          /* "srctools/_tokenizer.pyx":481
 *                     elif next_char == '"':
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     elif next_char == '\\' and self.allow_escapes:
 */
          goto __pyx_L13;
        }

        /* "srctools/_tokenizer.pyx":483
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 *                     elif next_char == '\\' and self.allow_escapes:             # <<<<<<<<<<<<<<
 *                         # Escape text
 *                         escape_char = self._next_char()
 */
        __pyx_t_1 = ((__pyx_v_next_char == 92) != 0);
        if (__pyx_t_1) {
        } else {
          __pyx_t_2 = __pyx_t_1;
          goto __pyx_L14_bool_binop_done;
        }
        __pyx_t_1 = (__pyx_v_self->allow_escapes != 0);
        __pyx_t_2 = __pyx_t_1;
        __pyx_L14_bool_binop_done:;
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":485
 *                     elif next_char == '\\' and self.allow_escapes:
 *                         # Escape text
 *                         escape_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if escape_char == -1:
 *                             raise self._error('Unterminated string!')
 */
          __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 485, __pyx_L1_error)
          __pyx_v_escape_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":486
 *                         # Escape text
 *                         escape_char = self._next_char()
 *                         if escape_char == -1:             # <<<<<<<<<<<<<<
 *                             raise self._error('Unterminated string!')
 * 
 */
          __pyx_t_2 = ((__pyx_v_escape_char == -1L) != 0);
          if (unlikely(__pyx_t_2)) {

            /* "srctools/_tokenizer.pyx":487
 *                         escape_char = self._next_char()
 *                         if escape_char == -1:
 *                             raise self._error('Unterminated string!')             # <<<<<<<<<<<<<<
 * 
 *                         if escape_char == 'n':
 */
            __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Unterminated_string); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 487, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_Raise(__pyx_t_3, 0, 0, 0);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            __PYX_ERR(0, 487, __pyx_L1_error)

            /* "srctools/_tokenizer.pyx":486
 *                         # Escape text
 *                         escape_char = self._next_char()
 *                         if escape_char == -1:             # <<<<<<<<<<<<<<
 *                             raise self._error('Unterminated string!')
 * 
 */
          }

          /* "srctools/_tokenizer.pyx":489
 *                             raise self._error('Unterminated string!')
 * 
 *                         if escape_char == 'n':             # <<<<<<<<<<<<<<
 *                             next_char = '\n'
 *                         elif escape_char == 't':
 */
          switch (__pyx_v_escape_char) {
            case 0x6E:

            /* "srctools/_tokenizer.pyx":490
 * 
 *                         if escape_char == 'n':
 *                             next_char = '\n'             # <<<<<<<<<<<<<<
 *                         elif escape_char == 't':
 *                             next_char = '\t'
 */
            __pyx_v_next_char = 10;

            /* "srctools/_tokenizer.pyx":489
 *                             raise self._error('Unterminated string!')
 * 
 *                         if escape_char == 'n':             # <<<<<<<<<<<<<<
 *                             next_char = '\n'
 *                         elif escape_char == 't':
 */
            break;
            case 0x74:

            /* "srctools/_tokenizer.pyx":492
 *                             next_char = '\n'
 *                         elif escape_char == 't':
 *                             next_char = '\t'             # <<<<<<<<<<<<<<
 *                         elif escape_char == '\n':
 *                             # \ at end of line ignores the newline.
 */
            __pyx_v_next_char = 9;

            /* "srctools/_tokenizer.pyx":491
 *                         if escape_char == 'n':
 *                             next_char = '\n'
 *                         elif escape_char == 't':             # <<<<<<<<<<<<<<
 *                             next_char = '\t'
 *                         elif escape_char == '\n':
 */
            break;
            case 10:

            /* "srctools/_tokenizer.pyx":495
 *                         elif escape_char == '\n':
 *                             # \ at end of line ignores the newline.
 *                             continue             # <<<<<<<<<<<<<<
 *                         elif escape_char in ('"', '\\', '/'):
 *                             # For these, we escape to give the literal value.
 */
            goto __pyx_L11_continue;

            /* "srctools/_tokenizer.pyx":493
 *                         elif escape_char == 't':
 *                             next_char = '\t'
 *                         elif escape_char == '\n':             # <<<<<<<<<<<<<<
 *                             # \ at end of line ignores the newline.
 *                             continue
 */
            break;
            case 34:

            /* "srctools/_tokenizer.pyx":496
 *                             # \ at end of line ignores the newline.
 *                             continue
 *                         elif escape_char in ('"', '\\', '/'):             # <<<<<<<<<<<<<<
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char
 */
            case 92:
            case 47:

            /* "srctools/_tokenizer.pyx":498
 *                         elif escape_char in ('"', '\\', '/'):
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char             # <<<<<<<<<<<<<<
 *                         else:
 *                             # For unknown escape_chars, escape the \ automatically.
 */
            __pyx_v_next_char = __pyx_v_escape_char;

            /* "srctools/_tokenizer.pyx":496
 *                             # \ at end of line ignores the newline.
 *                             continue
 *                         elif escape_char in ('"', '\\', '/'):             # <<<<<<<<<<<<<<
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char
 */
            break;
            default:

            /* "srctools/_tokenizer.pyx":501
 *                         else:
 *                             # For unknown escape_chars, escape the \ automatically.
 *                             self.buf_add_char('\\')             # <<<<<<<<<<<<<<
 *                             self.buf_add_char(escape_char)
 *                             continue
 */
            __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, 92);

            /* "srctools/_tokenizer.pyx":502
 *                             # For unknown escape_chars, escape the \ automatically.
 *                             self.buf_add_char('\\')
 *                             self.buf_add_char(escape_char)             # <<<<<<<<<<<<<<
 *                             continue
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 */
            __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_escape_char);

            /* "srctools/_tokenizer.pyx":503
 *                             self.buf_add_char('\\')
 *                             self.buf_add_char(escape_char)
 *                             continue             # <<<<<<<<<<<<<<
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 *                     self.buf_add_char(next_char)
 */
            goto __pyx_L11_continue;
            break;
          }

          /* "srctools/_tokenizer.pyx":483
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 *                     elif next_char == '\\' and self.allow_escapes:             # <<<<<<<<<<<<<<
 *                         # Escape text
 *                         escape_char = self._next_char()
 */
        }
        __pyx_L13:;

        /* "srctools/_tokenizer.pyx":505
 *                             continue
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == '[':
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
        __pyx_L11_continue:;
      }

      /* "srctools/_tokenizer.pyx":473
 * 
 *             # Strings
 *             elif next_char == '"':             # <<<<<<<<<<<<<<
 *                 self.buf_reset()
 *                 while True:
 */
      break;
      case 91:

      /* "srctools/_tokenizer.pyx":509
 *             elif next_char == '[':
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.string_bracket:             # <<<<<<<<<<<<<<
 *                     return BRACK_OPEN_TUP
 * 
 */
      __pyx_t_2 = ((!(__pyx_v_self->string_bracket != 0)) != 0);
      if (__pyx_t_2) {

        /* "srctools/_tokenizer.pyx":510
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.string_bracket:
 *                     return BRACK_OPEN_TUP             # <<<<<<<<<<<<<<
 * 
 *                 self.buf_reset()
 */
        __Pyx_XDECREF(__pyx_r);
        __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP);
        __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP;
        goto __pyx_L0;

        /* "srctools/_tokenizer.pyx":509
 *             elif next_char == '[':
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.string_bracket:             # <<<<<<<<<<<<<<
 *                     return BRACK_OPEN_TUP
 * 
 */
      }

      /* "srctools/_tokenizer.pyx":512
 *                     return BRACK_OPEN_TUP
 * 
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":513
 * 
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == '[':
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":514
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == '[':
 *                         # Don't allow nesting, that's bad.
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 514, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":515
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == '[':             # <<<<<<<<<<<<<<
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 */
        switch (__pyx_v_next_char) {
          case 91:

          /* "srctools/_tokenizer.pyx":517
 *                     if next_char == '[':
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')             # <<<<<<<<<<<<<<
 *                     elif next_char == ']':
 *                         return PROP_FLAG, self.buf_get_text()
 */
          __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Cannot_nest_brackets); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 517, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_Raise(__pyx_t_3, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __PYX_ERR(0, 517, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":515
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == '[':             # <<<<<<<<<<<<<<
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 */
          break;
          case 93:

          /* "srctools/_tokenizer.pyx":519
 *                         raise self._error('Cannot nest [] brackets!')
 *                     elif next_char == ']':
 *                         return PROP_FLAG, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     # Must be one line!
 *                     elif next_char == '\n' or next_char == -1:
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 519, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 519, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          __Pyx_GIVEREF(__pyx_t_3);
          PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_3);
          __pyx_t_3 = 0;
          __pyx_r = __pyx_t_7;
          __pyx_t_7 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":518
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 *                     elif next_char == ']':             # <<<<<<<<<<<<<<
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 */
          break;
          case 10:

          /* "srctools/_tokenizer.pyx":521
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 *                     elif next_char == '\n' or next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error(
 *                             'Reached end of line '
 */
          case -1L:

          /* "srctools/_tokenizer.pyx":522
 *                     # Must be one line!
 *                     elif next_char == '\n' or next_char == -1:
 *                         raise self._error(             # <<<<<<<<<<<<<<
 *                             'Reached end of line '
 *                             'without closing "]"!'
 */
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Reached_end_of_line_without_clos); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 522, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_Raise(__pyx_t_7, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __PYX_ERR(0, 522, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":521
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 *                     elif next_char == '\n' or next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error(
 *                             'Reached end of line '
 */
          break;
          default: break;
        }

        /* "srctools/_tokenizer.pyx":526
 *                             'without closing "]"!'
 *                         )
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == ']':
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
      }

      /* "srctools/_tokenizer.pyx":507
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == '[':             # <<<<<<<<<<<<<<
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.string_bracket:
 */
      break;
      case 93:

      /* "srctools/_tokenizer.pyx":529
 * 
 *             elif next_char == ']':
 *                 if self.string_bracket:             # <<<<<<<<<<<<<<
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 */
      __pyx_t_2 = (__pyx_v_self->string_bracket != 0);
      if (unlikely(__pyx_t_2)) {

        /* "srctools/_tokenizer.pyx":532
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 *                     raise self._error('No open [] to close with "]"!')             # <<<<<<<<<<<<<<
 *                 return BRACK_CLOSE_TUP
 * 
 */
        __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_No_open_to_close_with); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 532, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_Raise(__pyx_t_7, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __PYX_ERR(0, 532, __pyx_L1_error)

        /* "srctools/_tokenizer.pyx":529
 * 
 *             elif next_char == ']':
 *                 if self.string_bracket:             # <<<<<<<<<<<<<<
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 */
      }

      /* "srctools/_tokenizer.pyx":533
 *                     # syntax error - we don't have an open one to close!
 *                     raise self._error('No open [] to close with "]"!')
 *                 return BRACK_CLOSE_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == '(':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":528
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == ']':             # <<<<<<<<<<<<<<
 *                 if self.string_bracket:
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 */
      break;
      case 40:

      /* "srctools/_tokenizer.pyx":537
 *             elif next_char == '(':
 *                 # Parentheses around text...
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":538
 *                 # Parentheses around text...
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":539
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == -1:
 *                         raise self._error('Unterminated parentheses!')
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 539, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":540
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == '(':
 */
        switch (__pyx_v_next_char) {
          case -1L:

          /* "srctools/_tokenizer.pyx":541
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 *                         raise self._error('Unterminated parentheses!')             # <<<<<<<<<<<<<<
 *                     elif next_char == '(':
 *                         raise self._error('Cannot nest () brackets!')
 */
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Unterminated_parentheses); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 541, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_Raise(__pyx_t_7, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __PYX_ERR(0, 541, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":540
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == '(':
 */
          break;
          case 40:

          /* "srctools/_tokenizer.pyx":543
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == '(':
 *                         raise self._error('Cannot nest () brackets!')             # <<<<<<<<<<<<<<
 *                     elif next_char == ')':
 *                         return PAREN_ARGS, self.buf_get_text()
 */
          __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Cannot_nest_brackets_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 543, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_Raise(__pyx_t_7, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __PYX_ERR(0, 543, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":542
 *                     if next_char == -1:
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == '(':             # <<<<<<<<<<<<<<
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == ')':
 */
          break;
          case 41:

          /* "srctools/_tokenizer.pyx":545
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == ')':
 *                         return PAREN_ARGS, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_7 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 545, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 545, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_r = __pyx_t_3;
          __pyx_t_3 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":544
 *                     elif next_char == '(':
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == ')':             # <<<<<<<<<<<<<<
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == '\n':
 */
          break;
          case 10:

          /* "srctools/_tokenizer.pyx":547
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == '\n':
 *                         self.line_num += 1             # <<<<<<<<<<<<<<
 *                     self.buf_add_char(next_char)
 * 
 */
          __pyx_v_self->__pyx_base.line_num = (__pyx_v_self->__pyx_base.line_num + 1);

          /* "srctools/_tokenizer.pyx":546
 *                     elif next_char == ')':
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == '\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     self.buf_add_char(next_char)
 */
          break;
          default: break;
        }

        /* "srctools/_tokenizer.pyx":548
 *                     elif next_char == '\n':
 *                         self.line_num += 1
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == ')':
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
      }

      /* "srctools/_tokenizer.pyx":535
 *                 return BRACK_CLOSE_TUP
 * 
 *             elif next_char == '(':             # <<<<<<<<<<<<<<
 *                 # Parentheses around text...
 *                 self.buf_reset()
 */
      break;
      case 41:

      /* "srctools/_tokenizer.pyx":551
 * 
 *             elif next_char == ')':
 *                 raise self._error('No open () to close with ")"!')             # <<<<<<<<<<<<<<
 * 
 *             # Directives
 */
      __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_No_open_to_close_with_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 551, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 551, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":550
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == ')':             # <<<<<<<<<<<<<<
 *                 raise self._error('No open () to close with ")"!')
 * 
 */
      break;
      case 35:

      /* "srctools/_tokenizer.pyx":555
 *             # Directives
 *             elif next_char == '#':
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":556
 *             elif next_char == '#':
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == -1:
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":557
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == -1:
 *                         # A directive could be the last value in the file.
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 557, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":558
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         # A directive could be the last value in the file.
 *                         return DIRECTIVE, self.buf_get_text()
 */
        switch (__pyx_v_next_char) {
          case -1L:

          /* "srctools/_tokenizer.pyx":560
 *                     if next_char == -1:
 *                         # A directive could be the last value in the file.
 *                         return DIRECTIVE, self.buf_get_text()             # <<<<<<<<<<<<<<
 * 
 *                     elif next_char in BARE_DISALLOWED:
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 560, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 560, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
          PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_8srctools_10_tokenizer_DIRECTIVE);
          __Pyx_GIVEREF(__pyx_t_3);
          PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_3);
          __pyx_t_3 = 0;
          __pyx_r = __pyx_t_7;
          __pyx_t_7 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":558
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == -1:             # <<<<<<<<<<<<<<
 *                         # A directive could be the last value in the file.
 *                         return DIRECTIVE, self.buf_get_text()
 */
          break;
          case 34:

          /* "srctools/_tokenizer.pyx":562
 *                         return DIRECTIVE, self.buf_get_text()
 * 
 *                     elif next_char in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                         # We need to repeat this so we return the ending
 *                         # char next. If it's not allowed, that'll error on
 */
          case 39:
          case 0x7B:
          case 0x7D:
          case 59:
          case 58:
          case 91:
          case 93:
          case 40:
          case 41:
          case 10:
          case 9:
          case 32:

          /* "srctools/_tokenizer.pyx":566
 *                         # char next. If it's not allowed, that'll error on
 *                         # next call.
 *                         self.char_index -= 1             # <<<<<<<<<<<<<<
 *                         return DIRECTIVE, self.buf_get_text()
 *                     else:
 */
          __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

          /* "srctools/_tokenizer.pyx":567
 *                         # next call.
 *                         self.char_index -= 1
 *                         return DIRECTIVE, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     else:
 *                         # Lower() is far cheaper, but only valid for ASCII.
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_7 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 567, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 567, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
          PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_DIRECTIVE);
          __Pyx_GIVEREF(__pyx_t_7);
          PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
          __pyx_t_7 = 0;
          __pyx_r = __pyx_t_3;
          __pyx_t_3 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":562
 *                         return DIRECTIVE, self.buf_get_text()
 * 
 *                     elif next_char in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                         # We need to repeat this so we return the ending
 *                         # char next. If it's not allowed, that'll error on
 */
          break;
          default:

          /* "srctools/_tokenizer.pyx":570
 *                     else:
 *                         # Lower() is far cheaper, but only valid for ASCII.
 *                         if next_char < 128:             # <<<<<<<<<<<<<<
 *                             self.buf_add_char(next_char.lower())
 *                         else:
 */
          __pyx_t_2 = ((__pyx_v_next_char < 0x80) != 0);
          if (__pyx_t_2) {

            /* "srctools/_tokenizer.pyx":571
 *                         # Lower() is far cheaper, but only valid for ASCII.
 *                         if next_char < 128:
 *                             self.buf_add_char(next_char.lower())             # <<<<<<<<<<<<<<
 *                         else:
 *                             # Might result in multiple output characters.
 */
            __pyx_t_4 = Py_UNICODE_TOLOWER(__pyx_v_next_char); 
            __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_t_4);

            /* "srctools/_tokenizer.pyx":570
 *                     else:
 *                         # Lower() is far cheaper, but only valid for ASCII.
 *                         if next_char < 128:             # <<<<<<<<<<<<<<
 *                             self.buf_add_char(next_char.lower())
 *                         else:
 */
            goto __pyx_L25;
          }

          /* "srctools/_tokenizer.pyx":574
 *                         else:
 *                             # Might result in multiple output characters.
 *                             for next_char in <str>next_char.casefold():             # <<<<<<<<<<<<<<
 *                                 self.buf_add_char(next_char)
 * 
 */
          /*else*/ {
            __pyx_t_7 = PyUnicode_FromOrdinal(__pyx_v_next_char); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 574, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_7);
            __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_casefold); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 574, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_8);
            __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
            __pyx_t_7 = NULL;
            if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
              __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_8);
              if (likely(__pyx_t_7)) {
                PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
                __Pyx_INCREF(__pyx_t_7);
                __Pyx_INCREF(function);
                __Pyx_DECREF_SET(__pyx_t_8, function);
              }
            }
            __pyx_t_3 = (__pyx_t_7) ? __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_7) : __Pyx_PyObject_CallNoArg(__pyx_t_8);
            __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
            if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 574, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
            if (unlikely(__pyx_t_3 == Py_None)) {
              PyErr_SetString(PyExc_TypeError, "'NoneType' is not iterable");
              __PYX_ERR(0, 574, __pyx_L1_error)
            }
            __Pyx_INCREF(((PyObject*)__pyx_t_3));
            __pyx_t_9 = ((PyObject*)__pyx_t_3);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            __pyx_t_12 = __Pyx_init_unicode_iteration(__pyx_t_9, (&__pyx_t_10), (&__pyx_t_11), (&__pyx_t_5)); if (unlikely(__pyx_t_12 == ((int)-1))) __PYX_ERR(0, 574, __pyx_L1_error)
            for (__pyx_t_13 = 0; __pyx_t_13 < __pyx_t_10; __pyx_t_13++) {
              __pyx_t_6 = __pyx_t_13;
              __pyx_v_next_char = __Pyx_PyUnicode_READ(__pyx_t_5, __pyx_t_11, __pyx_t_6);

              /* "srctools/_tokenizer.pyx":575
 *                             # Might result in multiple output characters.
 *                             for next_char in <str>next_char.casefold():
 *                                 self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             # Ignore Unicode Byte Order Mark on first lines
 */
              __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
            }
            __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          }
          __pyx_L25:;
          break;
        }
      }

      /* "srctools/_tokenizer.pyx":554
 * 
 *             # Directives
 *             elif next_char == '#':             # <<<<<<<<<<<<<<
 *                 self.buf_reset()
 *                 while True:
 */
      break;
      case 0xFEFF:

      /* "srctools/_tokenizer.pyx":579
 *             # Ignore Unicode Byte Order Mark on first lines
 *             elif next_char == '\uFEFF':
 *                 if self.line_num == 1:             # <<<<<<<<<<<<<<
 *                     continue
 *                 # else, we fall out of the if, and get an unexpected char
 */
      __pyx_t_2 = ((__pyx_v_self->__pyx_base.line_num == 1) != 0);
      if (__pyx_t_2) {

        /* "srctools/_tokenizer.pyx":580
 *             elif next_char == '\uFEFF':
 *                 if self.line_num == 1:
 *                     continue             # <<<<<<<<<<<<<<
 *                 # else, we fall out of the if, and get an unexpected char
 *                 # error.
 */
        goto __pyx_L4_continue;

        /* "srctools/_tokenizer.pyx":579
 *             # Ignore Unicode Byte Order Mark on first lines
 *             elif next_char == '\uFEFF':
 *                 if self.line_num == 1:             # <<<<<<<<<<<<<<
 *                     continue
 *                 # else, we fall out of the if, and get an unexpected char
 */
      }

      /* "srctools/_tokenizer.pyx":578
 * 
 *             # Ignore Unicode Byte Order Mark on first lines
 *             elif next_char == '\uFEFF':             # <<<<<<<<<<<<<<
 *                 if self.line_num == 1:
 *                     continue
 */
      break;
      default:

      /* "srctools/_tokenizer.pyx":586
 *             else: # Not-in can't be in a switch, so we need to nest this.
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 */
      switch (__pyx_v_next_char) {
        case 34:
        case 39:
        case 0x7B:
        case 0x7D:
        case 59:
        case 58:
        case 91:
        case 93:
        case 40:
        case 41:
        case 10:
        case 9:
        case 32:
        __pyx_t_2 = 0;
        break;
        default:
        __pyx_t_2 = 1;
        break;
      }
      __pyx_t_1 = (__pyx_t_2 != 0);
      if (likely(__pyx_t_1)) {

        /* "srctools/_tokenizer.pyx":587
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:
 *                     self.buf_reset()             # <<<<<<<<<<<<<<
 *                     self.buf_add_char(next_char)
 *                     while True:
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

        /* "srctools/_tokenizer.pyx":588
 *                 if next_char not in BARE_DISALLOWED:
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 *                     while True:
 *                         next_char = self._next_char()
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);

        /* "srctools/_tokenizer.pyx":589
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 *                     while True:             # <<<<<<<<<<<<<<
 *                         next_char = self._next_char()
 *                         if next_char == -1:
 */
        while (1) {

          /* "srctools/_tokenizer.pyx":590
 *                     self.buf_add_char(next_char)
 *                     while True:
 *                         next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if next_char == -1:
 *                             # Bare names at the end are actually fine.
 */
          __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((Py_UCS4)-2))) __PYX_ERR(0, 590, __pyx_L1_error)
          __pyx_v_next_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":591
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == -1:             # <<<<<<<<<<<<<<
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 */
          switch (__pyx_v_next_char) {
            case -1L:

            /* "srctools/_tokenizer.pyx":594
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 *                             return STRING, self.buf_get_text()             # <<<<<<<<<<<<<<
 * 
 *                         elif next_char in BARE_DISALLOWED:
 */
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 594, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_8 = PyTuple_New(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 594, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_8);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_STRING);
            PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_t_3);
            PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_t_3);
            __pyx_t_3 = 0;
            __pyx_r = __pyx_t_8;
            __pyx_t_8 = 0;
            goto __pyx_L0;

            /* "srctools/_tokenizer.pyx":591
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == -1:             # <<<<<<<<<<<<<<
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 */
            break;
            case 34:

            /* "srctools/_tokenizer.pyx":596
 *                             return STRING, self.buf_get_text()
 * 
 *                         elif next_char in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                             # We need to repeat this so we return the ending
 *                             # char next. If it's not allowed, that'll error on
 */
            case 39:
            case 0x7B:
            case 0x7D:
            case 59:
            case 58:
            case 91:
            case 93:
            case 40:
            case 41:
            case 10:
            case 9:
            case 32:

            /* "srctools/_tokenizer.pyx":601
 *                             # next call.
 *                             # We need to repeat this so we return the newline.
 *                             self.char_index -= 1             # <<<<<<<<<<<<<<
 *                             return (BARE_STRING if self.mark_bare_strings else STRING), self.buf_get_text()
 *                         else:
 */
            __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

            /* "srctools/_tokenizer.pyx":602
 *                             # We need to repeat this so we return the newline.
 *                             self.char_index -= 1
 *                             return (BARE_STRING if self.mark_bare_strings else STRING), self.buf_get_text()             # <<<<<<<<<<<<<<
 *                         else:
 *                             self.buf_add_char(next_char)
 */
            __Pyx_XDECREF(__pyx_r);
            if ((__pyx_v_self->mark_bare_strings != 0)) {
              __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BARE_STRING);
              __pyx_t_8 = __pyx_v_8srctools_10_tokenizer_BARE_STRING;
            } else {
              __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
              __pyx_t_8 = __pyx_v_8srctools_10_tokenizer_STRING;
            }
            __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 602, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 602, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_7);
            __Pyx_GIVEREF(__pyx_t_8);
            PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_8);
            __Pyx_GIVEREF(__pyx_t_3);
            PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_3);
            __pyx_t_8 = 0;
            __pyx_t_3 = 0;
            __pyx_r = __pyx_t_7;
            __pyx_t_7 = 0;
            goto __pyx_L0;

            /* "srctools/_tokenizer.pyx":596
 *                             return STRING, self.buf_get_text()
 * 
 *                         elif next_char in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                             # We need to repeat this so we return the ending
 *                             # char next. If it's not allowed, that'll error on
 */
            break;
            default:

            /* "srctools/_tokenizer.pyx":604
 *                             return (BARE_STRING if self.mark_bare_strings else STRING), self.buf_get_text()
 *                         else:
 *                             self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 *                 else:
 *                     raise self._error(f'Unexpected character "{next_char}"' '!')
 */
            __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char);
            break;
          }
        }

        /* "srctools/_tokenizer.pyx":586
 *             else: # Not-in can't be in a switch, so we need to nest this.
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 */
        goto __pyx_L29;
      }

      /* "srctools/_tokenizer.pyx":606
 *                             self.buf_add_char(next_char)
 *                 else:
 *                     raise self._error(f'Unexpected character "{next_char}"' '!')             # <<<<<<<<<<<<<<
 * 
 * 
 */
      /*else*/ {
        __pyx_t_7 = PyTuple_New(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 606, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __pyx_t_10 = 0;
        __pyx_t_4 = 127;
        __Pyx_INCREF(__pyx_kp_u_Unexpected_character);
        __pyx_t_10 += 22;
        __Pyx_GIVEREF(__pyx_kp_u_Unexpected_character);
        PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_kp_u_Unexpected_character);
        __pyx_t_3 = PyUnicode_FromOrdinal(__pyx_v_next_char); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 606, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_4 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_4) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_4;
        __pyx_t_10 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_3);
        __pyx_t_3 = 0;
        __Pyx_INCREF(__pyx_kp_u_);
        __pyx_t_10 += 2;
        __Pyx_GIVEREF(__pyx_kp_u_);
        PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_kp_u_);
        __pyx_t_3 = __Pyx_PyUnicode_Join(__pyx_t_7, 3, __pyx_t_10, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 606, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __pyx_t_7 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 606, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_Raise(__pyx_t_7, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        __PYX_ERR(0, 606, __pyx_L1_error)
      }
      __pyx_L29:;
      break;
    }
    __pyx_L4_continue:;
  }

  /* "srctools/_tokenizer.pyx":381
 *                 return (<str>chunk_obj)[0]
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair - this is the C version."""
 *         cdef:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_output);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":236
 *     cdef int char_index # Position inside cur_chunk
 * 
 *     cdef public bint string_bracket             # <<<<<<<<<<<<<<
 *     cdef public bint allow_escapes
 *     cdef public bint allow_star_comments
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_self->string_bracket); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 236, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.string_bracket.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 236, __pyx_L1_error)
  __pyx_v_self->string_bracket = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.string_bracket.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":237
 * 
 *     cdef public bint string_bracket
 *     cdef public bint allow_escapes             # <<<<<<<<<<<<<<
 *     cdef public bint allow_star_comments
 *     cdef public bint mark_bare_strings
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_self->allow_escapes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 237, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_escapes.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 237, __pyx_L1_error)
  __pyx_v_self->allow_escapes = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_escapes.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":238
 *     cdef public bint string_bracket
 *     cdef public bint allow_escapes
 *     cdef public bint allow_star_comments             # <<<<<<<<<<<<<<
 *     cdef public bint mark_bare_strings
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_self->allow_star_comments); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_star_comments.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 238, __pyx_L1_error)
  __pyx_v_self->allow_star_comments = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_star_comments.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":239
 *     cdef public bint allow_escapes
 *     cdef public bint allow_star_comments
 *     cdef public bint mark_bare_strings             # <<<<<<<<<<<<<<
 * 
 *     # Private buffer, to hold string parts we're constructing.
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_self->mark_bare_strings); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 239, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.mark_bare_strings.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 239, __pyx_L1_error)
  __pyx_v_self->mark_bare_strings = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.mark_bare_strings.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":616
 *     """
 *     cdef public object source
 *     def __init__(self, source, filename='', error=None) -> None:             # <<<<<<<<<<<<<<
 *         BaseTokenizer.__init__(self, filename, error)
 *         self.source = iter(source)
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_source = 0;
  PyObject *__pyx_v_filename = 0;
  PyObject *__pyx_v_error = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_source,&__pyx_n_s_filename,&__pyx_n_s_error,0};
    PyObject* values[3] = {0,0,0};
    values[1] = ((PyObject *)__pyx_kp_u__6);
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_source)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_filename);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_error);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 616, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_source = values[0];
    __pyx_v_filename = values[1];
    __pyx_v_error = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 0, 1, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 616, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer___init__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self), __pyx_v_source, __pyx_v_filename, __pyx_v_error);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer___init__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self, PyObject *__pyx_v_source, PyObject *__pyx_v_filename, PyObject *__pyx_v_error) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":617
 *     cdef public object source
 *     def __init__(self, source, filename='', error=None) -> None:
 *         BaseTokenizer.__init__(self, filename, error)             # <<<<<<<<<<<<<<
 *         self.source = iter(source)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer), __pyx_n_s_init); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 617, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_filename, __pyx_v_error};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 617, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_filename, __pyx_v_error};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 617, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 617, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, ((PyObject *)__pyx_v_self));
    __Pyx_INCREF(__pyx_v_filename);
    __Pyx_GIVEREF(__pyx_v_filename);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_filename);
    __Pyx_INCREF(__pyx_v_error);
    __Pyx_GIVEREF(__pyx_v_error);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_error);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 617, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":618
 *     def __init__(self, source, filename='', error=None) -> None:
 *         BaseTokenizer.__init__(self, filename, error)
 *         self.source = iter(source)             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(self):
 */
  __pyx_t_1 = PyObject_GetIter(__pyx_v_source); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 618, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->source);
  __Pyx_DECREF(__pyx_v_self->source);
  __pyx_v_self->source = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":616
 *     """
 *     cdef public object source
 *     def __init__(self, source, filename='', error=None) -> None:             # <<<<<<<<<<<<<<
 *         BaseTokenizer.__init__(self, filename, error)
 *         self.source = iter(source)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":620
 *         self.source = iter(source)
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         if self.error_type is TokenSyntaxError:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13IterTokenizer_3__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13IterTokenizer_3__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_2__repr__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13IterTokenizer_2__repr__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  Py_UCS4 __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "srctools/_tokenizer.pyx":621
 * 
 *     def __repr__(self):
 *         if self.error_type is TokenSyntaxError:             # <<<<<<<<<<<<<<
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 *         else:
 */
  __pyx_t_1 = (__pyx_v_self->__pyx_base.error_type == __pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":622
 *     def __repr__(self):
 *         if self.error_type is TokenSyntaxError:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'             # <<<<<<<<<<<<<<
 *         else:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r}, {self.error_type!r})'
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = PyTuple_New(5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 622, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = 0;
    __pyx_t_5 = 127;
    __Pyx_INCREF(__pyx_kp_u_IterTokenizer);
    __pyx_t_4 += 14;
    __Pyx_GIVEREF(__pyx_kp_u_IterTokenizer);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_IterTokenizer);
    __pyx_t_6 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->source), __pyx_empty_unicode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 622, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_6);
    __pyx_t_6 = 0;
    __Pyx_INCREF(__pyx_kp_u__19);
    __pyx_t_4 += 2;
    __Pyx_GIVEREF(__pyx_kp_u__19);
    PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__19);
    __pyx_t_6 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->__pyx_base.filename), __pyx_empty_unicode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 622, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_3, 3, __pyx_t_6);
    __pyx_t_6 = 0;
    __Pyx_INCREF(__pyx_kp_u__20);
    __pyx_t_4 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__20);
    PyTuple_SET_ITEM(__pyx_t_3, 4, __pyx_kp_u__20);
    __pyx_t_6 = __Pyx_PyUnicode_Join(__pyx_t_3, 5, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 622, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_6;
    __pyx_t_6 = 0;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":621
 * 
 *     def __repr__(self):
 *         if self.error_type is TokenSyntaxError:             # <<<<<<<<<<<<<<
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 *         else:
 */
  }

  /* "srctools/_tokenizer.pyx":624
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 *         else:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r}, {self.error_type!r})'             # <<<<<<<<<<<<<<
 * 
 *     cdef next_token(self):
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_6 = PyTuple_New(7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 624, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_4 = 0;
    __pyx_t_5 = 127;
    __Pyx_INCREF(__pyx_kp_u_IterTokenizer);
    __pyx_t_4 += 14;
    __Pyx_GIVEREF(__pyx_kp_u_IterTokenizer);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_kp_u_IterTokenizer);
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->source), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 624, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__19);
    __pyx_t_4 += 2;
    __Pyx_GIVEREF(__pyx_kp_u__19);
    PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_kp_u__19);
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->__pyx_base.filename), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 624, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_6, 3, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__19);
    __pyx_t_4 += 2;
    __Pyx_GIVEREF(__pyx_kp_u__19);
    PyTuple_SET_ITEM(__pyx_t_6, 4, __pyx_kp_u__19);
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->__pyx_base.error_type), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 624, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_6, 5, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__20);
    __pyx_t_4 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__20);
    PyTuple_SET_ITEM(__pyx_t_6, 6, __pyx_kp_u__20);
    __pyx_t_3 = __Pyx_PyUnicode_Join(__pyx_t_6, 7, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 624, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;
  }

  /* "srctools/_tokenizer.pyx":620
 *         self.source = iter(source)
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         if self.error_type is TokenSyntaxError:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":626
 *             return f'IterTokenizer({self.source!r}, {self.filename!r}, {self.error_type!r})'
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         try:
 *             return next(self.source)
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_13IterTokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("next_token", 0);

  /* "srctools/_tokenizer.pyx":627
 * 
 *     cdef next_token(self):
 *         try:             # <<<<<<<<<<<<<<
 *             return next(self.source)
 *         except StopIteration:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "srctools/_tokenizer.pyx":628
 *     cdef next_token(self):
 *         try:
 *             return next(self.source)             # <<<<<<<<<<<<<<
 *         except StopIteration:
 *             return EOF_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __pyx_v_self->source;
      __Pyx_INCREF(__pyx_t_4);
      __pyx_t_5 = __Pyx_PyIter_Next(__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 628, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_r = __pyx_t_5;
      __pyx_t_5 = 0;
      goto __pyx_L7_try_return;

      /* "srctools/_tokenizer.pyx":627
 * 
 *     cdef next_token(self):
 *         try:             # <<<<<<<<<<<<<<
 *             return next(self.source)
 *         except StopIteration:
 */
    }
    __pyx_L3_error:;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "srctools/_tokenizer.pyx":629
 *         try:
 *             return next(self.source)
 *         except StopIteration:             # <<<<<<<<<<<<<<
 *             return EOF_TUP
 * 
 */
    __pyx_t_6 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_StopIteration);
    if (__pyx_t_6) {
      __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_4, &__pyx_t_7) < 0) __PYX_ERR(0, 629, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_t_7);

      /* "srctools/_tokenizer.pyx":630
 *             return next(self.source)
 *         except StopIteration:
 *             return EOF_TUP             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EOF_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_EOF_TUP;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      goto __pyx_L6_except_return;
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "srctools/_tokenizer.pyx":627
 * 
 *     cdef next_token(self):
 *         try:             # <<<<<<<<<<<<<<
 *             return next(self.source)
 *         except StopIteration:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L7_try_return:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L0;
    __pyx_L6_except_return:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L0;
  }

  /* "srctools/_tokenizer.pyx":626
 *             return f'IterTokenizer({self.source!r}, {self.filename!r}, {self.error_type!r})'
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         try:
 *             return next(self.source)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":615
 *     code.
 *     """
 *     cdef public object source             # <<<<<<<<<<<<<<
 *     def __init__(self, source, filename='', error=None) -> None:
 *         BaseTokenizer.__init__(self, filename, error)
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source___get__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source___get__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->source);
  __pyx_r = __pyx_v_self->source;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_2__set__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__", 0);
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->source);
  __Pyx_DECREF(__pyx_v_self->source);
  __pyx_v_self->source = __pyx_v_value;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_4__del__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_4__del__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->source);
  __Pyx_DECREF(__pyx_v_self->source);
  __pyx_v_self->source = Py_None;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":641
 *     cdef Tokenizer tok
 * 
 *     def __cinit__(self, Tokenizer tok not None):             # <<<<<<<<<<<<<<
 *         self.tok = tok
 * 
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_tok = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(0, 641, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_tok = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)values[0]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 641, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_tok), __pyx_ptype_8srctools_10_tokenizer_Tokenizer, 0, "tok", 0))) __PYX_ERR(0, 641, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter___cinit__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self), __pyx_v_tok);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter___cinit__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self, struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_tok) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "srctools/_tokenizer.pyx":642
 * 
 *     def __cinit__(self, Tokenizer tok not None):
 *         self.tok = tok             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(self):
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_tok));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_tok));
  __Pyx_GOTREF(__pyx_v_self->tok);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->tok));
  __pyx_v_self->tok = __pyx_v_tok;

  /* "srctools/_tokenizer.pyx":641
 *     cdef Tokenizer tok
 * 
 *     def __cinit__(self, Tokenizer tok not None):             # <<<<<<<<<<<<<<
 *         self.tok = tok
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":644
 *         self.tok = tok
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_3__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_3__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_2__repr__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_2__repr__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  Py_UCS4 __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "srctools/_tokenizer.pyx":645
 * 
 *     def __repr__(self):
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self, tok):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 645, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = 0;
  __pyx_t_3 = 127;
  __Pyx_INCREF(__pyx_kp_u_srctools_tokenizer_BaseTokenize);
  __pyx_t_2 += 57;
  __Pyx_GIVEREF(__pyx_kp_u_srctools_tokenizer_BaseTokenize);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_kp_u_srctools_tokenizer_BaseTokenize);
  __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_id, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 645, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_Format(__pyx_t_4, __pyx_n_u_X); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 645, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_3 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_5) > __pyx_t_3) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_5) : __pyx_t_3;
  __pyx_t_2 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_5);
  __pyx_t_5 = 0;
  __Pyx_INCREF(__pyx_kp_u__21);
  __pyx_t_2 += 1;
  __Pyx_GIVEREF(__pyx_kp_u__21);
  PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_kp_u__21);
  __pyx_t_5 = __Pyx_PyUnicode_Join(__pyx_t_1, 3, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 645, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_5;
  __pyx_t_5 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":644
 *         self.tok = tok
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":647
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'
 * 
 *     def __init__(self, tok):             # <<<<<<<<<<<<<<
 *         raise TypeError("Cannot create '_NewlinesIter' instances")
 * 
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  CYTHON_UNUSED PyObject *__pyx_v_tok = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 647, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_tok = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 647, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_4__init__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self), __pyx_v_tok);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_4__init__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_tok) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":648
 * 
 *     def __init__(self, tok):
 *         raise TypeError("Cannot create '_NewlinesIter' instances")             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__22, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 648, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 648, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":647
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'
 * 
 *     def __init__(self, tok):             # <<<<<<<<<<<<<<
 *         raise TypeError("Cannot create '_NewlinesIter' instances")
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":650
 *         raise TypeError("Cannot create '_NewlinesIter' instances")
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_7__iter__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_7__iter__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_6__iter__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_6__iter__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__", 0);

  /* "srctools/_tokenizer.pyx":651
 * 
 *     def __iter__(self):
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __next__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":650
 *         raise TypeError("Cannot create '_NewlinesIter' instances")
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":653
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         while True:
 *             tok_and_val = self.tok.next_token()
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__next__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_8__next__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_8__next__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_v_tok_and_val = NULL;
  PyObject *__pyx_v_token = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__next__", 0);

  /* "srctools/_tokenizer.pyx":654
 * 
 *     def __next__(self):
 *         while True:             # <<<<<<<<<<<<<<
 *             tok_and_val = self.tok.next_token()
 *             token = (<tuple?>tok_and_val)[0]
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":655
 *     def __next__(self):
 *         while True:
 *             tok_and_val = self.tok.next_token()             # <<<<<<<<<<<<<<
 *             token = (<tuple?>tok_and_val)[0]
 * 
 */
    __pyx_t_1 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->tok->__pyx_base.__pyx_vtab)->__pyx_base.next_token(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->tok)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 655, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_XDECREF_SET(__pyx_v_tok_and_val, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":656
 *         while True:
 *             tok_and_val = self.tok.next_token()
 *             token = (<tuple?>tok_and_val)[0]             # <<<<<<<<<<<<<<
 * 
 *             # Only our code is doing next_token here, so the tuples are
 */
    if (!(likely(PyTuple_CheckExact(__pyx_v_tok_and_val))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v_tok_and_val)->tp_name), 0))) __PYX_ERR(0, 656, __pyx_L1_error)
    if (unlikely(__pyx_v_tok_and_val == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 656, __pyx_L1_error)
    }
    __pyx_t_1 = __Pyx_GetItemInt_Tuple(((PyObject*)__pyx_v_tok_and_val), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 656, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_XDECREF_SET(__pyx_v_token, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":660
 *             # Only our code is doing next_token here, so the tuples are
 *             # going to be this same instance.
 *             if token is EOF:             # <<<<<<<<<<<<<<
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 */
    __pyx_t_2 = (__pyx_v_token == __pyx_v_8srctools_10_tokenizer_EOF);
    __pyx_t_3 = (__pyx_t_2 != 0);
    if (unlikely(__pyx_t_3)) {

      /* "srctools/_tokenizer.pyx":661
 *             # going to be this same instance.
 *             if token is EOF:
 *                 raise StopIteration             # <<<<<<<<<<<<<<
 *             elif token is not NEWLINE:
 *                 return tok_and_val
 */
      __Pyx_Raise(__pyx_builtin_StopIteration, 0, 0, 0);
      __PYX_ERR(0, 661, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":660
 *             # Only our code is doing next_token here, so the tuples are
 *             # going to be this same instance.
 *             if token is EOF:             # <<<<<<<<<<<<<<
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 */
    }

    /* "srctools/_tokenizer.pyx":662
 *             if token is EOF:
 *                 raise StopIteration
 *             elif token is not NEWLINE:             # <<<<<<<<<<<<<<
 *                 return tok_and_val
 * 
 */
    __pyx_t_3 = (__pyx_v_token != __pyx_v_8srctools_10_tokenizer_NEWLINE);
    __pyx_t_2 = (__pyx_t_3 != 0);
    if (__pyx_t_2) {

      /* "srctools/_tokenizer.pyx":663
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 *                 return tok_and_val             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_tok_and_val);
      __pyx_r = __pyx_v_tok_and_val;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":662
 *             if token is EOF:
 *                 raise StopIteration
 *             elif token is not NEWLINE:             # <<<<<<<<<<<<<<
 *                 return tok_and_val
 * 
 */
    }
  }

  /* "srctools/_tokenizer.pyx":653
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         while True:
 *             tok_and_val = self.tok.next_token()
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__next__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tok_and_val);
  __Pyx_XDECREF(__pyx_v_token);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":665
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__[] = "This cannot be pickled - the Python version does not have this class.";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__ = {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "srctools/_tokenizer.pyx":667
 *     def __reduce__(self):
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_NotImplementedError, __pyx_tuple__23, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 667, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 667, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":665
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":671
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None: str) -> str:             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_1escape_text(PyObject *__pyx_self, PyObject *__pyx_v_text); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_escape_text[] = "escape_text(unicode text: str) -> str\nEscape special characters and backslashes, so tokenising reproduces them.\n\n    Specifically, \\, \", tab, and newline.\n    ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_1escape_text = {"escape_text", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_1escape_text, METH_O, __pyx_doc_8srctools_10_tokenizer_escape_text};
static PyObject *__pyx_pw_8srctools_10_tokenizer_1escape_text(PyObject *__pyx_self, PyObject *__pyx_v_text) {
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("escape_text (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_text), (&PyUnicode_Type), 0, "text", 1))) __PYX_ERR(0, 671, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_escape_text(__pyx_self, ((PyObject*)__pyx_v_text));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_escape_text(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_text) {
  PyObject *__pyx_v_enc_text = 0;
  Py_ssize_t __pyx_v_final_len;
  char __pyx_v_letter;
  char *__pyx_v_out_buff;
  int __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  char *__pyx_t_4;
  char *__pyx_t_5;
  char *__pyx_t_6;
  char *__pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  char const *__pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("escape_text", 0);

  /* "srctools/_tokenizer.pyx":677
 *     """
 *     # UTF8 = ASCII for those chars, so we can replace in that form.
 *     cdef bytes enc_text = text.encode('utf8')             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t final_len = len(enc_text)
 *     cdef char letter
 */
  __pyx_t_1 = PyUnicode_AsUTF8String(__pyx_v_text); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 677, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_enc_text = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":678
 *     # UTF8 = ASCII for those chars, so we can replace in that form.
 *     cdef bytes enc_text = text.encode('utf8')
 *     cdef Py_ssize_t final_len = len(enc_text)             # <<<<<<<<<<<<<<
 *     cdef char letter
 *     for letter in enc_text:
 */
  if (unlikely(__pyx_v_enc_text == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 678, __pyx_L1_error)
  }
  __pyx_t_2 = PyBytes_GET_SIZE(__pyx_v_enc_text); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 678, __pyx_L1_error)
  __pyx_v_final_len = __pyx_t_2;

  /* "srctools/_tokenizer.pyx":680
 *     cdef Py_ssize_t final_len = len(enc_text)
 *     cdef char letter
 *     for letter in enc_text:             # <<<<<<<<<<<<<<
 *         if letter in (b'\\', b'"', b'\t', b'\n'):
 *             final_len += 1
 */
  if (unlikely(__pyx_v_enc_text == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' is not iterable");
    __PYX_ERR(0, 680, __pyx_L1_error)
  }
  __Pyx_INCREF(__pyx_v_enc_text);
  __pyx_t_3 = __pyx_v_enc_text;
  __pyx_t_5 = PyBytes_AS_STRING(__pyx_t_3);
  __pyx_t_6 = (__pyx_t_5 + PyBytes_GET_SIZE(__pyx_t_3));
  for (__pyx_t_7 = __pyx_t_5; __pyx_t_7 < __pyx_t_6; __pyx_t_7++) {
    __pyx_t_4 = __pyx_t_7;
    __pyx_v_letter = (__pyx_t_4[0]);

    /* "srctools/_tokenizer.pyx":681
 *     cdef char letter
 *     for letter in enc_text:
 *         if letter in (b'\\', b'"', b'\t', b'\n'):             # <<<<<<<<<<<<<<
 *             final_len += 1
 * 
 */
    switch (__pyx_v_letter) {
      case '\\':
      case '"':
      case '\t':
      case '\n':

      /* "srctools/_tokenizer.pyx":682
 *     for letter in enc_text:
 *         if letter in (b'\\', b'"', b'\t', b'\n'):
 *             final_len += 1             # <<<<<<<<<<<<<<
 * 
 *     cdef char * out_buff
 */
      __pyx_v_final_len = (__pyx_v_final_len + 1);

      /* "srctools/_tokenizer.pyx":681
 *     cdef char letter
 *     for letter in enc_text:
 *         if letter in (b'\\', b'"', b'\t', b'\n'):             # <<<<<<<<<<<<<<
 *             final_len += 1
 * 
 */
      break;
      default: break;
    }
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "srctools/_tokenizer.pyx":685
 * 
 *     cdef char * out_buff
 *     cdef int i = 0             # <<<<<<<<<<<<<<
 *     try:
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 */
  __pyx_v_i = 0;

  /* "srctools/_tokenizer.pyx":686
 *     cdef char * out_buff
 *     cdef int i = 0
 *     try:             # <<<<<<<<<<<<<<
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 *         for letter in enc_text:
 */
  /*try:*/ {

    /* "srctools/_tokenizer.pyx":687
 *     cdef int i = 0
 *     try:
 *         out_buff = <char *>PyMem_Malloc(final_len+1)             # <<<<<<<<<<<<<<
 *         for letter in enc_text:
 *             if letter == b'\\':
 */
    __pyx_v_out_buff = ((char *)PyMem_Malloc((__pyx_v_final_len + 1)));

    /* "srctools/_tokenizer.pyx":688
 *     try:
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 *         for letter in enc_text:             # <<<<<<<<<<<<<<
 *             if letter == b'\\':
 *                 out_buff[i] = b'\\'
 */
    if (unlikely(__pyx_v_enc_text == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' is not iterable");
      __PYX_ERR(0, 688, __pyx_L6_error)
    }
    __Pyx_INCREF(__pyx_v_enc_text);
    __pyx_t_3 = __pyx_v_enc_text;
    __pyx_t_6 = PyBytes_AS_STRING(__pyx_t_3);
    __pyx_t_5 = (__pyx_t_6 + PyBytes_GET_SIZE(__pyx_t_3));
    for (__pyx_t_7 = __pyx_t_6; __pyx_t_7 < __pyx_t_5; __pyx_t_7++) {
      __pyx_t_4 = __pyx_t_7;
      __pyx_v_letter = (__pyx_t_4[0]);

      /* "srctools/_tokenizer.pyx":689
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 *         for letter in enc_text:
 *             if letter == b'\\':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
      switch (__pyx_v_letter) {
        case '\\':

        /* "srctools/_tokenizer.pyx":690
 *         for letter in enc_text:
 *             if letter == b'\\':
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *                 i += 1
 *                 out_buff[i] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":691
 *             if letter == b'\\':
 *                 out_buff[i] = b'\\'
 *                 i += 1             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *             elif letter == b'"':
 */
        __pyx_v_i = (__pyx_v_i + 1);

        /* "srctools/_tokenizer.pyx":692
 *                 out_buff[i] = b'\\'
 *                 i += 1
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *             elif letter == b'"':
 *                 out_buff[i] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":689
 *         out_buff = <char *>PyMem_Malloc(final_len+1)
 *         for letter in enc_text:
 *             if letter == b'\\':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
        break;
        case '"':

        /* "srctools/_tokenizer.pyx":694
 *                 out_buff[i] = b'\\'
 *             elif letter == b'"':
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *                 i += 1
 *                 out_buff[i] = b'"'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":695
 *             elif letter == b'"':
 *                 out_buff[i] = b'\\'
 *                 i += 1             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'"'
 *             elif letter == b'\t':
 */
        __pyx_v_i = (__pyx_v_i + 1);

        /* "srctools/_tokenizer.pyx":696
 *                 out_buff[i] = b'\\'
 *                 i += 1
 *                 out_buff[i] = b'"'             # <<<<<<<<<<<<<<
 *             elif letter == b'\t':
 *                 out_buff[i] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '"';

        /* "srctools/_tokenizer.pyx":693
 *                 i += 1
 *                 out_buff[i] = b'\\'
 *             elif letter == b'"':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
        break;
        case '\t':

        /* "srctools/_tokenizer.pyx":698
 *                 out_buff[i] = b'"'
 *             elif letter == b'\t':
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *                 i += 1
 *                 out_buff[i] = b't'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":699
 *             elif letter == b'\t':
 *                 out_buff[i] = b'\\'
 *                 i += 1             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b't'
 *             elif letter == b'\n':
 */
        __pyx_v_i = (__pyx_v_i + 1);

        /* "srctools/_tokenizer.pyx":700
 *                 out_buff[i] = b'\\'
 *                 i += 1
 *                 out_buff[i] = b't'             # <<<<<<<<<<<<<<
 *             elif letter == b'\n':
 *                 out_buff[i] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = 't';

        /* "srctools/_tokenizer.pyx":697
 *                 i += 1
 *                 out_buff[i] = b'"'
 *             elif letter == b'\t':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
        break;
        case '\n':

        /* "srctools/_tokenizer.pyx":702
 *                 out_buff[i] = b't'
 *             elif letter == b'\n':
 *                 out_buff[i] = b'\\'             # <<<<<<<<<<<<<<
 *                 i += 1
 *                 out_buff[i] = b'n'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = '\\';

        /* "srctools/_tokenizer.pyx":703
 *             elif letter == b'\n':
 *                 out_buff[i] = b'\\'
 *                 i += 1             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'n'
 *             else:
 */
        __pyx_v_i = (__pyx_v_i + 1);

        /* "srctools/_tokenizer.pyx":704
 *                 out_buff[i] = b'\\'
 *                 i += 1
 *                 out_buff[i] = b'n'             # <<<<<<<<<<<<<<
 *             else:
 *                 out_buff[i] = letter
 */
        (__pyx_v_out_buff[__pyx_v_i]) = 'n';

        /* "srctools/_tokenizer.pyx":701
 *                 i += 1
 *                 out_buff[i] = b't'
 *             elif letter == b'\n':             # <<<<<<<<<<<<<<
 *                 out_buff[i] = b'\\'
 *                 i += 1
 */
        break;
        default:

        /* "srctools/_tokenizer.pyx":706
 *                 out_buff[i] = b'n'
 *             else:
 *                 out_buff[i] = letter             # <<<<<<<<<<<<<<
 *             i += 1
 *         out_buff[final_len] = b'\0'
 */
        (__pyx_v_out_buff[__pyx_v_i]) = __pyx_v_letter;
        break;
      }

      /* "srctools/_tokenizer.pyx":707
 *             else:
 *                 out_buff[i] = letter
 *             i += 1             # <<<<<<<<<<<<<<
 *         out_buff[final_len] = b'\0'
 *         return PyUnicode_FromStringAndSize(out_buff, final_len)
 */
      __pyx_v_i = (__pyx_v_i + 1);
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":708
 *                 out_buff[i] = letter
 *             i += 1
 *         out_buff[final_len] = b'\0'             # <<<<<<<<<<<<<<
 *         return PyUnicode_FromStringAndSize(out_buff, final_len)
 *     finally:
 */
    (__pyx_v_out_buff[__pyx_v_final_len]) = '\x00';

    /* "srctools/_tokenizer.pyx":709
 *             i += 1
 *         out_buff[final_len] = b'\0'
 *         return PyUnicode_FromStringAndSize(out_buff, final_len)             # <<<<<<<<<<<<<<
 *     finally:
 *         PyMem_Free(out_buff)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_1 = PyUnicode_FromStringAndSize(__pyx_v_out_buff, __pyx_v_final_len); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 709, __pyx_L6_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_r = ((PyObject*)__pyx_t_1);
    __pyx_t_1 = 0;
    goto __pyx_L5_return;
  }

  /* "srctools/_tokenizer.pyx":711
 *         return PyUnicode_FromStringAndSize(out_buff, final_len)
 *     finally:
 *         PyMem_Free(out_buff)             # <<<<<<<<<<<<<<
 * 
 * cdef extern from *:  # Allow ourselves to access one of the feature flag macros.
 */
  /*finally:*/ {
    __pyx_L6_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13) < 0)) __Pyx_ErrFetch(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __pyx_t_8 = __pyx_lineno; __pyx_t_9 = __pyx_clineno; __pyx_t_10 = __pyx_filename;
      {
        PyMem_Free(__pyx_v_out_buff);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_14);
        __Pyx_XGIVEREF(__pyx_t_15);
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_ExceptionReset(__pyx_t_14, __pyx_t_15, __pyx_t_16);
      }
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_XGIVEREF(__pyx_t_12);
      __Pyx_XGIVEREF(__pyx_t_13);
      __Pyx_ErrRestore(__pyx_t_11, __pyx_t_12, __pyx_t_13);
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __pyx_lineno = __pyx_t_8; __pyx_clineno = __pyx_t_9; __pyx_filename = __pyx_t_10;
      goto __pyx_L1_error;
    }
    __pyx_L5_return: {
      __pyx_t_17 = __pyx_r;
      __pyx_r = 0;
      PyMem_Free(__pyx_v_out_buff);
      __pyx_r = __pyx_t_17;
      __pyx_t_17 = 0;
      goto __pyx_L0;
    }
  }

  /* "srctools/_tokenizer.pyx":671
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None: str) -> str:             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("srctools._tokenizer.escape_text", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_enc_text);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer __pyx_vtable_8srctools_10_tokenizer_BaseTokenizer;

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)o);
  p->__pyx_vtab = __pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer;
  p->error_type = Py_None; Py_INCREF(Py_None);
  p->filename = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->pushback_tok = Py_None; Py_INCREF(Py_None);
  p->pushback_val = Py_None; Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_BaseTokenizer(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->error_type);
  Py_CLEAR(p->filename);
  Py_CLEAR(p->pushback_tok);
  Py_CLEAR(p->pushback_val);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_BaseTokenizer(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)o;
  if (p->error_type) {
    e = (*v)(p->error_type, a); if (e) return e;
  }
  if (p->pushback_tok) {
    e = (*v)(p->pushback_tok, a); if (e) return e;
  }
  if (p->pushback_val) {
    e = (*v)(p->pushback_val, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_BaseTokenizer(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)o;
  tmp = ((PyObject*)p->error_type);
  p->error_type = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->pushback_tok);
  p->pushback_tok = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->pushback_val);
  p->pushback_val = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_filename(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_filename(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_3__set__(o, v);
  }
  else {
    return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_5__del__(o);
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_line_num(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_line_num(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_BaseTokenizer[] = {
  {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__},
  {"error", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_5error, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_4error},
  {"push_back", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11push_back, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_10push_back},
  {"peek", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13peek, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_12peek},
  {"skipping_newlines", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_15skipping_newlines, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_14skipping_newlines},
  {"expect", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_17expect, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_16expect},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_8srctools_10_tokenizer_BaseTokenizer[] = {
  {(char *)"filename", __pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_filename, __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_filename, (char *)"filename: unicode", 0},
  {(char *)"line_num", __pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_line_num, __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_line_num, (char *)"line_num: 'int'", 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_BaseTokenizer = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.BaseTokenizer", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_BaseTokenizer, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "BaseTokenizer(filename, error)\nProvides an interface for processing text into tokens.\n\n     It then provides tools for using those to parse data.\n     This is an abstract class, a subclass must be used to provide a source\n     for the tokens.\n    ", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_BaseTokenizer, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_BaseTokenizer, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9__iter__, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer_BaseTokenizer, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_8srctools_10_tokenizer_BaseTokenizer, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer __pyx_vtable_8srctools_10_tokenizer_Tokenizer;

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_Tokenizer(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p;
  PyObject *o = __pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer(t, a, k);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o);
  p->__pyx_base.__pyx_vtab = (struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer*)__pyx_vtabptr_8srctools_10_tokenizer_Tokenizer;
  p->cur_chunk = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->chunk_iter = Py_None; Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(o, __pyx_empty_tuple, NULL) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_Tokenizer(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) + 1);
    __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(o);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) - 1);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->cur_chunk);
  Py_CLEAR(p->chunk_iter);
  PyObject_GC_Track(o);
  __pyx_tp_dealloc_8srctools_10_tokenizer_BaseTokenizer(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_Tokenizer(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  e = __pyx_tp_traverse_8srctools_10_tokenizer_BaseTokenizer(o, v, a); if (e) return e;
  if (p->chunk_iter) {
    e = (*v)(p->chunk_iter, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_Tokenizer(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  __pyx_tp_clear_8srctools_10_tokenizer_BaseTokenizer(o);
  tmp = ((PyObject*)p->chunk_iter);
  p->chunk_iter = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_string_bracket(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_string_bracket(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_mark_bare_strings(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_mark_bare_strings(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_17mark_bare_strings_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_Tokenizer[] = {
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_8srctools_10_tokenizer_Tokenizer[] = {
  {(char *)"string_bracket", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_string_bracket, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_string_bracket, (char *)"string_bracket: 'bool'", 0},
  {(char *)"allow_escapes", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes, (char *)"allow_escapes: 'bool'", 0},
  {(char *)"allow_star_comments", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments, (char *)"allow_star_comments: 'bool'", 0},
  {(char *)"mark_bare_strings", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_mark_bare_strings, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_mark_bare_strings, (char *)"mark_bare_strings: 'bool'", 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_Tokenizer = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.Tokenizer", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_Tokenizer, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__, /*tp_call*/
  #else
  0, /*tp_call*/
  #endif
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "Tokenizer(data, filename=None, error=None, bool string_bracket=False, bool allow_escapes=True, bool allow_star_comments=False, bool mark_bare_strings=False)\nProcesses text data into groups of tokens.\n\n    This mainly groups strings and removes comments.\n\n    Due to many inconsistencies in Valve's parsing of files,\n    several options are available to control whether different\n    syntaxes are accepted:\n        * string_bracket parses [bracket] blocks as a single string-like block.\n          If disabled these are parsed as BRACK_OPEN, STRING, BRACK_CLOSE.\n        * allow_escapes controls whether \\n-style escapes are expanded.\n        * allow_star_comments if enabled allows /* */ comments.\n    ", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_Tokenizer, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_Tokenizer, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9__iter__, /*tp_iter*/
  #else
  0, /*tp_iter*/
  #endif
  0, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer_Tokenizer, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_8srctools_10_tokenizer_Tokenizer, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_Tokenizer, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_IterTokenizer __pyx_vtable_8srctools_10_tokenizer_IterTokenizer;

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_IterTokenizer(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *p;
  PyObject *o = __pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer(t, a, k);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)o);
  p->__pyx_base.__pyx_vtab = (struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer*)__pyx_vtabptr_8srctools_10_tokenizer_IterTokenizer;
  p->source = Py_None; Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_IterTokenizer(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->source);
  PyObject_GC_Track(o);
  __pyx_tp_dealloc_8srctools_10_tokenizer_BaseTokenizer(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_IterTokenizer(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)o;
  e = __pyx_tp_traverse_8srctools_10_tokenizer_BaseTokenizer(o, v, a); if (e) return e;
  if (p->source) {
    e = (*v)(p->source, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_IterTokenizer(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)o;
  __pyx_tp_clear_8srctools_10_tokenizer_BaseTokenizer(o);
  tmp = ((PyObject*)p->source);
  p->source = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_13IterTokenizer_source(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_13IterTokenizer_source(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_3__set__(o, v);
  }
  else {
    return __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_5__del__(o);
  }
}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_IterTokenizer[] = {
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_8srctools_10_tokenizer_IterTokenizer[] = {
  {(char *)"source", __pyx_getprop_8srctools_10_tokenizer_13IterTokenizer_source, __pyx_setprop_8srctools_10_tokenizer_13IterTokenizer_source, (char *)"source: object", 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_IterTokenizer = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.IterTokenizer", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_IterTokenizer, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_3__repr__, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__, /*tp_call*/
  #else
  0, /*tp_call*/
  #endif
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "IterTokenizer(source, filename=u'', error=None) -> None\nWraps a token iterator to provide the tokenizer interface.\n\n    This is useful to pre-process a token stream before parsing it with other\n    code.\n    ", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_IterTokenizer, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_IterTokenizer, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9__iter__, /*tp_iter*/
  #else
  0, /*tp_iter*/
  #endif
  0, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer_IterTokenizer, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_8srctools_10_tokenizer_IterTokenizer, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_IterTokenizer, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};

static PyObject *__pyx_tp_new_8srctools_10_tokenizer__NewlinesIter(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *p;
  PyObject *o;
  o = (*t->tp_alloc)(t, 0);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)o);
  p->tok = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)Py_None); Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer__NewlinesIter(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->tok);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer__NewlinesIter(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)o;
  if (p->tok) {
    e = (*v)(((PyObject *)p->tok), a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer__NewlinesIter(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)o;
  tmp = ((PyObject*)p->tok);
  p->tok = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__(PyObject *self, CYTHON_UNUSED PyObject *arg) {return __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__(self);}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer__NewlinesIter[] = {
  {"__next__", (PyCFunction)__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__, METH_NOARGS|METH_COEXIST, 0},
  {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__},
  {0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer__NewlinesIter = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer._NewlinesIter", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer__NewlinesIter, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_3__repr__, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "Iterate over the tokens, skipping newlines.", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer__NewlinesIter, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer__NewlinesIter, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_7__iter__, /*tp_iter*/
  __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer__NewlinesIter, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer__NewlinesIter, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};

static PyMethodDef __pyx_methods[] = {
  {0, 0, 0, 0}
};

#if PY_MAJOR_VERSION >= 3
#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec__tokenizer(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec__tokenizer},
  {0, NULL}
};
#endif

static struct PyModuleDef __pyx_moduledef = {
    PyModuleDef_HEAD_INIT,
    "_tokenizer",
    __pyx_k_Cython_version_of_the_Tokenizer, /* m_doc */
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    0, /* m_size */
  #else
    -1, /* m_size */
  #endif
    __pyx_methods /* m_methods */,
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    __pyx_moduledef_slots, /* m_slots */
  #else
    NULL, /* m_reload */
  #endif
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif
#ifndef CYTHON_SMALL_CODE
#if defined(__clang__)
    #define CYTHON_SMALL_CODE
#elif defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 3))
    #define CYTHON_SMALL_CODE __attribute__((cold))
#else
    #define CYTHON_SMALL_CODE
#endif
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_kp_u_, __pyx_k_, sizeof(__pyx_k_), 0, 1, 0, 0},
  {&__pyx_kp_u_Abstract_method, __pyx_k_Abstract_method, sizeof(__pyx_k_Abstract_method), 0, 1, 0, 0},
  {&__pyx_n_s_AttributeError, __pyx_k_AttributeError, sizeof(__pyx_k_AttributeError), 0, 0, 1, 1},
  {&__pyx_n_s_BARE_STRING, __pyx_k_BARE_STRING, sizeof(__pyx_k_BARE_STRING), 0, 0, 1, 1},
  {&__pyx_n_s_BRACE_CLOSE, __pyx_k_BRACE_CLOSE, sizeof(__pyx_k_BRACE_CLOSE), 0, 0, 1, 1},
  {&__pyx_n_s_BRACE_OPEN, __pyx_k_BRACE_OPEN, sizeof(__pyx_k_BRACE_OPEN), 0, 0, 1, 1},
  {&__pyx_n_s_BRACK_CLOSE, __pyx_k_BRACK_CLOSE, sizeof(__pyx_k_BRACK_CLOSE), 0, 0, 1, 1},
  {&__pyx_n_s_BRACK_OPEN, __pyx_k_BRACK_OPEN, sizeof(__pyx_k_BRACK_OPEN), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer, __pyx_k_BaseTokenizer, sizeof(__pyx_k_BaseTokenizer), 0, 0, 1, 1},
  {&__pyx_n_u_BaseTokenizer, __pyx_k_BaseTokenizer, sizeof(__pyx_k_BaseTokenizer), 0, 1, 0, 1},
  {&__pyx_n_s_BaseTokenizer___reduce, __pyx_k_BaseTokenizer___reduce, sizeof(__pyx_k_BaseTokenizer___reduce), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_error, __pyx_k_BaseTokenizer_error, sizeof(__pyx_k_BaseTokenizer_error), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_expect, __pyx_k_BaseTokenizer_expect, sizeof(__pyx_k_BaseTokenizer_expect), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_peek, __pyx_k_BaseTokenizer_peek, sizeof(__pyx_k_BaseTokenizer_peek), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_push_back, __pyx_k_BaseTokenizer_push_back, sizeof(__pyx_k_BaseTokenizer_push_back), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_skipping_newlines, __pyx_k_BaseTokenizer_skipping_newlines, sizeof(__pyx_k_BaseTokenizer_skipping_newlines), 0, 0, 1, 1},
  {&__pyx_n_s_COLON, __pyx_k_COLON, sizeof(__pyx_k_COLON), 0, 0, 1, 1},
  {&__pyx_kp_u_Cannot_create__NewlinesIter_inst, __pyx_k_Cannot_create__NewlinesIter_inst, sizeof(__pyx_k_Cannot_create__NewlinesIter_inst), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_nest_brackets, __pyx_k_Cannot_nest_brackets, sizeof(__pyx_k_Cannot_nest_brackets), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_nest_brackets_2, __pyx_k_Cannot_nest_brackets_2, sizeof(__pyx_k_Cannot_nest_brackets_2), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_parse_binary_data, __pyx_k_Cannot_parse_binary_data, sizeof(__pyx_k_Cannot_parse_binary_data), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_parse_binary_data_Decode, __pyx_k_Cannot_parse_binary_data_Decode, sizeof(__pyx_k_Cannot_parse_binary_data_Decode), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_pickle_Tokenizers, __pyx_k_Cannot_pickle_Tokenizers, sizeof(__pyx_k_Cannot_pickle_Tokenizers), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_pickle__NewlinesIter, __pyx_k_Cannot_pickle__NewlinesIter, sizeof(__pyx_k_Cannot_pickle__NewlinesIter), 0, 1, 0, 0},
  {&__pyx_kp_u_Could_not_decode_file, __pyx_k_Could_not_decode_file, sizeof(__pyx_k_Could_not_decode_file), 0, 1, 0, 0},
  {&__pyx_n_s_DIRECTIVE, __pyx_k_DIRECTIVE, sizeof(__pyx_k_DIRECTIVE), 0, 0, 1, 1},
  {&__pyx_kp_u_Data_was_not_a_string, __pyx_k_Data_was_not_a_string, sizeof(__pyx_k_Data_was_not_a_string), 0, 1, 0, 0},
  {&__pyx_n_s_EOF, __pyx_k_EOF, sizeof(__pyx_k_EOF), 0, 0, 1, 1},
  {&__pyx_n_s_EQUALS, __pyx_k_EQUALS, sizeof(__pyx_k_EQUALS), 0, 0, 1, 1},
  {&__pyx_kp_u_Expected, __pyx_k_Expected, sizeof(__pyx_k_Expected), 0, 1, 0, 0},
  {&__pyx_kp_u_Invalid_error_instance, __pyx_k_Invalid_error_instance, sizeof(__pyx_k_Invalid_error_instance), 0, 1, 0, 0},
  {&__pyx_kp_u_IterTokenizer, __pyx_k_IterTokenizer, sizeof(__pyx_k_IterTokenizer), 0, 1, 0, 0},
  {&__pyx_n_s_IterTokenizer_2, __pyx_k_IterTokenizer_2, sizeof(__pyx_k_IterTokenizer_2), 0, 0, 1, 1},
  {&__pyx_n_u_IterTokenizer_2, __pyx_k_IterTokenizer_2, sizeof(__pyx_k_IterTokenizer_2), 0, 1, 0, 1},
  {&__pyx_n_s_NEWLINE, __pyx_k_NEWLINE, sizeof(__pyx_k_NEWLINE), 0, 0, 1, 1},
  {&__pyx_n_s_NewlinesIter___reduce, __pyx_k_NewlinesIter___reduce, sizeof(__pyx_k_NewlinesIter___reduce), 0, 0, 1, 1},
  {&__pyx_kp_u_No_open_to_close_with, __pyx_k_No_open_to_close_with, sizeof(__pyx_k_No_open_to_close_with), 0, 1, 0, 0},
  {&__pyx_kp_u_No_open_to_close_with_2, __pyx_k_No_open_to_close_with_2, sizeof(__pyx_k_No_open_to_close_with_2), 0, 1, 0, 0},
  {&__pyx_n_s_NotImplementedError, __pyx_k_NotImplementedError, sizeof(__pyx_k_NotImplementedError), 0, 0, 1, 1},
  {&__pyx_n_s_PAREN_ARGS, __pyx_k_PAREN_ARGS, sizeof(__pyx_k_PAREN_ARGS), 0, 0, 1, 1},
  {&__pyx_n_s_PLUS, __pyx_k_PLUS, sizeof(__pyx_k_PLUS), 0, 0, 1, 1},
  {&__pyx_n_s_PROP_FLAG, __pyx_k_PROP_FLAG, sizeof(__pyx_k_PROP_FLAG), 0, 0, 1, 1},
  {&__pyx_kp_u_Reached_end_of_line_without_clos, __pyx_k_Reached_end_of_line_without_clos, sizeof(__pyx_k_Reached_end_of_line_without_clos), 0, 1, 0, 0},
  {&__pyx_n_s_STRING, __pyx_k_STRING, sizeof(__pyx_k_STRING), 0, 0, 1, 1},
  {&__pyx_kp_u_Single_slash_found_instead_of_tw, __pyx_k_Single_slash_found_instead_of_tw, sizeof(__pyx_k_Single_slash_found_instead_of_tw), 0, 1, 0, 0},
  {&__pyx_kp_u_Single_slash_found_instead_of_tw_2, __pyx_k_Single_slash_found_instead_of_tw_2, sizeof(__pyx_k_Single_slash_found_instead_of_tw_2), 0, 1, 0, 0},
  {&__pyx_n_s_StopIteration, __pyx_k_StopIteration, sizeof(__pyx_k_StopIteration), 0, 0, 1, 1},
  {&__pyx_n_s_Token, __pyx_k_Token, sizeof(__pyx_k_Token), 0, 0, 1, 1},
  {&__pyx_n_s_TokenSyntaxError, __pyx_k_TokenSyntaxError, sizeof(__pyx_k_TokenSyntaxError), 0, 0, 1, 1},
  {&__pyx_kp_u_Token_already_pushed_back, __pyx_k_Token_already_pushed_back, sizeof(__pyx_k_Token_already_pushed_back), 0, 1, 0, 0},
  {&__pyx_n_s_Tokenizer, __pyx_k_Tokenizer, sizeof(__pyx_k_Tokenizer), 0, 0, 1, 1},
  {&__pyx_n_u_Tokenizer, __pyx_k_Tokenizer, sizeof(__pyx_k_Tokenizer), 0, 1, 0, 1},
  {&__pyx_n_s_TypeError, __pyx_k_TypeError, sizeof(__pyx_k_TypeError), 0, 0, 1, 1},
  {&__pyx_kp_u_Unclosed_comment_starting_on_lin, __pyx_k_Unclosed_comment_starting_on_lin, sizeof(__pyx_k_Unclosed_comment_starting_on_lin), 0, 1, 0, 0},
  {&__pyx_kp_u_Unexpected_character, __pyx_k_Unexpected_character, sizeof(__pyx_k_Unexpected_character), 0, 1, 0, 0},
  {&__pyx_kp_u_Unexpected_token, __pyx_k_Unexpected_token, sizeof(__pyx_k_Unexpected_token), 0, 1, 0, 0},
  {&__pyx_n_s_UnicodeDecodeError, __pyx_k_UnicodeDecodeError, sizeof(__pyx_k_UnicodeDecodeError), 0, 0, 1, 1},
  {&__pyx_kp_u_Unknown_token, __pyx_k_Unknown_token, sizeof(__pyx_k_Unknown_token), 0, 1, 0, 0},
  {&__pyx_kp_u_Unterminated_parentheses, __pyx_k_Unterminated_parentheses, sizeof(__pyx_k_Unterminated_parentheses), 0, 1, 0, 0},
  {&__pyx_kp_u_Unterminated_string, __pyx_k_Unterminated_string, sizeof(__pyx_k_Unterminated_string), 0, 1, 0, 0},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_kp_u_Value_required_for, __pyx_k_Value_required_for, sizeof(__pyx_k_Value_required_for), 0, 1, 0, 0},
  {&__pyx_n_u_X, __pyx_k_X, sizeof(__pyx_k_X), 0, 1, 0, 1},
  {&__pyx_kp_u__10, __pyx_k__10, sizeof(__pyx_k__10), 0, 1, 0, 0},
  {&__pyx_kp_u__11, __pyx_k__11, sizeof(__pyx_k__11), 0, 1, 0, 0},
  {&__pyx_kp_u__12, __pyx_k__12, sizeof(__pyx_k__12), 0, 1, 0, 0},
  {&__pyx_kp_u__13, __pyx_k__13, sizeof(__pyx_k__13), 0, 1, 0, 0},
  {&__pyx_kp_u__14, __pyx_k__14, sizeof(__pyx_k__14), 0, 1, 0, 0},
  {&__pyx_kp_u__18, __pyx_k__18, sizeof(__pyx_k__18), 0, 1, 0, 0},
  {&__pyx_kp_u__19, __pyx_k__19, sizeof(__pyx_k__19), 0, 1, 0, 0},
  {&__pyx_kp_u__20, __pyx_k__20, sizeof(__pyx_k__20), 0, 1, 0, 0},
  {&__pyx_kp_u__21, __pyx_k__21, sizeof(__pyx_k__21), 0, 1, 0, 0},
  {&__pyx_kp_u__3, __pyx_k__3, sizeof(__pyx_k__3), 0, 1, 0, 0},
  {&__pyx_kp_u__6, __pyx_k__6, sizeof(__pyx_k__6), 0, 1, 0, 0},
  {&__pyx_kp_u__7, __pyx_k__7, sizeof(__pyx_k__7), 0, 1, 0, 0},
  {&__pyx_kp_u__8, __pyx_k__8, sizeof(__pyx_k__8), 0, 1, 0, 0},
  {&__pyx_kp_u__9, __pyx_k__9, sizeof(__pyx_k__9), 0, 1, 0, 0},
  {&__pyx_n_s_all, __pyx_k_all, sizeof(__pyx_k_all), 0, 0, 1, 1},
  {&__pyx_n_s_allow_escapes, __pyx_k_allow_escapes, sizeof(__pyx_k_allow_escapes), 0, 0, 1, 1},
  {&__pyx_n_s_allow_star_comments, __pyx_k_allow_star_comments, sizeof(__pyx_k_allow_star_comments), 0, 0, 1, 1},
  {&__pyx_n_s_args, __pyx_k_args, sizeof(__pyx_k_args), 0, 0, 1, 1},
  {&__pyx_kp_u_but_got, __pyx_k_but_got, sizeof(__pyx_k_but_got), 0, 1, 0, 0},
  {&__pyx_n_s_casefold, __pyx_k_casefold, sizeof(__pyx_k_casefold), 0, 0, 1, 1},
  {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
  {&__pyx_n_s_data, __pyx_k_data, sizeof(__pyx_k_data), 0, 0, 1, 1},
  {&__pyx_n_s_enc_text, __pyx_k_enc_text, sizeof(__pyx_k_enc_text), 0, 0, 1, 1},
  {&__pyx_n_s_error, __pyx_k_error, sizeof(__pyx_k_error), 0, 0, 1, 1},
  {&__pyx_n_s_escape_text, __pyx_k_escape_text, sizeof(__pyx_k_escape_text), 0, 0, 1, 1},
  {&__pyx_n_u_escape_text, __pyx_k_escape_text, sizeof(__pyx_k_escape_text), 0, 1, 0, 1},
  {&__pyx_n_s_expect, __pyx_k_expect, sizeof(__pyx_k_expect), 0, 0, 1, 1},
  {&__pyx_n_s_filename, __pyx_k_filename, sizeof(__pyx_k_filename), 0, 0, 1, 1},
  {&__pyx_n_s_final_len, __pyx_k_final_len, sizeof(__pyx_k_final_len), 0, 0, 1, 1},
  {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
  {&__pyx_n_s_fspath, __pyx_k_fspath, sizeof(__pyx_k_fspath), 0, 0, 1, 1},
  {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
  {&__pyx_n_s_id, __pyx_k_id, sizeof(__pyx_k_id), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_init, __pyx_k_init, sizeof(__pyx_k_init), 0, 0, 1, 1},
  {&__pyx_kp_u_is_not_a_Token, __pyx_k_is_not_a_Token, sizeof(__pyx_k_is_not_a_Token), 0, 1, 0, 0},
  {&__pyx_n_s_letter, __pyx_k_letter, sizeof(__pyx_k_letter), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_mark_bare_strings, __pyx_k_mark_bare_strings, sizeof(__pyx_k_mark_bare_strings), 0, 0, 1, 1},
  {&__pyx_n_s_message, __pyx_k_message, sizeof(__pyx_k_message), 0, 0, 1, 1},
  {&__pyx_n_s_module, __pyx_k_module, sizeof(__pyx_k_module), 0, 0, 1, 1},
  {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
  {&__pyx_n_s_name_2, __pyx_k_name_2, sizeof(__pyx_k_name_2), 0, 0, 1, 1},
  {&__pyx_n_s_next_token, __pyx_k_next_token, sizeof(__pyx_k_next_token), 0, 0, 1, 1},
  {&__pyx_n_s_os, __pyx_k_os, sizeof(__pyx_k_os), 0, 0, 1, 1},
  {&__pyx_n_s_out_buff, __pyx_k_out_buff, sizeof(__pyx_k_out_buff), 0, 0, 1, 1},
  {&__pyx_n_s_peek, __pyx_k_peek, sizeof(__pyx_k_peek), 0, 0, 1, 1},
  {&__pyx_n_s_push_back, __pyx_k_push_back, sizeof(__pyx_k_push_back), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_vtable, __pyx_k_pyx_vtable, sizeof(__pyx_k_pyx_vtable), 0, 0, 1, 1},
  {&__pyx_n_s_real_value, __pyx_k_real_value, sizeof(__pyx_k_real_value), 0, 0, 1, 1},
  {&__pyx_n_s_reduce, __pyx_k_reduce, sizeof(__pyx_k_reduce), 0, 0, 1, 1},
  {&__pyx_n_s_return, __pyx_k_return, sizeof(__pyx_k_return), 0, 0, 1, 1},
  {&__pyx_n_s_self, __pyx_k_self, sizeof(__pyx_k_self), 0, 0, 1, 1},
  {&__pyx_n_s_skip_newline, __pyx_k_skip_newline, sizeof(__pyx_k_skip_newline), 0, 0, 1, 1},
  {&__pyx_n_s_skipping_newlines, __pyx_k_skipping_newlines, sizeof(__pyx_k_skipping_newlines), 0, 0, 1, 1},
  {&__pyx_n_s_source, __pyx_k_source, sizeof(__pyx_k_source), 0, 0, 1, 1},
  {&__pyx_n_s_srctools__tokenizer, __pyx_k_srctools__tokenizer, sizeof(__pyx_k_srctools__tokenizer), 0, 0, 1, 1},
  {&__pyx_kp_s_srctools__tokenizer_pyx, __pyx_k_srctools__tokenizer_pyx, sizeof(__pyx_k_srctools__tokenizer_pyx), 0, 0, 1, 0},
  {&__pyx_n_s_srctools_tokenizer, __pyx_k_srctools_tokenizer, sizeof(__pyx_k_srctools_tokenizer), 0, 0, 1, 1},
  {&__pyx_kp_u_srctools_tokenizer, __pyx_k_srctools_tokenizer, sizeof(__pyx_k_srctools_tokenizer), 0, 1, 0, 0},
  {&__pyx_kp_u_srctools_tokenizer_BaseTokenize, __pyx_k_srctools_tokenizer_BaseTokenize, sizeof(__pyx_k_srctools_tokenizer_BaseTokenize), 0, 1, 0, 0},
  {&__pyx_n_s_string_bracket, __pyx_k_string_bracket, sizeof(__pyx_k_string_bracket), 0, 0, 1, 1},
  {&__pyx_kp_u_style_comments_are_not_allowed, __pyx_k_style_comments_are_not_allowed, sizeof(__pyx_k_style_comments_are_not_allowed), 0, 1, 0, 0},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_n_s_text, __pyx_k_text, sizeof(__pyx_k_text), 0, 0, 1, 1},
  {&__pyx_n_s_tok, __pyx_k_tok, sizeof(__pyx_k_tok), 0, 0, 1, 1},
  {&__pyx_n_s_tok_and_val, __pyx_k_tok_and_val, sizeof(__pyx_k_tok_and_val), 0, 0, 1, 1},
  {&__pyx_n_s_tok_val, __pyx_k_tok_val, sizeof(__pyx_k_tok_val), 0, 0, 1, 1},
  {&__pyx_n_s_token, __pyx_k_token, sizeof(__pyx_k_token), 0, 0, 1, 1},
  {&__pyx_n_u_unicode, __pyx_k_unicode, sizeof(__pyx_k_unicode), 0, 1, 0, 1},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {&__pyx_n_s_value_2, __pyx_k_value_2, sizeof(__pyx_k_value_2), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(0, 88, __pyx_L1_error)
  __pyx_builtin_NotImplementedError = __Pyx_GetBuiltinName(__pyx_n_s_NotImplementedError); if (!__pyx_builtin_NotImplementedError) __PYX_ERR(0, 133, __pyx_L1_error)
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 147, __pyx_L1_error)
  __pyx_builtin_AttributeError = __Pyx_GetBuiltinName(__pyx_n_s_AttributeError); if (!__pyx_builtin_AttributeError) __PYX_ERR(0, 292, __pyx_L1_error)
  __pyx_builtin_UnicodeDecodeError = __Pyx_GetBuiltinName(__pyx_n_s_UnicodeDecodeError); if (!__pyx_builtin_UnicodeDecodeError) __PYX_ERR(0, 344, __pyx_L1_error)
  __pyx_builtin_StopIteration = __Pyx_GetBuiltinName(__pyx_n_s_StopIteration); if (!__pyx_builtin_StopIteration) __PYX_ERR(0, 629, __pyx_L1_error)
  __pyx_builtin_id = __Pyx_GetBuiltinName(__pyx_n_s_id); if (!__pyx_builtin_id) __PYX_ERR(0, 645, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "srctools/_tokenizer.pyx":101
 *         There is also the issue with recreating the C/Python versions.
 *         """
 *         raise TypeError('Cannot pickle Tokenizers!')             # <<<<<<<<<<<<<<
 * 
 *     def error(self, message, *args):
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_kp_u_Cannot_pickle_Tokenizers); if (unlikely(!__pyx_tuple__2)) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "srctools/_tokenizer.pyx":133
 * 
 *     cdef next_token(self):
 *         raise NotImplementedError("Abstract method!")             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __pyx_tuple__4 = PyTuple_Pack(1, __pyx_kp_u_Abstract_method); if (unlikely(!__pyx_tuple__4)) __PYX_ERR(0, 133, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__4);
  __Pyx_GIVEREF(__pyx_tuple__4);

  /* "srctools/_tokenizer.pyx":147
 *         """
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')             # <<<<<<<<<<<<<<
 *         if not isinstance(tok, Token):
 *             raise ValueError(repr(tok) + ' is not a Token!')
 */
  __pyx_tuple__5 = PyTuple_Pack(1, __pyx_kp_u_Token_already_pushed_back); if (unlikely(!__pyx_tuple__5)) __PYX_ERR(0, 147, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__5);
  __Pyx_GIVEREF(__pyx_tuple__5);

  /* "srctools/_tokenizer.pyx":267
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):
 *             raise TypeError(             # <<<<<<<<<<<<<<
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 *                 'or wrap in io.TextIOWrapper() to decode gradually.'
 */
  __pyx_tuple__15 = PyTuple_Pack(1, __pyx_kp_u_Cannot_parse_binary_data_Decode); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(0, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__15);
  __Pyx_GIVEREF(__pyx_tuple__15);

  /* "srctools/_tokenizer.pyx":350
 * 
 *         if isinstance(chunk_obj, bytes):
 *             raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *         if not isinstance(chunk_obj, str):
 *             raise ValueError("Data was not a string!")
 */
  __pyx_tuple__16 = PyTuple_Pack(1, __pyx_kp_u_Cannot_parse_binary_data); if (unlikely(!__pyx_tuple__16)) __PYX_ERR(0, 350, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__16);
  __Pyx_GIVEREF(__pyx_tuple__16);

  /* "srctools/_tokenizer.pyx":352
 *             raise ValueError('Cannot parse binary data!')
 *         if not isinstance(chunk_obj, str):
 *             raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *         self.cur_chunk = chunk = <str>chunk_obj
 */
  __pyx_tuple__17 = PyTuple_Pack(1, __pyx_kp_u_Data_was_not_a_string); if (unlikely(!__pyx_tuple__17)) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__17);
  __Pyx_GIVEREF(__pyx_tuple__17);

  /* "srctools/_tokenizer.pyx":648
 * 
 *     def __init__(self, tok):
 *         raise TypeError("Cannot create '_NewlinesIter' instances")             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __pyx_tuple__22 = PyTuple_Pack(1, __pyx_kp_u_Cannot_create__NewlinesIter_inst); if (unlikely(!__pyx_tuple__22)) __PYX_ERR(0, 648, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__22);
  __Pyx_GIVEREF(__pyx_tuple__22);

  /* "srctools/_tokenizer.pyx":667
 *     def __reduce__(self):
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__23 = PyTuple_Pack(1, __pyx_kp_u_Cannot_pickle__NewlinesIter); if (unlikely(!__pyx_tuple__23)) __PYX_ERR(0, 667, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__23);
  __Pyx_GIVEREF(__pyx_tuple__23);

  /* "srctools/_tokenizer.pyx":94
 *         self.line_num = 1
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */
  __pyx_tuple__24 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__24)) __PYX_ERR(0, 94, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__24);
  __Pyx_GIVEREF(__pyx_tuple__24);
  __pyx_codeobj__25 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__24, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_reduce, 94, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__25)) __PYX_ERR(0, 94, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":103
 *         raise TypeError('Cannot pickle Tokenizers!')
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */
  __pyx_tuple__26 = PyTuple_Pack(3, __pyx_n_s_self, __pyx_n_s_message, __pyx_n_s_args); if (unlikely(!__pyx_tuple__26)) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__26);
  __Pyx_GIVEREF(__pyx_tuple__26);
  __pyx_codeobj__27 = (PyObject*)__Pyx_PyCode_New(2, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS|CO_VARARGS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__26, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_error, 103, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__27)) __PYX_ERR(0, 103, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":139
 *         return iter(self, EOF_TUP)
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */
  __pyx_tuple__28 = PyTuple_Pack(5, __pyx_n_s_self, __pyx_n_s_tok, __pyx_n_s_value, __pyx_n_s_tok_val, __pyx_n_s_real_value); if (unlikely(!__pyx_tuple__28)) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__28);
  __Pyx_GIVEREF(__pyx_tuple__28);
  __pyx_codeobj__29 = (PyObject*)__Pyx_PyCode_New(3, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__28, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_push_back, 139, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__29)) __PYX_ERR(0, 139, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":187
 *         self.pushback_val = value
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */
  __pyx_tuple__30 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_tok_and_val); if (unlikely(!__pyx_tuple__30)) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__30);
  __Pyx_GIVEREF(__pyx_tuple__30);
  __pyx_codeobj__31 = (PyObject*)__Pyx_PyCode_New(1, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__30, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_peek, 187, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__31)) __PYX_ERR(0, 187, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":195
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 */
  __pyx_tuple__32 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__32)) __PYX_ERR(0, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__32);
  __Pyx_GIVEREF(__pyx_tuple__32);
  __pyx_codeobj__33 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__32, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_skipping_newlines, 195, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__33)) __PYX_ERR(0, 195, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":199
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */
  __pyx_tuple__34 = PyTuple_Pack(5, __pyx_n_s_self, __pyx_n_s_token, __pyx_n_s_skip_newline, __pyx_n_s_next_token, __pyx_n_s_value); if (unlikely(!__pyx_tuple__34)) __PYX_ERR(0, 199, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__34);
  __Pyx_GIVEREF(__pyx_tuple__34);
  __pyx_codeobj__35 = (PyObject*)__Pyx_PyCode_New(3, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__34, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_expect, 199, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__35)) __PYX_ERR(0, 199, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":665
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')
 */
  __pyx_tuple__36 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__36)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__36);
  __Pyx_GIVEREF(__pyx_tuple__36);
  __pyx_codeobj__37 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__36, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_reduce, 665, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__37)) __PYX_ERR(0, 665, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":671
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None: str) -> str:             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */
  __pyx_tuple__38 = PyTuple_Pack(6, __pyx_n_s_text, __pyx_n_s_enc_text, __pyx_n_s_final_len, __pyx_n_s_letter, __pyx_n_s_out_buff, __pyx_n_s_i); if (unlikely(!__pyx_tuple__38)) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__38);
  __Pyx_GIVEREF(__pyx_tuple__38);
  __pyx_codeobj__39 = (PyObject*)__Pyx_PyCode_New(1, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__38, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_escape_text, 671, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__39)) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  return 0;
  __pyx_L1_error:;
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_modinit_global_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_import_code(void); /*proto*/

static int __Pyx_modinit_global_init_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_global_init_code", 0);
  /*--- Global init code ---*/
  __pyx_v_8srctools_10_tokenizer_os_fspath = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_Token = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_TokenSyntaxError = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_STRING = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PAREN_ARGS = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PROP_FLAG = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_DIRECTIVE = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BARE_STRING = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EOF = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_NEWLINE = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EMPTY_ITER = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EOF_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_NEWLINE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_COLON_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EQUALS_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PLUS_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_variable_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_export_code", 0);
  /*--- Variable export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_export_code", 0);
  /*--- Function export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_type_init_code(void) {
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
  /*--- Type init code ---*/
  __pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer = &__pyx_vtable_8srctools_10_tokenizer_BaseTokenizer;
  __pyx_vtable_8srctools_10_tokenizer_BaseTokenizer._error = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *, PyObject *))__pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error;
  __pyx_vtable_8srctools_10_tokenizer_BaseTokenizer.next_token = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *))__pyx_f_8srctools_10_tokenizer_13BaseTokenizer_next_token;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_BaseTokenizer) < 0) __PYX_ERR(0, 61, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_getattro = __Pyx_PyObject_GenericGetAttr;
  }
  #if CYTHON_COMPILING_IN_CPYTHON
  {
    PyObject *wrapper = PyObject_GetAttrString((PyObject *)&__pyx_type_8srctools_10_tokenizer_BaseTokenizer, "__call__"); if (unlikely(!wrapper)) __PYX_ERR(0, 61, __pyx_L1_error)
    if (Py_TYPE(wrapper) == &PyWrapperDescr_Type) {
      __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_6__call__ = *((PyWrapperDescrObject *)wrapper)->d_base;
      __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_6__call__.doc = __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_6__call__;
      ((PyWrapperDescrObject *)wrapper)->d_base = &__pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_6__call__;
    }
  }
  #endif
  if (__Pyx_SetVtable(__pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_dict, __pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer) < 0) __PYX_ERR(0, 61, __pyx_L1_error)
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_BaseTokenizer, (PyObject *)&__pyx_type_8srctools_10_tokenizer_BaseTokenizer) < 0) __PYX_ERR(0, 61, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer_BaseTokenizer = &__pyx_type_8srctools_10_tokenizer_BaseTokenizer;
  __pyx_vtabptr_8srctools_10_tokenizer_Tokenizer = &__pyx_vtable_8srctools_10_tokenizer_Tokenizer;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.__pyx_base = *__pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.__pyx_base.next_token = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_reset = (void (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_add_char = (void (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, Py_UCS4))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_get_text = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer._next_char = (Py_UCS4 (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char;
  __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_base = __pyx_ptype_8srctools_10_tokenizer_BaseTokenizer;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 219, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_Tokenizer.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_getattro = __Pyx_PyObject_GenericGetAttr;
  }
  if (__Pyx_SetVtable(__pyx_type_8srctools_10_tokenizer_Tokenizer.tp_dict, __pyx_vtabptr_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 219, __pyx_L1_error)
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_Tokenizer, (PyObject *)&__pyx_type_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 219, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer_Tokenizer = &__pyx_type_8srctools_10_tokenizer_Tokenizer;
  __pyx_vtabptr_8srctools_10_tokenizer_IterTokenizer = &__pyx_vtable_8srctools_10_tokenizer_IterTokenizer;
  __pyx_vtable_8srctools_10_tokenizer_IterTokenizer.__pyx_base = *__pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer;
  __pyx_vtable_8srctools_10_tokenizer_IterTokenizer.__pyx_base.next_token = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *))__pyx_f_8srctools_10_tokenizer_13IterTokenizer_next_token;
  __pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_base = __pyx_ptype_8srctools_10_tokenizer_BaseTokenizer;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_IterTokenizer) < 0) __PYX_ERR(0, 609, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_getattro = __Pyx_PyObject_GenericGetAttr;
  }
  if (__Pyx_SetVtable(__pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_dict, __pyx_vtabptr_8srctools_10_tokenizer_IterTokenizer) < 0) __PYX_ERR(0, 609, __pyx_L1_error)
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_IterTokenizer_2, (PyObject *)&__pyx_type_8srctools_10_tokenizer_IterTokenizer) < 0) __PYX_ERR(0, 609, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer_IterTokenizer = &__pyx_type_8srctools_10_tokenizer_IterTokenizer;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer__NewlinesIter) < 0) __PYX_ERR(0, 637, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer__NewlinesIter.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer__NewlinesIter.tp_dictoffset && __pyx_type_8srctools_10_tokenizer__NewlinesIter.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer__NewlinesIter.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
  }
  __pyx_ptype_8srctools_10_tokenizer__NewlinesIter = &__pyx_type_8srctools_10_tokenizer__NewlinesIter;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_type_import_code(void) {
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_import_code", 0);
  /*--- Type import code ---*/
  __pyx_t_1 = PyImport_ImportModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_ptype_7cpython_4type_type = __Pyx_ImportType(__pyx_t_1, __Pyx_BUILTIN_MODULE_NAME, "type", 
  #if defined(PYPY_VERSION_NUM) && PYPY_VERSION_NUM < 0x050B0000
  sizeof(PyTypeObject),
  #else
  sizeof(PyHeapTypeObject),
  #endif
  __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_7cpython_4type_type) __PYX_ERR(1, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_variable_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_import_code", 0);
  /*--- Variable import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_import_code", 0);
  /*--- Function import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}


#ifndef CYTHON_NO_PYINIT_EXPORT
#define __Pyx_PyMODINIT_FUNC PyMODINIT_FUNC
#elif PY_MAJOR_VERSION < 3
#ifdef __cplusplus
#define __Pyx_PyMODINIT_FUNC extern "C" void
#else
#define __Pyx_PyMODINIT_FUNC void
#endif
#else
#ifdef __cplusplus
#define __Pyx_PyMODINIT_FUNC extern "C" PyObject *
#else
#define __Pyx_PyMODINIT_FUNC PyObject *
#endif
#endif


#if PY_MAJOR_VERSION < 3
__Pyx_PyMODINIT_FUNC init_tokenizer(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC init_tokenizer(void)
#else
__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
static CYTHON_SMALL_CODE int __Pyx_check_single_interpreter(void) {
    #if PY_VERSION_HEX >= 0x030700A1
    static PY_INT64_T main_interpreter_id = -1;
    PY_INT64_T current_id = PyInterpreterState_GetID(PyThreadState_Get()->interp);
    if (main_interpreter_id == -1) {
        main_interpreter_id = current_id;
        return (unlikely(current_id == -1)) ? -1 : 0;
    } else if (unlikely(main_interpreter_id != current_id))
    #else
    static PyInterpreterState *main_interpreter = NULL;
    PyInterpreterState *current_interpreter = PyThreadState_Get()->interp;
    if (!main_interpreter) {
        main_interpreter = current_interpreter;
    } else if (unlikely(main_interpreter != current_interpreter))
    #endif
    {
        PyErr_SetString(
            PyExc_ImportError,
            "Interpreter change detected - this module can only be loaded into one interpreter per process.");
        return -1;
    }
    return 0;
}
static CYTHON_SMALL_CODE int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name, int allow_none) {
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        if (allow_none || value != Py_None) {
            result = PyDict_SetItemString(moddict, to_name, value);
        }
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static CYTHON_SMALL_CODE PyObject* __pyx_pymod_create(PyObject *spec, CYTHON_UNUSED PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    if (__Pyx_check_single_interpreter())
        return NULL;
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__", 0) < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static CYTHON_SMALL_CODE int __pyx_pymod_exec__tokenizer(PyObject *__pyx_pyinit_module)
#endif
#endif
{
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m) {
    if (__pyx_m == __pyx_pyinit_module) return 0;
    PyErr_SetString(PyExc_RuntimeError, "Module '_tokenizer' has already been imported. Re-initialisation is not supported.");
    return -1;
  }
  #elif PY_MAJOR_VERSION >= 3
  if (__pyx_m) return __Pyx_NewRef(__pyx_m);
  #endif
  #if CYTHON_REFNANNY
__Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
if (!__Pyx_RefNanny) {
  PyErr_Clear();
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
  if (!__Pyx_RefNanny)
      Py_FatalError("failed to import 'refnanny' module");
}
#endif
  __Pyx_RefNannySetupContext("__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pxy_PyFrame_Initialize_Offsets
  __Pxy_PyFrame_Initialize_Offsets();
  #endif
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  #ifdef WITH_THREAD /* Python build with threading support? */
  PyEval_InitThreads();
  #endif
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_m = __pyx_pyinit_module;
  Py_INCREF(__pyx_m);
  #else
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("_tokenizer", __pyx_methods, __pyx_k_Cython_version_of_the_Tokenizer, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_b);
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_cython_runtime);
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_srctools___tokenizer) {
    if (PyObject_SetAttr(__pyx_m, __pyx_n_s_name, __pyx_n_s_main) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "srctools._tokenizer")) {
      if (unlikely(PyDict_SetItemString(modules, "srctools._tokenizer", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Global type/function init code ---*/
  (void)__Pyx_modinit_global_init_code();
  (void)__Pyx_modinit_variable_export_code();
  (void)__Pyx_modinit_function_export_code();
  if (unlikely(__Pyx_modinit_type_init_code() < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
  if (unlikely(__Pyx_modinit_type_import_code() < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
  (void)__Pyx_modinit_variable_import_code();
  (void)__Pyx_modinit_function_import_code();
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif

  /* "srctools/_tokenizer.pyx":13
 * # On Python 3.6+, convert stuff to PathLike.
 * cdef object os_fspath
 * from os import fspath as os_fspath             # <<<<<<<<<<<<<<
 * 
 * # Import the Token enum from the Python file, and cache references
 */
  __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_n_s_fspath);
  __Pyx_GIVEREF(__pyx_n_s_fspath);
  PyList_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_fspath);
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_os, __pyx_t_1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_fspath); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_os_fspath);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_os_fspath, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":20
 * 
 * cdef object Token, TokenSyntaxError
 * from srctools.tokenizer import Token,  TokenSyntaxError             # <<<<<<<<<<<<<<
 * 
 * __all__ = ['BaseTokenizer', 'Tokenizer', 'IterTokenizer', 'escape_text']
 */
  __pyx_t_2 = PyList_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_n_s_Token);
  __Pyx_GIVEREF(__pyx_n_s_Token);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_Token);
  __Pyx_INCREF(__pyx_n_s_TokenSyntaxError);
  __Pyx_GIVEREF(__pyx_n_s_TokenSyntaxError);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_n_s_TokenSyntaxError);
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_srctools_tokenizer, __pyx_t_2, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_1, __pyx_n_s_Token); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_t_2);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_Token);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_Token, __pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_1, __pyx_n_s_TokenSyntaxError); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_t_2);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError, __pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":22
 * from srctools.tokenizer import Token,  TokenSyntaxError
 * 
 * __all__ = ['BaseTokenizer', 'Tokenizer', 'IterTokenizer', 'escape_text']             # <<<<<<<<<<<<<<
 * 
 * # Cdef-ed globals become static module vars, which aren't in the module
 */
  __pyx_t_1 = PyList_New(4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_n_u_BaseTokenizer);
  __Pyx_GIVEREF(__pyx_n_u_BaseTokenizer);
  PyList_SET_ITEM(__pyx_t_1, 0, __pyx_n_u_BaseTokenizer);
  __Pyx_INCREF(__pyx_n_u_Tokenizer);
  __Pyx_GIVEREF(__pyx_n_u_Tokenizer);
  PyList_SET_ITEM(__pyx_t_1, 1, __pyx_n_u_Tokenizer);
  __Pyx_INCREF(__pyx_n_u_IterTokenizer_2);
  __Pyx_GIVEREF(__pyx_n_u_IterTokenizer_2);
  PyList_SET_ITEM(__pyx_t_1, 2, __pyx_n_u_IterTokenizer_2);
  __Pyx_INCREF(__pyx_n_u_escape_text);
  __Pyx_GIVEREF(__pyx_n_u_escape_text);
  PyList_SET_ITEM(__pyx_t_1, 3, __pyx_n_u_escape_text);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_all, __pyx_t_1) < 0) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":28
 * # lookup.
 * cdef:
 *     object STRING = Token.STRING             # <<<<<<<<<<<<<<
 *     object PAREN_ARGS = Token.PAREN_ARGS
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_STRING); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 28, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_STRING);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_STRING, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":29
 * cdef:
 *     object STRING = Token.STRING
 *     object PAREN_ARGS = Token.PAREN_ARGS             # <<<<<<<<<<<<<<
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]
 *     object DIRECTIVE = Token.DIRECTIVE  # #name (automatically casefolded)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PAREN_ARGS); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 29, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":30
 *     object STRING = Token.STRING
 *     object PAREN_ARGS = Token.PAREN_ARGS
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]             # <<<<<<<<<<<<<<
 *     object DIRECTIVE = Token.DIRECTIVE  # #name (automatically casefolded)
 *     object BARE_STRING = Token.BARE_STRING
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PROP_FLAG); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PROP_FLAG, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":31
 *     object PAREN_ARGS = Token.PAREN_ARGS
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]
 *     object DIRECTIVE = Token.DIRECTIVE  # #name (automatically casefolded)             # <<<<<<<<<<<<<<
 *     object BARE_STRING = Token.BARE_STRING
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_DIRECTIVE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_DIRECTIVE, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":32
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]
 *     object DIRECTIVE = Token.DIRECTIVE  # #name (automatically casefolded)
 *     object BARE_STRING = Token.BARE_STRING             # <<<<<<<<<<<<<<
 * 
 *     object EOF = Token.EOF
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BARE_STRING); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 32, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BARE_STRING);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BARE_STRING, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":34
 *     object BARE_STRING = Token.BARE_STRING
 * 
 *     object EOF = Token.EOF             # <<<<<<<<<<<<<<
 *     object NEWLINE = Token.NEWLINE
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EOF); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 34, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EOF);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EOF, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":35
 * 
 *     object EOF = Token.EOF
 *     object NEWLINE = Token.NEWLINE             # <<<<<<<<<<<<<<
 * 
 *     # Iterator that immediately raises StopIteration.
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_NEWLINE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 35, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_NEWLINE);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_NEWLINE, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":38
 * 
 *     # Iterator that immediately raises StopIteration.
 *     object EMPTY_ITER = iter('')             # <<<<<<<<<<<<<<
 * 
 *     # Reuse a single tuple for these, since the value is constant.
 */
  __pyx_t_1 = PyObject_GetIter(__pyx_kp_u__6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EMPTY_ITER);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EMPTY_ITER, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":41
 * 
 *     # Reuse a single tuple for these, since the value is constant.
 *     tuple EOF_TUP = (Token.EOF, '')             # <<<<<<<<<<<<<<
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EOF); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__6);
  __Pyx_GIVEREF(__pyx_kp_u__6);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__6);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EOF_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EOF_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":42
 *     # Reuse a single tuple for these, since the value is constant.
 *     tuple EOF_TUP = (Token.EOF, '')
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')             # <<<<<<<<<<<<<<
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_NEWLINE); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __Pyx_INCREF(__pyx_kp_u__7);
  __Pyx_GIVEREF(__pyx_kp_u__7);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__7);
  __pyx_t_2 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":44
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')             # <<<<<<<<<<<<<<
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_COLON); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 44, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 44, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__12);
  __Pyx_GIVEREF(__pyx_kp_u__12);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__12);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_COLON_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_COLON_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":45
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')             # <<<<<<<<<<<<<<
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EQUALS); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 45, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 45, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __Pyx_INCREF(__pyx_kp_u__13);
  __Pyx_GIVEREF(__pyx_kp_u__13);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__13);
  __pyx_t_2 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":46
 *     tuple COLON_TUP = (Token.COLON, ':')
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')
 *     tuple PLUS_TUP = (Token.PLUS, '+')             # <<<<<<<<<<<<<<
 * 
 *     tuple BRACE_OPEN_TUP = (Token.BRACE_OPEN, '{')
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PLUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__14);
  __Pyx_GIVEREF(__pyx_kp_u__14);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__14);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PLUS_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PLUS_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":48
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 * 
 *     tuple BRACE_OPEN_TUP = (Token.BRACE_OPEN, '{')             # <<<<<<<<<<<<<<
 *     tuple BRACE_CLOSE_TUP = (Token.BRACE_CLOSE, '}')
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACE_OPEN); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __Pyx_INCREF(__pyx_kp_u__8);
  __Pyx_GIVEREF(__pyx_kp_u__8);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__8);
  __pyx_t_2 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":49
 * 
 *     tuple BRACE_OPEN_TUP = (Token.BRACE_OPEN, '{')
 *     tuple BRACE_CLOSE_TUP = (Token.BRACE_CLOSE, '}')             # <<<<<<<<<<<<<<
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACE_CLOSE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__9);
  __Pyx_GIVEREF(__pyx_kp_u__9);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__9);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":51
 *     tuple BRACE_CLOSE_TUP = (Token.BRACE_CLOSE, '}')
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')             # <<<<<<<<<<<<<<
 *     tuple BRACK_CLOSE_TUP = (Token.BRACK_CLOSE, ']')
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACK_OPEN); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __Pyx_INCREF(__pyx_kp_u__10);
  __Pyx_GIVEREF(__pyx_kp_u__10);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__10);
  __pyx_t_2 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":52
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')
 *     tuple BRACK_CLOSE_TUP = (Token.BRACK_CLOSE, ']')             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACK_CLOSE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__11);
  __Pyx_GIVEREF(__pyx_kp_u__11);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__11);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":94
 *         self.line_num = 1
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer___reduce, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__25)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 94, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_reduce, __pyx_t_2) < 0) __PYX_ERR(0, 94, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":103
 *         raise TypeError('Cannot pickle Tokenizers!')
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_5error, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_error, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__27)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_error, __pyx_t_2) < 0) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":139
 *         return iter(self, EOF_TUP)
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_11push_back, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_push_back, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__29)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_push_back, __pyx_t_2) < 0) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":187
 *         self.pushback_val = value
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_13peek, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_peek, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__31)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_peek, __pyx_t_2) < 0) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":195
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_15skipping_newlines, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_skipping_newlines, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__33)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_skipping_newlines, __pyx_t_2) < 0) __PYX_ERR(0, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":199
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_17expect, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_expect, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__35)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 199, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_expect, __pyx_t_2) < 0) __PYX_ERR(0, 199, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":665
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_NewlinesIter___reduce, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__37)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer__NewlinesIter->tp_dict, __pyx_n_s_reduce, __pyx_t_2) < 0) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer__NewlinesIter);

  /* "srctools/_tokenizer.pyx":671
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None: str) -> str:             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */
  __pyx_t_2 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_text, __pyx_n_u_unicode) < 0) __PYX_ERR(0, 671, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_return, __pyx_n_u_unicode) < 0) __PYX_ERR(0, 671, __pyx_L1_error)
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_1escape_text, 0, __pyx_n_s_escape_text, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__39)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_CyFunction_SetAnnotationsDict(__pyx_t_1, __pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_escape_text, __pyx_t_1) < 0) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":719
 * # This fixes all the methods too, though not in exceptions.
 * from cpython.object cimport PyTypeObject
 * if USE_TYPE_INTERNALS:             # <<<<<<<<<<<<<<
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 */
  __pyx_t_3 = (CYTHON_USE_TYPE_SLOTS != 0);
  if (__pyx_t_3) {

    /* "srctools/_tokenizer.pyx":720
 * from cpython.object cimport PyTypeObject
 * if USE_TYPE_INTERNALS:
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"             # <<<<<<<<<<<<<<
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer.BaseTokenizer.skipping_newlines"
 */
    ((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer)->tp_name = ((char const *)"srctools.tokenizer.BaseTokenizer");

    /* "srctools/_tokenizer.pyx":721
 * if USE_TYPE_INTERNALS:
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"             # <<<<<<<<<<<<<<
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer.BaseTokenizer.skipping_newlines"
 *     escape_text.__module__ = 'srctools.tokenizer'
 */
    ((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer_Tokenizer)->tp_name = ((char const *)"srctools.tokenizer.Tokenizer");

    /* "srctools/_tokenizer.pyx":722
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer.BaseTokenizer.skipping_newlines"             # <<<<<<<<<<<<<<
 *     escape_text.__module__ = 'srctools.tokenizer'
 */
    ((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer__NewlinesIter)->tp_name = ((char const *)"srctools.tokenizer.BaseTokenizer.skipping_newlines");

    /* "srctools/_tokenizer.pyx":723
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer.BaseTokenizer.skipping_newlines"
 *     escape_text.__module__ = 'srctools.tokenizer'             # <<<<<<<<<<<<<<
 */
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_escape_text); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 723, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (__Pyx_PyObject_SetAttrStr(__pyx_t_1, __pyx_n_s_module, __pyx_kp_u_srctools_tokenizer) < 0) __PYX_ERR(0, 723, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":719
 * # This fixes all the methods too, though not in exceptions.
 * from cpython.object cimport PyTypeObject
 * if USE_TYPE_INTERNALS:             # <<<<<<<<<<<<<<
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 */
  }

  /* "srctools/_tokenizer.pyx":1
 * # cython: language_level=3, embedsignature=True, auto_pickle=False             # <<<<<<<<<<<<<<
 * # cython: binding=True
 * """Cython version of the Tokenizer class."""
 */
  __pyx_t_1 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_1) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init srctools._tokenizer", __pyx_clineno, __pyx_lineno, __pyx_filename);
    }
    Py_CLEAR(__pyx_m);
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init srctools._tokenizer");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #elif PY_MAJOR_VERSION >= 3
  return __pyx_m;
  #else
  return;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule(modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, "RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* PyObjectGetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (__Pyx_PyUnicode_GET_LENGTH(**name) != __Pyx_PyUnicode_GET_LENGTH(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (__Pyx_PyUnicode_GET_LENGTH(**argname) != __Pyx_PyUnicode_GET_LENGTH(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* PyCFunctionFastCall */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    int flags = PyCFunction_GET_FLAGS(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    if ((PY_VERSION_HEX < 0x030700A0) || unlikely(flags & METH_KEYWORDS)) {
        return (*((__Pyx_PyCFunctionFastWithKeywords)(void*)meth)) (self, args, nargs, NULL);
    } else {
        return (*((__Pyx_PyCFunctionFast)(void*)meth)) (self, args, nargs);
    }
}
#endif

/* PyFunctionFastCall */
#if CYTHON_FAST_PYCALL
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = __Pyx_PyFrame_GetLocalsplus(f);
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif
#endif

/* PyObjectCall */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = func->ob_type->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallMethO */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallOneArg */
#if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
    if (likely(PyCFunction_Check(func))) {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (PyCFunction_GET_FLAGS(func) & METH_FASTCALL) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* JoinPyUnicode */
static PyObject* __Pyx_PyUnicode_Join(PyObject* value_tuple, Py_ssize_t value_count, Py_ssize_t result_ulength,
                                      CYTHON_UNUSED Py_UCS4 max_char) {
#if CYTHON_USE_UNICODE_INTERNALS && CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    PyObject *result_uval;
    int result_ukind;
    Py_ssize_t i, char_pos;
    void *result_udata;
#if CYTHON_PEP393_ENABLED
    result_uval = PyUnicode_New(result_ulength, max_char);
    if (unlikely(!result_uval)) return NULL;
    result_ukind = (max_char <= 255) ? PyUnicode_1BYTE_KIND : (max_char <= 65535) ? PyUnicode_2BYTE_KIND : PyUnicode_4BYTE_KIND;
    result_udata = PyUnicode_DATA(result_uval);
#else
    result_uval = PyUnicode_FromUnicode(NULL, result_ulength);
    if (unlikely(!result_uval)) return NULL;
    result_ukind = sizeof(Py_UNICODE);
    result_udata = PyUnicode_AS_UNICODE(result_uval);
#endif
    char_pos = 0;
    for (i=0; i < value_count; i++) {
        int ukind;
        Py_ssize_t ulength;
        void *udata;
        PyObject *uval = PyTuple_GET_ITEM(value_tuple, i);
        if (unlikely(__Pyx_PyUnicode_READY(uval)))
            goto bad;
        ulength = __Pyx_PyUnicode_GET_LENGTH(uval);
        if (unlikely(!ulength))
            continue;
        if (unlikely(char_pos + ulength < 0))
            goto overflow;
        ukind = __Pyx_PyUnicode_KIND(uval);
        udata = __Pyx_PyUnicode_DATA(uval);
        if (!CYTHON_PEP393_ENABLED || ukind == result_ukind) {
            memcpy((char *)result_udata + char_pos * result_ukind, udata, (size_t) (ulength * result_ukind));
        } else {
            #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030300F0 || defined(_PyUnicode_FastCopyCharacters)
            _PyUnicode_FastCopyCharacters(result_uval, char_pos, uval, 0, ulength);
            #else
            Py_ssize_t j;
            for (j=0; j < ulength; j++) {
                Py_UCS4 uchar = __Pyx_PyUnicode_READ(ukind, udata, j);
                __Pyx_PyUnicode_WRITE(result_ukind, result_udata, char_pos+j, uchar);
            }
            #endif
        }
        char_pos += ulength;
    }
    return result_uval;
overflow:
    PyErr_SetString(PyExc_OverflowError, "join() result is too long for a Python string");
bad:
    Py_DECREF(result_uval);
    return NULL;
#else
    result_ulength++;
    value_count++;
    return PyUnicode_Join(__pyx_empty_unicode, value_tuple);
#endif
}

/* PyErrFetchRestore */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* RaiseException */
#if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* KeywordStringCheck */
static int __Pyx_CheckKeywordStrings(
    PyObject *kwdict,
    const char* function_name,
    int kw_allowed)
{
    PyObject* key = 0;
    Py_ssize_t pos = 0;
#if CYTHON_COMPILING_IN_PYPY
    if (!kw_allowed && PyDict_Next(kwdict, &pos, &key, 0))
        goto invalid_keyword;
    return 1;
#else
    while (PyDict_Next(kwdict, &pos, &key, 0)) {
        #if PY_MAJOR_VERSION < 3
        if (unlikely(!PyString_Check(key)))
        #endif
            if (unlikely(!PyUnicode_Check(key)))
                goto invalid_keyword_type;
    }
    if ((!kw_allowed) && unlikely(key))
        goto invalid_keyword;
    return 1;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    return 0;
#endif
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
    return 0;
}

/* ArgTypeTest */
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact)
{
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    else if (exact) {
        #if PY_MAJOR_VERSION == 2
        if ((type == &PyBaseString_Type) && likely(__Pyx_PyBaseString_CheckExact(obj))) return 1;
        #endif
    }
    else {
        if (likely(__Pyx_TypeCheck(obj, type))) return 1;
    }
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected %.200s, got %.200s)",
        name, type->tp_name, Py_TYPE(obj)->tp_name);
    return 0;
}

/* PyObjectFormatAndDecref */
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatSimpleAndDecref(PyObject* s, PyObject* f) {
    if (unlikely(!s)) return NULL;
    if (likely(PyUnicode_CheckExact(s))) return s;
    #if PY_MAJOR_VERSION < 3
    if (likely(PyString_CheckExact(s))) {
        PyObject *result = PyUnicode_FromEncodedObject(s, NULL, "strict");
        Py_DECREF(s);
        return result;
    }
    #endif
    return __Pyx_PyObject_FormatAndDecref(s, f);
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatAndDecref(PyObject* s, PyObject* f) {
    PyObject *result = PyObject_Format(s, f);
    Py_DECREF(s);
    return result;
}

/* RaiseTooManyValuesToUnpack */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* RaiseNoneIterError */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
}

/* GetTopmostException */
#if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem *
__Pyx_PyErr_GetTopmostException(PyThreadState *tstate)
{
    _PyErr_StackItem *exc_info = tstate->exc_info;
    while ((exc_info->exc_type == NULL || exc_info->exc_type == Py_None) &&
           exc_info->previous_item != NULL)
    {
        exc_info = exc_info->previous_item;
    }
    return exc_info;
}
#endif

/* SaveResetException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = __Pyx_PyErr_GetTopmostException(tstate);
    *type = exc_info->exc_type;
    *value = exc_info->exc_value;
    *tb = exc_info->exc_traceback;
    #else
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    #endif
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = type;
    exc_info->exc_value = value;
    exc_info->exc_traceback = tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
#endif

/* PyErrExceptionMatches */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx_PyErr_ExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        if (__Pyx_PyErr_GivenExceptionMatches(exc_type, PyTuple_GET_ITEM(tuple, i))) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    PyObject *exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
    if (unlikely(PyTuple_Check(err)))
        return __Pyx_PyErr_ExceptionMatchesTuple(exc_type, err);
    return __Pyx_PyErr_GivenExceptionMatches(exc_type, err);
}
#endif

/* GetException */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb)
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb)
#endif
{
    PyObject *local_type, *local_value, *local_tb;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    #if PY_MAJOR_VERSION >= 3
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
    #endif
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    #if CYTHON_USE_EXC_INFO_STACK
    {
        _PyErr_StackItem *exc_info = tstate->exc_info;
        tmp_type = exc_info->exc_type;
        tmp_value = exc_info->exc_value;
        tmp_tb = exc_info->exc_traceback;
        exc_info->exc_type = local_type;
        exc_info->exc_value = local_value;
        exc_info->exc_traceback = local_tb;
    }
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
}

/* GetItemIntUnicode */
static CYTHON_INLINE Py_UCS4 __Pyx_GetItemInt_Unicode_Fast(PyObject* ustring, Py_ssize_t i,
                                                           int wraparound, int boundscheck) {
    Py_ssize_t length;
    if (unlikely(__Pyx_PyUnicode_READY(ustring) < 0)) return (Py_UCS4)-1;
    if (wraparound | boundscheck) {
        length = __Pyx_PyUnicode_GET_LENGTH(ustring);
        if (wraparound & unlikely(i < 0)) i += length;
        if ((!boundscheck) || likely(__Pyx_is_valid_index(i, length))) {
            return __Pyx_PyUnicode_READ_CHAR(ustring, i);
        } else {
            PyErr_SetString(PyExc_IndexError, "string index out of range");
            return (Py_UCS4)-1;
        }
    } else {
        return __Pyx_PyUnicode_READ_CHAR(ustring, i);
    }
}

/* IterNext */
static PyObject *__Pyx_PyIter_Next2Default(PyObject* defval) {
    PyObject* exc_type;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    exc_type = __Pyx_PyErr_Occurred();
    if (unlikely(exc_type)) {
        if (!defval || unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration)))
            return NULL;
        __Pyx_PyErr_Clear();
        Py_INCREF(defval);
        return defval;
    }
    if (defval) {
        Py_INCREF(defval);
        return defval;
    }
    __Pyx_PyErr_SetNone(PyExc_StopIteration);
    return NULL;
}
static void __Pyx_PyIter_Next_ErrorNoIterator(PyObject *iterator) {
    PyErr_Format(PyExc_TypeError,
        "%.200s object is not an iterator", Py_TYPE(iterator)->tp_name);
}
static CYTHON_INLINE PyObject *__Pyx_PyIter_Next2(PyObject* iterator, PyObject* defval) {
    PyObject* next;
    iternextfunc iternext = Py_TYPE(iterator)->tp_iternext;
    if (likely(iternext)) {
#if CYTHON_USE_TYPE_SLOTS
        next = iternext(iterator);
        if (likely(next))
            return next;
        #if PY_VERSION_HEX >= 0x02070000
        if (unlikely(iternext == &_PyObject_NextNotImplemented))
            return NULL;
        #endif
#else
        next = PyIter_Next(iterator);
        if (likely(next))
            return next;
#endif
    } else if (CYTHON_USE_TYPE_SLOTS || unlikely(!PyIter_Check(iterator))) {
        __Pyx_PyIter_Next_ErrorNoIterator(iterator);
        return NULL;
    }
#if !CYTHON_USE_TYPE_SLOTS
    else {
        next = PyIter_Next(iterator);
        if (likely(next))
            return next;
    }
#endif
    return __Pyx_PyIter_Next2Default(defval);
}

/* SwapException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = *type;
    exc_info->exc_value = *value;
    exc_info->exc_traceback = *tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = *type;
    tstate->exc_value = *value;
    tstate->exc_traceback = *tb;
    #endif
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyErr_GetExcInfo(&tmp_type, &tmp_value, &tmp_tb);
    PyErr_SetExcInfo(*type, *value, *tb);
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#endif

/* CIntToDigits */
static const char DIGIT_PAIRS_10[2*10*10+1] = {
    "00010203040506070809"
    "10111213141516171819"
    "20212223242526272829"
    "30313233343536373839"
    "40414243444546474849"
    "50515253545556575859"
    "60616263646566676869"
    "70717273747576777879"
    "80818283848586878889"
    "90919293949596979899"
};
static const char DIGIT_PAIRS_8[2*8*8+1] = {
    "0001020304050607"
    "1011121314151617"
    "2021222324252627"
    "3031323334353637"
    "4041424344454647"
    "5051525354555657"
    "6061626364656667"
    "7071727374757677"
};
static const char DIGITS_HEX[2*16+1] = {
    "0123456789abcdef"
    "0123456789ABCDEF"
};

/* BuildPyUnicode */
static PyObject* __Pyx_PyUnicode_BuildFromAscii(Py_ssize_t ulength, char* chars, int clength,
                                                int prepend_sign, char padding_char) {
    PyObject *uval;
    Py_ssize_t uoffset = ulength - clength;
#if CYTHON_USE_UNICODE_INTERNALS
    Py_ssize_t i;
#if CYTHON_PEP393_ENABLED
    void *udata;
    uval = PyUnicode_New(ulength, 127);
    if (unlikely(!uval)) return NULL;
    udata = PyUnicode_DATA(uval);
#else
    Py_UNICODE *udata;
    uval = PyUnicode_FromUnicode(NULL, ulength);
    if (unlikely(!uval)) return NULL;
    udata = PyUnicode_AS_UNICODE(uval);
#endif
    if (uoffset > 0) {
        i = 0;
        if (prepend_sign) {
            __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, 0, '-');
            i++;
        }
        for (; i < uoffset; i++) {
            __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, i, padding_char);
        }
    }
    for (i=0; i < clength; i++) {
        __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, uoffset+i, chars[i]);
    }
#else
    {
        PyObject *sign = NULL, *padding = NULL;
        uval = NULL;
        if (uoffset > 0) {
            prepend_sign = !!prepend_sign;
            if (uoffset > prepend_sign) {
                padding = PyUnicode_FromOrdinal(padding_char);
                if (likely(padding) && uoffset > prepend_sign + 1) {
                    PyObject *tmp;
                    PyObject *repeat = PyInt_FromSize_t(uoffset - prepend_sign);
                    if (unlikely(!repeat)) goto done_or_error;
                    tmp = PyNumber_Multiply(padding, repeat);
                    Py_DECREF(repeat);
                    Py_DECREF(padding);
                    padding = tmp;
                }
                if (unlikely(!padding)) goto done_or_error;
            }
            if (prepend_sign) {
                sign = PyUnicode_FromOrdinal('-');
                if (unlikely(!sign)) goto done_or_error;
            }
        }
        uval = PyUnicode_DecodeASCII(chars, clength, NULL);
        if (likely(uval) && padding) {
            PyObject *tmp = PyNumber_Add(padding, uval);
            Py_DECREF(uval);
            uval = tmp;
        }
        if (likely(uval) && sign) {
            PyObject *tmp = PyNumber_Add(sign, uval);
            Py_DECREF(uval);
            uval = tmp;
        }
done_or_error:
        Py_XDECREF(padding);
        Py_XDECREF(sign);
    }
#endif
    return uval;
}

/* CIntToPyUnicode */
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned short    uint16_t;
        #else
           typedef unsigned __int16  uint16_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#if defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6))
#define GCC_DIAGNOSTIC
#endif
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_From_int(int value, Py_ssize_t width, char padding_char, char format_char) {
    char digits[sizeof(int)*3+2];
    char *dpos, *end = digits + sizeof(int)*3+2;
    const char *hex_digits = DIGITS_HEX;
    Py_ssize_t length, ulength;
    int prepend_sign, last_one_off;
    int remaining;
#ifdef GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (format_char == 'X') {
        hex_digits += 16;
        format_char = 'x';
    }
    remaining = value;
    last_one_off = 0;
    dpos = end;
    do {
        int digit_pos;
        switch (format_char) {
        case 'o':
            digit_pos = abs((int)(remaining % (8*8)));
            remaining = (int) (remaining / (8*8));
            dpos -= 2;
            *(uint16_t*)dpos = ((const uint16_t*)DIGIT_PAIRS_8)[digit_pos];
            last_one_off = (digit_pos < 8);
            break;
        case 'd':
            digit_pos = abs((int)(remaining % (10*10)));
            remaining = (int) (remaining / (10*10));
            dpos -= 2;
            *(uint16_t*)dpos = ((const uint16_t*)DIGIT_PAIRS_10)[digit_pos];
            last_one_off = (digit_pos < 10);
            break;
        case 'x':
            *(--dpos) = hex_digits[abs((int)(remaining % 16))];
            remaining = (int) (remaining / 16);
            break;
        default:
            assert(0);
            break;
        }
    } while (unlikely(remaining != 0));
    if (last_one_off) {
        assert(*dpos == '0');
        dpos++;
    }
    length = end - dpos;
    ulength = length;
    prepend_sign = 0;
    if (!is_unsigned && value <= neg_one) {
        if (padding_char == ' ' || width <= length + 1) {
            *(--dpos) = '-';
            ++length;
        } else {
            prepend_sign = 1;
        }
        ++ulength;
    }
    if (width > ulength) {
        ulength = width;
    }
    if (ulength == 1) {
        return PyUnicode_FromOrdinal(*dpos);
    }
    return __Pyx_PyUnicode_BuildFromAscii(ulength, dpos, (int) length, prepend_sign, padding_char);
}

/* PyObjectCallNoArg */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, NULL, 0);
    }
#endif
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || __Pyx_CyFunction_Check(func)))
#else
    if (likely(PyCFunction_Check(func)))
#endif
    {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
            return __Pyx_PyObject_CallMethO(func, NULL);
        }
    }
    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
}
#endif

/* unicode_iter */
static CYTHON_INLINE int __Pyx_init_unicode_iteration(
    PyObject* ustring, Py_ssize_t *length, void** data, int *kind) {
#if CYTHON_PEP393_ENABLED
    if (unlikely(__Pyx_PyUnicode_READY(ustring) < 0)) return -1;
    *kind   = PyUnicode_KIND(ustring);
    *length = PyUnicode_GET_LENGTH(ustring);
    *data   = PyUnicode_DATA(ustring);
#else
    *kind   = 0;
    *length = PyUnicode_GET_SIZE(ustring);
    *data   = (void*)PyUnicode_AS_UNICODE(ustring);
#endif
    return 0;
}

/* PyObjectFormat */
#if CYTHON_USE_UNICODE_WRITER
static PyObject* __Pyx_PyObject_Format(PyObject* obj, PyObject* format_spec) {
    int ret;
    _PyUnicodeWriter writer;
    if (likely(PyFloat_CheckExact(obj))) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x03040000
        _PyUnicodeWriter_Init(&writer, 0);
#else
        _PyUnicodeWriter_Init(&writer);
#endif
        ret = _PyFloat_FormatAdvancedWriter(
            &writer,
            obj,
            format_spec, 0, PyUnicode_GET_LENGTH(format_spec));
    } else if (likely(PyLong_CheckExact(obj))) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x03040000
        _PyUnicodeWriter_Init(&writer, 0);
#else
        _PyUnicodeWriter_Init(&writer);
#endif
        ret = _PyLong_FormatAdvancedWriter(
            &writer,
            obj,
            format_spec, 0, PyUnicode_GET_LENGTH(format_spec));
    } else {
        return PyObject_Format(obj, format_spec);
    }
    if (unlikely(ret == -1)) {
        _PyUnicodeWriter_Dealloc(&writer);
        return NULL;
    }
    return _PyUnicodeWriter_Finish(&writer);
}
#endif

/* GetItemInt */
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely(__Pyx_is_valid_index(n, PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely(__Pyx_is_valid_index(n, PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* PyObject_GenericGetAttrNoDict */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject *__Pyx_RaiseGenericGetAttributeError(PyTypeObject *tp, PyObject *attr_name) {
    PyErr_Format(PyExc_AttributeError,
#if PY_MAJOR_VERSION >= 3
                 "'%.50s' object has no attribute '%U'",
                 tp->tp_name, attr_name);
#else
                 "'%.50s' object has no attribute '%.400s'",
                 tp->tp_name, PyString_AS_STRING(attr_name));
#endif
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name) {
    PyObject *descr;
    PyTypeObject *tp = Py_TYPE(obj);
    if (unlikely(!PyString_Check(attr_name))) {
        return PyObject_GenericGetAttr(obj, attr_name);
    }
    assert(!tp->tp_dictoffset);
    descr = _PyType_Lookup(tp, attr_name);
    if (unlikely(!descr)) {
        return __Pyx_RaiseGenericGetAttributeError(tp, attr_name);
    }
    Py_INCREF(descr);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyType_HasFeature(Py_TYPE(descr), Py_TPFLAGS_HAVE_CLASS)))
    #endif
    {
        descrgetfunc f = Py_TYPE(descr)->tp_descr_get;
        if (unlikely(f)) {
            PyObject *res = f(descr, obj, (PyObject *)tp);
            Py_DECREF(descr);
            return res;
        }
    }
    return descr;
}
#endif

/* PyObject_GenericGetAttr */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject* __Pyx_PyObject_GenericGetAttr(PyObject* obj, PyObject* attr_name) {
    if (unlikely(Py_TYPE(obj)->tp_dictoffset)) {
        return PyObject_GenericGetAttr(obj, attr_name);
    }
    return __Pyx_PyObject_GenericGetAttrNoDict(obj, attr_name);
}
#endif

/* SetVTable */
static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
#if PY_VERSION_HEX >= 0x02070000
    PyObject *ob = PyCapsule_New(vtable, 0, 0);
#else
    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
#endif
    if (!ob)
        goto bad;
    if (PyDict_SetItem(dict, __pyx_n_s_pyx_vtable, ob) < 0)
        goto bad;
    Py_DECREF(ob);
    return 0;
bad:
    Py_XDECREF(ob);
    return -1;
}

/* TypeImport */
#ifndef __PYX_HAVE_RT_ImportType
#define __PYX_HAVE_RT_ImportType
static PyTypeObject *__Pyx_ImportType(PyObject *module, const char *module_name, const char *class_name,
    size_t size, enum __Pyx_ImportType_CheckSize check_size)
{
    PyObject *result = 0;
    char warning[200];
    Py_ssize_t basicsize;
#ifdef Py_LIMITED_API
    PyObject *py_basicsize;
#endif
    result = PyObject_GetAttrString(module, class_name);
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#ifndef Py_LIMITED_API
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
#else
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if ((size_t)basicsize < size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        goto bad;
    }
    if (check_size == __Pyx_ImportType_CheckSize_Error && (size_t)basicsize != size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        goto bad;
    }
    else if (check_size == __Pyx_ImportType_CheckSize_Warn && (size_t)basicsize > size) {
        PyOS_snprintf(warning, sizeof(warning),
            "%s.%s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(result);
    return NULL;
}
#endif

/* Import */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if ((1) && (strchr(__Pyx_MODULE_NAME, '.'))) {
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_MAJOR_VERSION < 3
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, (PyObject *)NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* ImportFrom */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name) {
    PyObject* value = __Pyx_PyObject_GetAttrStr(module, name);
    if (unlikely(!value) && PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Format(PyExc_ImportError,
        #if PY_MAJOR_VERSION < 3
            "cannot import name %.230s", PyString_AS_STRING(name));
        #else
            "cannot import name %S", name);
        #endif
    }
    return value;
}

/* FetchCommonType */
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type) {
    PyObject* fake_module;
    PyTypeObject* cached_type = NULL;
    fake_module = PyImport_AddModule((char*) "_cython_" CYTHON_ABI);
    if (!fake_module) return NULL;
    Py_INCREF(fake_module);
    cached_type = (PyTypeObject*) PyObject_GetAttrString(fake_module, type->tp_name);
    if (cached_type) {
        if (!PyType_Check((PyObject*)cached_type)) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s is not a type object",
                type->tp_name);
            goto bad;
        }
        if (cached_type->tp_basicsize != type->tp_basicsize) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s has the wrong size, try recompiling",
                type->tp_name);
            goto bad;
        }
    } else {
        if (!PyErr_ExceptionMatches(PyExc_AttributeError)) goto bad;
        PyErr_Clear();
        if (PyType_Ready(type) < 0) goto bad;
        if (PyObject_SetAttrString(fake_module, type->tp_name, (PyObject*) type) < 0)
            goto bad;
        Py_INCREF(type);
        cached_type = type;
    }
done:
    Py_DECREF(fake_module);
    return cached_type;
bad:
    Py_XDECREF(cached_type);
    cached_type = NULL;
    goto done;
}

/* CythonFunctionShared */
#include <structmember.h>
static PyObject *
__Pyx_CyFunction_get_doc(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *closure)
{
    if (unlikely(op->func_doc == NULL)) {
        if (op->func.m_ml->ml_doc) {
#if PY_MAJOR_VERSION >= 3
            op->func_doc = PyUnicode_FromString(op->func.m_ml->ml_doc);
#else
            op->func_doc = PyString_FromString(op->func.m_ml->ml_doc);
#endif
            if (unlikely(op->func_doc == NULL))
                return NULL;
        } else {
            Py_INCREF(Py_None);
            return Py_None;
        }
    }
    Py_INCREF(op->func_doc);
    return op->func_doc;
}
static int
__Pyx_CyFunction_set_doc(__pyx_CyFunctionObject *op, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp = op->func_doc;
    if (value == NULL) {
        value = Py_None;
    }
    Py_INCREF(value);
    op->func_doc = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_name(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    if (unlikely(op->func_name == NULL)) {
#if PY_MAJOR_VERSION >= 3
        op->func_name = PyUnicode_InternFromString(op->func.m_ml->ml_name);
#else
        op->func_name = PyString_InternFromString(op->func.m_ml->ml_name);
#endif
        if (unlikely(op->func_name == NULL))
            return NULL;
    }
    Py_INCREF(op->func_name);
    return op->func_name;
}
static int
__Pyx_CyFunction_set_name(__pyx_CyFunctionObject *op, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value)))
#else
    if (unlikely(value == NULL || !PyString_Check(value)))
#endif
    {
        PyErr_SetString(PyExc_TypeError,
                        "__name__ must be set to a string object");
        return -1;
    }
    tmp = op->func_name;
    Py_INCREF(value);
    op->func_name = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_qualname(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    Py_INCREF(op->func_qualname);
    return op->func_qualname;
}
static int
__Pyx_CyFunction_set_qualname(__pyx_CyFunctionObject *op, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value)))
#else
    if (unlikely(value == NULL || !PyString_Check(value)))
#endif
    {
        PyErr_SetString(PyExc_TypeError,
                        "__qualname__ must be set to a string object");
        return -1;
    }
    tmp = op->func_qualname;
    Py_INCREF(value);
    op->func_qualname = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_self(__pyx_CyFunctionObject *m, CYTHON_UNUSED void *closure)
{
    PyObject *self;
    self = m->func_closure;
    if (self == NULL)
        self = Py_None;
    Py_INCREF(self);
    return self;
}
static PyObject *
__Pyx_CyFunction_get_dict(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    if (unlikely(op->func_dict == NULL)) {
        op->func_dict = PyDict_New();
        if (unlikely(op->func_dict == NULL))
            return NULL;
    }
    Py_INCREF(op->func_dict);
    return op->func_dict;
}
static int
__Pyx_CyFunction_set_dict(__pyx_CyFunctionObject *op, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp;
    if (unlikely(value == NULL)) {
        PyErr_SetString(PyExc_TypeError,
               "function's dictionary may not be deleted");
        return -1;
    }
    if (unlikely(!PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
               "setting function's dictionary to a non-dict");
        return -1;
    }
    tmp = op->func_dict;
    Py_INCREF(value);
    op->func_dict = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_globals(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    Py_INCREF(op->func_globals);
    return op->func_globals;
}
static PyObject *
__Pyx_CyFunction_get_closure(CYTHON_UNUSED __pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    Py_INCREF(Py_None);
    return Py_None;
}
static PyObject *
__Pyx_CyFunction_get_code(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    PyObject* result = (op->func_code) ? op->func_code : Py_None;
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_init_defaults(__pyx_CyFunctionObject *op) {
    int result = 0;
    PyObject *res = op->defaults_getter((PyObject *) op);
    if (unlikely(!res))
        return -1;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    op->defaults_tuple = PyTuple_GET_ITEM(res, 0);
    Py_INCREF(op->defaults_tuple);
    op->defaults_kwdict = PyTuple_GET_ITEM(res, 1);
    Py_INCREF(op->defaults_kwdict);
    #else
    op->defaults_tuple = PySequence_ITEM(res, 0);
    if (unlikely(!op->defaults_tuple)) result = -1;
    else {
        op->defaults_kwdict = PySequence_ITEM(res, 1);
        if (unlikely(!op->defaults_kwdict)) result = -1;
    }
    #endif
    Py_DECREF(res);
    return result;
}
static int
__Pyx_CyFunction_set_defaults(__pyx_CyFunctionObject *op, PyObject* value, CYTHON_UNUSED void *context) {
    PyObject* tmp;
    if (!value) {
        value = Py_None;
    } else if (value != Py_None && !PyTuple_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__defaults__ must be set to a tuple object");
        return -1;
    }
    Py_INCREF(value);
    tmp = op->defaults_tuple;
    op->defaults_tuple = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_defaults(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context) {
    PyObject* result = op->defaults_tuple;
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (__Pyx_CyFunction_init_defaults(op) < 0) return NULL;
            result = op->defaults_tuple;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_set_kwdefaults(__pyx_CyFunctionObject *op, PyObject* value, CYTHON_UNUSED void *context) {
    PyObject* tmp;
    if (!value) {
        value = Py_None;
    } else if (value != Py_None && !PyDict_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__kwdefaults__ must be set to a dict object");
        return -1;
    }
    Py_INCREF(value);
    tmp = op->defaults_kwdict;
    op->defaults_kwdict = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_kwdefaults(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context) {
    PyObject* result = op->defaults_kwdict;
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (__Pyx_CyFunction_init_defaults(op) < 0) return NULL;
            result = op->defaults_kwdict;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_set_annotations(__pyx_CyFunctionObject *op, PyObject* value, CYTHON_UNUSED void *context) {
    PyObject* tmp;
    if (!value || value == Py_None) {
        value = NULL;
    } else if (!PyDict_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__annotations__ must be set to a dict object");
        return -1;
    }
    Py_XINCREF(value);
    tmp = op->func_annotations;
    op->func_annotations = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_annotations(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context) {
    PyObject* result = op->func_annotations;
    if (unlikely(!result)) {
        result = PyDict_New();
        if (unlikely(!result)) return NULL;
        op->func_annotations = result;
    }
    Py_INCREF(result);
    return result;
}
static PyGetSetDef __pyx_CyFunction_getsets[] = {
    {(char *) "func_doc", (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {(char *) "__doc__",  (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {(char *) "func_name", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {(char *) "__name__", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {(char *) "__qualname__", (getter)__Pyx_CyFunction_get_qualname, (setter)__Pyx_CyFunction_set_qualname, 0, 0},
    {(char *) "__self__", (getter)__Pyx_CyFunction_get_self, 0, 0, 0},
    {(char *) "func_dict", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {(char *) "__dict__", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {(char *) "func_globals", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {(char *) "__globals__", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {(char *) "func_closure", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {(char *) "__closure__", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {(char *) "func_code", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {(char *) "__code__", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {(char *) "func_defaults", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {(char *) "__defaults__", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {(char *) "__kwdefaults__", (getter)__Pyx_CyFunction_get_kwdefaults, (setter)__Pyx_CyFunction_set_kwdefaults, 0, 0},
    {(char *) "__annotations__", (getter)__Pyx_CyFunction_get_annotations, (setter)__Pyx_CyFunction_set_annotations, 0, 0},
    {0, 0, 0, 0, 0}
};
static PyMemberDef __pyx_CyFunction_members[] = {
    {(char *) "__module__", T_OBJECT, offsetof(PyCFunctionObject, m_module), PY_WRITE_RESTRICTED, 0},
    {0, 0, 0,  0, 0}
};
static PyObject *
__Pyx_CyFunction_reduce(__pyx_CyFunctionObject *m, CYTHON_UNUSED PyObject *args)
{
#if PY_MAJOR_VERSION >= 3
    return PyUnicode_FromString(m->func.m_ml->ml_name);
#else
    return PyString_FromString(m->func.m_ml->ml_name);
#endif
}
static PyMethodDef __pyx_CyFunction_methods[] = {
    {"__reduce__", (PyCFunction)__Pyx_CyFunction_reduce, METH_VARARGS, 0},
    {0, 0, 0, 0}
};
#if PY_VERSION_HEX < 0x030500A0
#define __Pyx_CyFunction_weakreflist(cyfunc) ((cyfunc)->func_weakreflist)
#else
#define __Pyx_CyFunction_weakreflist(cyfunc) ((cyfunc)->func.m_weakreflist)
#endif
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject *op, PyMethodDef *ml, int flags, PyObject* qualname,
                                       PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
    if (unlikely(op == NULL))
        return NULL;
    op->flags = flags;
    __Pyx_CyFunction_weakreflist(op) = NULL;
    op->func.m_ml = ml;
    op->func.m_self = (PyObject *) op;
    Py_XINCREF(closure);
    op->func_closure = closure;
    Py_XINCREF(module);
    op->func.m_module = module;
    op->func_dict = NULL;
    op->func_name = NULL;
    Py_INCREF(qualname);
    op->func_qualname = qualname;
    op->func_doc = NULL;
    op->func_classobj = NULL;
    op->func_globals = globals;
    Py_INCREF(op->func_globals);
    Py_XINCREF(code);
    op->func_code = code;
    op->defaults_pyobjects = 0;
    op->defaults_size = 0;
    op->defaults = NULL;
    op->defaults_tuple = NULL;
    op->defaults_kwdict = NULL;
    op->defaults_getter = NULL;
    op->func_annotations = NULL;
    return (PyObject *) op;
}
static int
__Pyx_CyFunction_clear(__pyx_CyFunctionObject *m)
{
    Py_CLEAR(m->func_closure);
    Py_CLEAR(m->func.m_module);
    Py_CLEAR(m->func_dict);
    Py_CLEAR(m->func_name);
    Py_CLEAR(m->func_qualname);
    Py_CLEAR(m->func_doc);
    Py_CLEAR(m->func_globals);
    Py_CLEAR(m->func_code);
    Py_CLEAR(m->func_classobj);
    Py_CLEAR(m->defaults_tuple);
    Py_CLEAR(m->defaults_kwdict);
    Py_CLEAR(m->func_annotations);
    if (m->defaults) {
        PyObject **pydefaults = __Pyx_CyFunction_Defaults(PyObject *, m);
        int i;
        for (i = 0; i < m->defaults_pyobjects; i++)
            Py_XDECREF(pydefaults[i]);
        PyObject_Free(m->defaults);
        m->defaults = NULL;
    }
    return 0;
}
static void __Pyx__CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    if (__Pyx_CyFunction_weakreflist(m) != NULL)
        PyObject_ClearWeakRefs((PyObject *) m);
    __Pyx_CyFunction_clear(m);
    PyObject_GC_Del(m);
}
static void __Pyx_CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    PyObject_GC_UnTrack(m);
    __Pyx__CyFunction_dealloc(m);
}
static int __Pyx_CyFunction_traverse(__pyx_CyFunctionObject *m, visitproc visit, void *arg)
{
    Py_VISIT(m->func_closure);
    Py_VISIT(m->func.m_module);
    Py_VISIT(m->func_dict);
    Py_VISIT(m->func_name);
    Py_VISIT(m->func_qualname);
    Py_VISIT(m->func_doc);
    Py_VISIT(m->func_globals);
    Py_VISIT(m->func_code);
    Py_VISIT(m->func_classobj);
    Py_VISIT(m->defaults_tuple);
    Py_VISIT(m->defaults_kwdict);
    if (m->defaults) {
        PyObject **pydefaults = __Pyx_CyFunction_Defaults(PyObject *, m);
        int i;
        for (i = 0; i < m->defaults_pyobjects; i++)
            Py_VISIT(pydefaults[i]);
    }
    return 0;
}
static PyObject *__Pyx_CyFunction_descr_get(PyObject *func, PyObject *obj, PyObject *type)
{
#if PY_MAJOR_VERSION < 3
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    if (m->flags & __Pyx_CYFUNCTION_STATICMETHOD) {
        Py_INCREF(func);
        return func;
    }
    if (m->flags & __Pyx_CYFUNCTION_CLASSMETHOD) {
        if (type == NULL)
            type = (PyObject *)(Py_TYPE(obj));
        return __Pyx_PyMethod_New(func, type, (PyObject *)(Py_TYPE(type)));
    }
    if (obj == Py_None)
        obj = NULL;
#endif
    return __Pyx_PyMethod_New(func, obj, type);
}
static PyObject*
__Pyx_CyFunction_repr(__pyx_CyFunctionObject *op)
{
#if PY_MAJOR_VERSION >= 3
    return PyUnicode_FromFormat("<cyfunction %U at %p>",
                                op->func_qualname, (void *)op);
#else
    return PyString_FromFormat("<cyfunction %s at %p>",
                               PyString_AsString(op->func_qualname), (void *)op);
#endif
}
static PyObject * __Pyx_CyFunction_CallMethod(PyObject *func, PyObject *self, PyObject *arg, PyObject *kw) {
    PyCFunctionObject* f = (PyCFunctionObject*)func;
    PyCFunction meth = f->m_ml->ml_meth;
    Py_ssize_t size;
    switch (f->m_ml->ml_flags & (METH_VARARGS | METH_KEYWORDS | METH_NOARGS | METH_O)) {
    case METH_VARARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0))
            return (*meth)(self, arg);
        break;
    case METH_VARARGS | METH_KEYWORDS:
        return (*(PyCFunctionWithKeywords)(void*)meth)(self, arg, kw);
    case METH_NOARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
            size = PyTuple_GET_SIZE(arg);
            if (likely(size == 0))
                return (*meth)(self, NULL);
            PyErr_Format(PyExc_TypeError,
                "%.200s() takes no arguments (%" CYTHON_FORMAT_SSIZE_T "d given)",
                f->m_ml->ml_name, size);
            return NULL;
        }
        break;
    case METH_O:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
            size = PyTuple_GET_SIZE(arg);
            if (likely(size == 1)) {
                PyObject *result, *arg0;
                #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                arg0 = PyTuple_GET_ITEM(arg, 0);
                #else
                arg0 = PySequence_ITEM(arg, 0); if (unlikely(!arg0)) return NULL;
                #endif
                result = (*meth)(self, arg0);
                #if !(CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS)
                Py_DECREF(arg0);
                #endif
                return result;
            }
            PyErr_Format(PyExc_TypeError,
                "%.200s() takes exactly one argument (%" CYTHON_FORMAT_SSIZE_T "d given)",
                f->m_ml->ml_name, size);
            return NULL;
        }
        break;
    default:
        PyErr_SetString(PyExc_SystemError, "Bad call flags in "
                        "__Pyx_CyFunction_Call. METH_OLDARGS is no "
                        "longer supported!");
        return NULL;
    }
    PyErr_Format(PyExc_TypeError, "%.200s() takes no keyword arguments",
                 f->m_ml->ml_name);
    return NULL;
}
static CYTHON_INLINE PyObject *__Pyx_CyFunction_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    return __Pyx_CyFunction_CallMethod(func, ((PyCFunctionObject*)func)->m_self, arg, kw);
}
static PyObject *__Pyx_CyFunction_CallAsMethod(PyObject *func, PyObject *args, PyObject *kw) {
    PyObject *result;
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *) func;
    if ((cyfunc->flags & __Pyx_CYFUNCTION_CCLASS) && !(cyfunc->flags & __Pyx_CYFUNCTION_STATICMETHOD)) {
        Py_ssize_t argc;
        PyObject *new_args;
        PyObject *self;
        argc = PyTuple_GET_SIZE(args);
        new_args = PyTuple_GetSlice(args, 1, argc);
        if (unlikely(!new_args))
            return NULL;
        self = PyTuple_GetItem(args, 0);
        if (unlikely(!self)) {
            Py_DECREF(new_args);
            return NULL;
        }
        result = __Pyx_CyFunction_CallMethod(func, self, new_args, kw);
        Py_DECREF(new_args);
    } else {
        result = __Pyx_CyFunction_Call(func, args, kw);
    }
    return result;
}
static PyTypeObject __pyx_CyFunctionType_type = {
    PyVarObject_HEAD_INIT(0, 0)
    "cython_function_or_method",
    sizeof(__pyx_CyFunctionObject),
    0,
    (destructor) __Pyx_CyFunction_dealloc,
    0,
    0,
    0,
#if PY_MAJOR_VERSION < 3
    0,
#else
    0,
#endif
    (reprfunc) __Pyx_CyFunction_repr,
    0,
    0,
    0,
    0,
    __Pyx_CyFunction_CallAsMethod,
    0,
    0,
    0,
    0,
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC,
    0,
    (traverseproc) __Pyx_CyFunction_traverse,
    (inquiry) __Pyx_CyFunction_clear,
    0,
#if PY_VERSION_HEX < 0x030500A0
    offsetof(__pyx_CyFunctionObject, func_weakreflist),
#else
    offsetof(PyCFunctionObject, m_weakreflist),
#endif
    0,
    0,
    __pyx_CyFunction_methods,
    __pyx_CyFunction_members,
    __pyx_CyFunction_getsets,
    0,
    0,
    __Pyx_CyFunction_descr_get,
    0,
    offsetof(__pyx_CyFunctionObject, func_dict),
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
#if PY_VERSION_HEX >= 0x030400a1
    0,
#endif
#if PY_VERSION_HEX >= 0x030800b1
    0,
#endif
#if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
    0,
#endif
};
static int __pyx_CyFunction_init(void) {
    __pyx_CyFunctionType = __Pyx_FetchCommonType(&__pyx_CyFunctionType_type);
    if (unlikely(__pyx_CyFunctionType == NULL)) {
        return -1;
    }
    return 0;
}
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *func, size_t size, int pyobjects) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults = PyObject_Malloc(size);
    if (unlikely(!m->defaults))
        return PyErr_NoMemory();
    memset(m->defaults, 0, size);
    m->defaults_pyobjects = pyobjects;
    m->defaults_size = size;
    return m->defaults;
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *func, PyObject *tuple) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_tuple = tuple;
    Py_INCREF(tuple);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_kwdict = dict;
    Py_INCREF(dict);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->func_annotations = dict;
    Py_INCREF(dict);
}

/* CythonFunction */
static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml, int flags, PyObject* qualname,
                                      PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
    PyObject *op = __Pyx_CyFunction_Init(
        PyObject_GC_New(__pyx_CyFunctionObject, __pyx_CyFunctionType),
        ml, flags, qualname, closure, module, globals, code
    );
    if (likely(op)) {
        PyObject_GC_Track(op);
    }
    return op;
}

/* PyDictVersioning */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
    PyObject **dictptr = NULL;
    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
    if (offset) {
#if CYTHON_COMPILING_IN_CPYTHON
        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
#else
        dictptr = _PyObject_GetDictPtr(obj);
#endif
    }
    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
}
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
        return 0;
    return obj_dict_version == __Pyx_get_object_dict_version(obj);
}
#endif

/* GetModuleGlobalName */
#if CYTHON_USE_DICT_VERSIONS
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
#else
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
#endif
{
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1
    result = _PyDict_GetItem_KnownHash(__pyx_d, name, ((PyASCIIObject *) name)->hash);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    } else if (unlikely(PyErr_Occurred())) {
        return NULL;
    }
#else
    result = PyDict_GetItem(__pyx_d, name);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
#endif
#else
    result = PyObject_GetItem(__pyx_d, name);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
    PyErr_Clear();
#endif
    return __Pyx_GetBuiltinName(name);
}

/* PyObjectSetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_setattro))
        return tp->tp_setattro(obj, attr_name, value);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_setattr))
        return tp->tp_setattr(obj, PyString_AS_STRING(attr_name), value);
#endif
    return PyObject_SetAttr(obj, attr_name, value);
}
#endif

/* CLineInTraceback */
#ifndef CYTHON_CLINE_IN_TRACEBACK
static int __Pyx_CLineForTraceback(CYTHON_NCP_UNUSED PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    if (unlikely(!__pyx_cython_runtime)) {
        return c_line;
    }
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
        __PYX_PY_DICT_LOOKUP_IF_MODIFIED(
            use_cline, *cython_runtime_dict,
            __Pyx_PyDict_GetItemStr(*cython_runtime_dict, __pyx_n_s_cline_in_traceback))
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (use_cline == Py_False || (use_cline != Py_True && PyObject_Not(use_cline) != 0)) {
        c_line = 0;
    }
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, ((size_t)new_max) * sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
#include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
    const int neg_one = (int) ((int) 0 - (int) 1), const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

/* CIntFromPyVerify */
#define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
    const long neg_one = (long) ((long) 0 - (long) 1), const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* PyUCS4InUnicode */
#if PY_VERSION_HEX < 0x03090000
#if Py_UNICODE_SIZE == 2
static int __Pyx_PyUnicodeBufferContainsUCS4_SP(Py_UNICODE* buffer, Py_ssize_t length, Py_UCS4 character) {
    Py_UNICODE high_val, low_val;
    Py_UNICODE* pos;
    high_val = (Py_UNICODE) (0xD800 | (((character - 0x10000) >> 10) & ((1<<10)-1)));
    low_val  = (Py_UNICODE) (0xDC00 | ( (character - 0x10000)        & ((1<<10)-1)));
    for (pos=buffer; pos < buffer+length-1; pos++) {
        if (unlikely((high_val == pos[0]) & (low_val == pos[1]))) return 1;
    }
    return 0;
}
#endif
static int __Pyx_PyUnicodeBufferContainsUCS4_BMP(Py_UNICODE* buffer, Py_ssize_t length, Py_UCS4 character) {
    Py_UNICODE uchar;
    Py_UNICODE* pos;
    uchar = (Py_UNICODE) character;
    for (pos=buffer; pos < buffer+length; pos++) {
        if (unlikely(uchar == pos[0])) return 1;
    }
    return 0;
}
#endif
static CYTHON_INLINE int __Pyx_UnicodeContainsUCS4(PyObject* unicode, Py_UCS4 character) {
#if CYTHON_PEP393_ENABLED
    const int kind = PyUnicode_KIND(unicode);
    if (likely(kind != PyUnicode_WCHAR_KIND)) {
        Py_ssize_t i;
        const void* udata = PyUnicode_DATA(unicode);
        const Py_ssize_t length = PyUnicode_GET_LENGTH(unicode);
        for (i=0; i < length; i++) {
            if (unlikely(character == PyUnicode_READ(kind, udata, i))) return 1;
        }
        return 0;
    }
#elif PY_VERSION_HEX >= 0x03090000
    #error Cannot use "UChar in Unicode" in Python 3.9 without PEP-393 unicode strings.
#endif
#if PY_VERSION_HEX < 0x03090000
#if Py_UNICODE_SIZE == 2
    if (unlikely(character > 65535)) {
        return __Pyx_PyUnicodeBufferContainsUCS4_SP(
            PyUnicode_AS_UNICODE(unicode),
            PyUnicode_GET_SIZE(unicode),
            character);
    } else
#endif
    {
        return __Pyx_PyUnicodeBufferContainsUCS4_BMP(
            PyUnicode_AS_UNICODE(unicode),
            PyUnicode_GET_SIZE(unicode),
            character);
    }
#endif
}

/* UnicodeAsUCS4 */
static CYTHON_INLINE Py_UCS4 __Pyx_PyUnicode_AsPy_UCS4(PyObject* x) {
   Py_ssize_t length;
   #if CYTHON_PEP393_ENABLED
   length = PyUnicode_GET_LENGTH(x);
   if (likely(length == 1)) {
       return PyUnicode_READ_CHAR(x, 0);
   }
   #else
   length = PyUnicode_GET_SIZE(x);
   if (likely(length == 1)) {
       return PyUnicode_AS_UNICODE(x)[0];
   }
   #if Py_UNICODE_SIZE == 2
   else if (PyUnicode_GET_SIZE(x) == 2) {
       Py_UCS4 high_val = PyUnicode_AS_UNICODE(x)[0];
       if (high_val >= 0xD800 && high_val <= 0xDBFF) {
           Py_UCS4 low_val = PyUnicode_AS_UNICODE(x)[1];
           if (low_val >= 0xDC00 && low_val <= 0xDFFF) {
               return 0x10000 + (((high_val & ((1<<10)-1)) << 10) | (low_val & ((1<<10)-1)));
           }
       }
   }
   #endif
   #endif
   PyErr_Format(PyExc_ValueError,
                "only single character unicode strings can be converted to Py_UCS4, "
                "got length %" CYTHON_FORMAT_SSIZE_T "d", length);
   return (Py_UCS4)-1;
}

/* CIntFromPy */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
    const int neg_one = (int) ((int) 0 - (int) 1), const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
static CYTHON_INLINE char __Pyx_PyInt_As_char(PyObject *x) {
    const char neg_one = (char) ((char) 0 - (char) 1), const_zero = (char) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(char) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(char, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (char) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (char) 0;
                case  1: __PYX_VERIFY_RETURN_INT(char, digit, digits[0])
                case 2:
                    if (8 * sizeof(char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 2 * PyLong_SHIFT) {
                            return (char) (((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 3 * PyLong_SHIFT) {
                            return (char) (((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) >= 4 * PyLong_SHIFT) {
                            return (char) (((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (char) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(char) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(char) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (char) 0;
                case -1: __PYX_VERIFY_RETURN_INT(char, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(char,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(char) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                            return (char) ((((((char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(char) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                            return (char) ((((((((char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(char) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 4 * PyLong_SHIFT) {
                            return (char) (((char)-1)*(((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(char) - 1 > 4 * PyLong_SHIFT) {
                            return (char) ((((((((((char)digits[3]) << PyLong_SHIFT) | (char)digits[2]) << PyLong_SHIFT) | (char)digits[1]) << PyLong_SHIFT) | (char)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(char) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(char) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(char, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            char val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (char) -1;
        }
    } else {
        char val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (char) -1;
        val = __Pyx_PyInt_As_char(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to char");
    return (char) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to char");
    return (char) -1;
}

/* ObjectAsUCS4 */
static Py_UCS4 __Pyx__PyObject_AsPy_UCS4_raise_error(long ival) {
   if (ival < 0) {
       if (!PyErr_Occurred())
           PyErr_SetString(PyExc_OverflowError,
                           "cannot convert negative value to Py_UCS4");
   } else {
       PyErr_SetString(PyExc_OverflowError,
                       "value too large to convert to Py_UCS4");
   }
   return (Py_UCS4)-1;
}
static Py_UCS4 __Pyx__PyObject_AsPy_UCS4(PyObject* x) {
   long ival;
   ival = __Pyx_PyInt_As_long(x);
   if (unlikely(!__Pyx_is_valid_index(ival, 1114111 + 1))) {
       return __Pyx__PyObject_AsPy_UCS4_raise_error(ival);
   }
   return (Py_UCS4)ival;
}

/* CIntFromPy */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
    const long neg_one = (long) ((long) 0 - (long) 1), const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* FastTypeChecks */
#if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = a->tp_base;
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
#if PY_MAJOR_VERSION == 2
static int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject* exc_type2) {
    PyObject *exception, *value, *tb;
    int res;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&exception, &value, &tb);
    res = exc_type1 ? PyObject_IsSubclass(err, exc_type1) : 0;
    if (unlikely(res == -1)) {
        PyErr_WriteUnraisable(err);
        res = 0;
    }
    if (!res) {
        res = PyObject_IsSubclass(err, exc_type2);
        if (unlikely(res == -1)) {
            PyErr_WriteUnraisable(err);
            res = 0;
        }
    }
    __Pyx_ErrRestore(exception, value, tb);
    return res;
}
#else
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    int res = exc_type1 ? __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type1) : 0;
    if (!res) {
        res = __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
    return res;
}
#endif
static int __Pyx_PyErr_GivenExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    assert(PyExceptionClass_Check(exc_type));
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        PyObject *t = PyTuple_GET_ITEM(tuple, i);
        #if PY_MAJOR_VERSION < 3
        if (likely(exc_type == t)) return 1;
        #endif
        if (likely(PyExceptionClass_Check(t))) {
            if (__Pyx_inner_PyErr_GivenExceptionMatches2(exc_type, NULL, t)) return 1;
        } else {
        }
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        if (likely(PyExceptionClass_Check(exc_type))) {
            return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
        } else if (likely(PyTuple_Check(exc_type))) {
            return __Pyx_PyErr_GivenExceptionMatchesTuple(err, exc_type);
        } else {
        }
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    assert(PyExceptionClass_Check(exc_type1));
    assert(PyExceptionClass_Check(exc_type2));
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* CheckBinaryVersion */
static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* InitStrings */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            return -1;
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#if !CYTHON_PEP393_ENABLED
static const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    char* defenc_c;
    PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
    if (!defenc) return NULL;
    defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    {
        char* end = defenc_c + PyBytes_GET_SIZE(defenc);
        char* c;
        for (c = defenc_c; c < end; c++) {
            if ((unsigned char) (*c) >= 128) {
                PyUnicode_AsASCIIString(o);
                return NULL;
            }
        }
    }
#endif
    *length = PyBytes_GET_SIZE(defenc);
    return defenc_c;
}
#else
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
}
#endif
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject* x) {
    int retval;
    if (unlikely(!x)) return -1;
    retval = __Pyx_PyObject_IsTrue(x);
    Py_DECREF(x);
    return retval;
}
static PyObject* __Pyx_PyNumber_IntOrLongWrongResultType(PyObject* result, const char* type_name) {
#if PY_MAJOR_VERSION >= 3
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type %.200s).  "
                "The ability to return an instance of a strict subclass of int "
                "is deprecated, and may be removed in a future version of Python.",
                Py_TYPE(result)->tp_name)) {
            Py_DECREF(result);
            return NULL;
        }
        return result;
    }
#endif
    PyErr_Format(PyExc_TypeError,
                 "__%.4s__ returned non-%.4s (type %.200s)",
                 type_name, type_name, Py_TYPE(result)->tp_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_Check(x) || PyLong_Check(x)))
#else
  if (likely(PyLong_Check(x)))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = m->nb_int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = m->nb_long(x);
  }
  #else
  if (likely(m && m->nb_int)) {
    name = "int";
    res = m->nb_int(x);
  }
  #endif
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
    res = PyNumber_Int(x);
  }
#endif
  if (likely(res)) {
#if PY_MAJOR_VERSION < 3
    if (unlikely(!PyInt_Check(res) && !PyLong_Check(res))) {
#else
    if (unlikely(!PyLong_CheckExact(res))) {
#endif
        return __Pyx_PyNumber_IntOrLongWrongResultType(res, name);
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(b);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b) {
  return b ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False);
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
